\documentclass[a4paper]{thesis}
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage{amsfonts}
\usepackage{amsmath} 
\usepackage[square,sort,comma,numbers]{natbib}
\usepackage[toc,page]{appendix} 
\usepackage{tikz}
\usetikzlibrary{arrows}
\usepackage{pgfplots} 
\usepackage{pgfgantt}
\usepackage{pdflscape}
\usepackage{textcomp}
\newlength\fwidth
\pgfplotsset{compat=newest} 
\pgfplotsset{plot coordinates/math parser=false}

\usepackage{graphicx} 
\usepackage{grffile} 
\usepackage{float} 

\usepackage{tabularx}
\newcolumntype{L}{>{\raggedright\arraybackslash}X}
\usepackage{ltablex}
\usepackage{pdflscape}

\usepackage{changes} 
\usepackage{todonotes}

\usepackage{dsfont} 

\usepackage{hyperref}
\bibliographystyle{plainnat}

\usepackage{amsthm}
\theoremstyle{definition}
\let\example\relax
\newtheorem{example}{Example}[chapter]
\newtheorem{remark}{Remark}[chapter]
\newtheorem{corollary}{Corollary}[chapter]

\newtheorem{theorem}{Theorem}[chapter]

\newtheorem{lemma}{Lemma}[chapter] \begin{document}
\frontmatter
\title{Dynamically adaptive age-based maintenance policies}
\author{Martijn G\"{o}sgens\\
\and
S\'{a}ndor Kolumb\'{a}n\\
\and
Stella Kapodistria
}
\begin{titlepage}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}} 

\center 
 

\textsc{\LARGE Eindhoven University of Technology}\\[1.5cm] 

\textsc{\Large Final Bachelor Project}\\[0.5cm] 
\textsc{\large 2WH40, 2017-2018}\\[0.5cm] 

\HRule \\[0.4cm]
{ \huge \bfseries Dynamically adaptive age-based maintenance policies}\\[0.4cm] 
\HRule \\[1.5cm]
 

\begin{minipage}{0.4\textwidth}
\begin{flushleft} \large
\emph{Author:}\\
Martijn \textsc{G\"{o}sgens}\\
0914954 
\end{flushleft}
\end{minipage}
~
\begin{minipage}{0.4\textwidth}
\begin{flushright} \large
\emph{Supervisor:} \\
S\'{a}ndor \textsc{Kolumb\'{a}n}\\ 
Stella \textsc{Kapodistria}
\end{flushright}
\end{minipage}\\[2cm]



{\large \today}\\[2cm] 


 

\vfill 

\end{titlepage} 

\begin{abstract}
	In this thesis, we model the lifetime of an asset as a Markov modulated fluid model (MMFM) and find a replacement policy minimizing the total discounted cost.
	We assume the cost of correctively repairing the asset is larger than the cost of preventively repairing it.
	At each transition of the Markovian environment, the fluid level instantaneously increases by a constant amount, where the amount depends on the origin and destination state of the Markovian environment.
	Numeric methods to compute the total discounted cost for a given stationary replacement policy and iteration methods to find the optimal replacement policy are presented.
	A method to estimate parameters of the MMFM from usage data of the asset is also presented.
\end{abstract}

\chapter*{Executive summary}
Often, the defect of an asset comes with additional costs.
This could be because the process halts, e.g. in the case of manufacturing machines, or because additional damage or loss occurs when the asset breaks, e.g. data loss when a computer breaks.
In these cases, performing preventive maintenance might save costs.

In this thesis, a method is derived that finds the optimal times to perform preventive maintenance.
The degradation of the asset was modeled by a Markov modulated fluid model.
This corresponds to an asset with the following characteristics:
\begin{itemize}
	\item There is a distinct set of activities that the asset is used for.
	\item The usage of the asset is recorded; at each time (in the past) it is known for what activity it is used.
	\item No schedule is known; it is not certain for which activity the asset will be used in the future.
	\item Maintenance restores the asset to a condition as good as new.
	\item When the asset is not maintained, the condition deteriorates over time (Negative aging).
	This is in contrary to assets that get more reliable over time.
	\item Optionally, the speed at which the asset wears out, depends on the activity it is being used for.
	\item Optionally, between certain (fixed) activities, the condition of the asset improves.
	For instance, when each time before a certain activity, the asset is inspected and partial maintenance is performed.
\end{itemize}

In order to use the presented method, certain parameters of the degradation model are needed.
With sufficient usage data and records of the time at which the asset broke, these parameters could be estimated using methods presented in this thesis.

We present the following approach to determine the times at which preventive maintenance should be performed:
\begin{itemize}
	\item First, control limits for the various activities must be calculated.
	These control limits could be interpreted in the following way:
	when the level of wear of the asset exceeds the control limit corresponding to a certain activity, the asset must be repaired before being used for that activity.
	\item When using the asset, data from its usage since the last repair are used to determine whether the asset should be repaired at each moment.
\end{itemize}







\tableofcontents

\mainmatter

\chapter{Introduction}\label{chapter:Introduction}
When an essential asset within an organization fails, this can have big consequences for the organization.
For instance, if the machine of a manufacturer breaks, the production may stop until it is (correctively) repaired.
Hence, it might be efficient to occasionally inspect and repair the machine before the machine breaks.
This motivates looking for preventive maintenance policies to plan such repairs.

Preventive maintenance problems can be classified based on various aspects.
First of all, there is the distinction between perfect and imperfect maintenance.
For perfect maintenance, the asset has the same lifetime distribution after maintenance as a new asset.
For imperfect maintenance, this is not always the case.
\cite{Pham1996} summarizes results for various preventive maintenance problems with imperfect maintenance.
Although imperfect maintenance might be more realistic in practice, we will assume perfect maintenance for simplicity.

Another distinction can be made based on the options for moments at which maintenance can be scheduled.
For simplicity, we assume that the machine is continuously monitored and we can decide to immediately repair the asset at any given time.
However, in practice, it might be that maintenance can only be done at some discrete planned or unplanned moments \cite{Kalosi2016}.

The goal of preventive maintenance is usually to optimize a certain goal function.
Chapter 4 of \cite{Zacks2012} discusses preventive maintenance aiming at maximizing the availability of assets.
In our problem definition, the cost of performing corrective maintenance exceeds that of preventive maintenance and we aim at minimizing the total (discounted) maintenance cost.

The solution to a preventive maintenance problem is a maintenance policy that prescribes when preventive maintenance should be performed.
These policies can be classified as either age-based or condition-based.
In age-based maintenance, the decision to perform preventive maintenance is done based only on the age of the machine.
Often, more aspects are observed that help predict the fitness of the asset.
When the decision to do preventive maintenance is based on other quantities than the age of the machine, this is called condition-based maintenance.
\cite{Kalosi2016} models the condition of the asset as a CTMC with a failure state and states corresponding to a perfect condition and a satisfactory condition.
The decision to perform preventive maintenance is then done based on the state the asset is in.
In this thesis, we will opt for an age-based maintenance policy that is dynamically adapted by observations of the asset.
Hence, this could be viewed as a hybrid between age-based maintenance and condition-based maintenance.

Various mathematical models have been developed to model the degradation of assets.
\cite{Derman1963} models the deterioration of the asset as a CTMC where there is a drift towards the failure state.
In this thesis, we will model the degradation of the asset as a Markov Modulated Fluid Model (Also known as a Markov modulated fluid queue or stochastic Fluid model) with jumps.

The research is motivated by the real-world problem of deciding when to repair a Philips manufacturing machine.
This machine produces a log that will be analyzed in this thesis.

The remainder of this thesis is organized as follows:
In chapter \ref{chapter:literatureOverview}, some concepts from the fields of dynamic programming and survival analysis are summarized.  
In chapter \ref{chapter:AgeBased}, a simple age-based preventive maintenance problem is addressed and methods to find the optimal maintenance policy are introduced.
This problem is extended in chapter \ref{chapter:SimpleFluid} to include jumps that instantaneously decrease the age of the machine by a constant.
We prove that this problem is equivalent to the age-based problem with an adjusted discount exponent.
In chapter \ref{chapter:Mmfm}, we change the degradation model to a MMFM with jumps.
Results from previous chapters are extended, resulting in a method to find the optimal preventive maintenance policy.
In chapter \ref{chapter:DataAnalysis}, the data of the Philips machine is analysed and in chapter \ref{chapter:ParameterEstimation}, a method is proposed to estimate the parameters of an MMFM given usage data.
Finally, the results are summarized and some directions for further research are presented.

 
\chapter{Literature overview}\label{chapter:literatureOverview}
In this chapter, some preliminaries will be summarized.
We will explain some useful results and concepts from the fields of Markov decision theory and survival analysis.

\section{Markov decision theory}
Markov Decision Theory provides the mathematical framework to make decisions based on a Markov model.
In a Markov Decision Process (MDP), the evolution of the process depends on the chosen control action.
The objective of an MDP is usually to minimize costs (or, equivalently, maximize profit) in some sense.

For a discrete MDP with state space $X$, when at the $k$'th decision epoch the process is in state $x_k\in X$, an action must be chosen out of a set $U(x_k)$ of allowed actions.
When the number of decision epochs that are considered is finite, the MDP is said to be a finite-horizon probem.
When the number of decision epochs is infinite, it is an infinite-horizon problem.
At every decision epoch, there is also some random variable $\omega_k$ which introduces the randomness in the process.
The process then evolves based on the current state $x_k$, the chosen action $u_k\in U(x_k)$ and this random parameter $\omega_k$ according to some function $f$, so that the next state of the process is determined by $x_{k+1}=f(x_k,u_k,\omega_k)$.
When an action $u_k\in U(u_k)$ in a state $x_k\in X$ is chosen, a cost $g(x_k,u_k)$ will be paid.
For infinite-horizon problems, the sum of the costs incurred over all decision epochs could be infinite.
This is often resolved by choosing a different aggregate of the costs as a goal function.
Often, this is done by either considering the long-run average cost per decision epoch, or by multiplying costs in decision epoch $k$ by $\alpha^k$, where $0<\alpha<1$ is a discount factor.
The latter cost is called the discounted cost.
In this thesis we will consider discounted costs.
This has the advantage over long-run average costs that the Bellman equations can be to solve the problem.

Admissible solutions to MDPs are policies that choose an allowed action for each decision epoch and state, i.e. for each $k$ there is some $\mu_k$ with $\mu_k(x_k)\in U(x_k)$ for all $k,x_k$.
A policy is said to be stationary if it does not depend on the decision epoch, i.e. there is one $\mu$ and for every $k$ $\mu_k=\mu$.
The aim of Markov decision theory is to find policies that choose action in each decision epoch and state so that the goal function is optimized.
Section 6.2.4 of \cite{Puterman2008} proves that for discounted infinite-horizon countable-state problems with cost-function $g$ independent of decision epoch $k$, there exists an optimal stationary policy.

In this thesis, we will aim at minimizing the total discounted cost for an infinite-horizon MDP, i.e. minimizing
\[
\mathbb{E}\left[\sum\limits_{k=0}^\infty \alpha^k g(x_k,\mu(x_k))\right],
\]
for some stationary policy $\mu$. 


\chapter{Age-based maintenance}\label{chapter:AgeBased}
An asset is considered that is subject to deterioration over time.
If no further observations are made, any choice to repair the asset can only be based on its age.
In this chapter we will investigate methods to find an optimal preventive maintenance policy in terms of total discounted cost.
\section{Problem formulation and definition}\label{section:AgeBasedDefinition}
In this section, the problem of choosing when to repair the asset is defined as a Markov decision process.
Calendar time is discretized in steps of size $\delta$, i.e. the $k$'th decision epoch is at time $t_k=k\delta$.
We refer to the interval $(k\delta,(k+1)\delta]$ as the $k$'th time interval.
At epoch $k\in\mathbb{N}\cup\{0\}$, we denote the state of the asset by $x_k\in X=\mathbb{N}_0$ and initially $x_0=1$.
When $x_k=x$, this means that after the $k$'th time interval, the asset has age $x\delta$.

The lifetime of the asset has a distribution function $F$.
We denote the reliability function by $\bar F(x):=1-F(x)$ and the conditional reliability function by $\bar F(x;y)=\frac{\bar F(x)}{\bar F(y)}$.
We assume that this distribution function is continuously differentiable so that the probability density function by $f$ and the hazard rate 
\[
h(x)=\frac{f(x)}{\bar F(x)}
\] 
are both continuous.

\subsection{Degradation model}
To model the degradation of the asset, we introduce random variables $\omega_k:=\omega_k(x_k)$ at decision epoch $k$ which only depend on $x_k$.
$$
\omega_k(x_k):=\begin{cases}
1,&\text{if the asset will reach age }\ \delta x_{k}\text{ given}\\
&\text{that it reached age}\ \delta(x_k-1)\ \text{ at time } t_k \\
0,&\text{otherwise}.
\end{cases}
$$
If the lifetimes of the asset are i.i.d. random variables with distribution $F$ then for $x>0$
$$
\mathbb{P}(\omega_k(x_k)=1)=\frac{1-F(\delta x_k)}{1-F(\delta (x_k-1))}.
$$

\subsection{Control actions}
At the $k$'th decision epoch, we shall choose an action $u_k$ from the action set $U(x_k)$.
Where
$$
U(x_k):=\begin{cases}
\{a_W,a_R\},&\text{if}\ x_k>0 \\
\{a_R\},&\text{if}\ x_k=0.
\end{cases}
$$
These actions are
\begin{itemize}
	\item $a_R$:
	Repair (or replace) the asset.
	\item $a_W$:
	Do nothing.
\end{itemize}

\subsection{State evolution}
During a time interval, a few things can happen:
\begin{itemize}
	\item If the asset is repaired, its age will be $\delta$ at the next stage.
	\item If the asset fails, its age will be $0$ at the next stage.
	\item If the asset does not fail and no repair is done, the age of the asset will increase by $\delta$.
\end{itemize}
Hence, the state evolves in the following way
$$
x_{k+1}=f(x_k,u_k,\omega_k):=\begin{cases}
1,&\text{if}\ u_k=a_R \\
0,&\text{if}\ u_k=a_W\ \text{and}\ \omega_k=0 \\
x_k+1,&\text{if}\ u_k=a_W\ \text{and}\ \omega_k=1.
\end{cases}
$$
For convenience, we define the random variable $S(x_k):=f(x_k,a_W,\omega_k(x_k))$ to denote the age of the asset one time interval after it was $x_k$.
Note that in the above definition, repairing the asset takes exactly one time interval.

\subsection{Costs and discounting}
Preventively repairing the asset has a cost $c>0$.
When the asset needs to be repaired correctively, an additional cost $a>0$ needs to be paid.
Hence, when the process is in state $x_k$ and the action $u_k$ is chosen, the following cost is incurred
$$
g(x_k,a_k):=\begin{cases}
c+a,&\text{if}\ x_k=0 \\
c,&\text{if}\ x_k>0\ \text{and}\ u_k=a_R \\
0,&\text{else}.
\end{cases}
$$
Furthermore, a discount $\alpha_\delta$ is introduced such that costs $n$ decision stages in the future are discounted by $\alpha_\delta^n$.
In the rest of the thesis, we will use a discount factor
$$
a_\delta=e^{-\beta\delta}
$$
for some discount rate $\beta>0$.
We consider the expected total discounted cost from decision epoch $k$ on
$$
V_\delta(x_k;k)=\sum\limits_{m=k}^\infty \alpha_\delta^{m-k}g(x_m,u_m).
$$


\subsection{Optimal stationary policy and the Bellman equations}
As the problem as defined above is a Markov decision process with $g$ independent of the decision epoch, there exists an optimal stationary policy \cite{Puterman2008}.
Hence, we want to find a stationary policy $\mu:X\rightarrow \{a_W,a_R\}$ that chooses the action $u_k=\mu(x_k)$ that minimizes the expected total discounted cost $V_\delta(x_0,\mu)$.
For a policy $\mu$, $V_\delta(x_k,\mu)$ is given by
$$
V_\delta(x_k,\mu)=g(x_k,\mu(x_k))+\alpha_\delta \mathbb{E}[V_\delta(f(x_k,\mu(x_k),\omega_k(x_k)),\mu)].
$$
The Bellman equations for the optimal cost $V^*_\delta$ read
\begin{equation}\label{eq:AgeBasedBellman}
V^*_\delta(x_k)=\begin{cases}
\min\{c+\alpha_\delta V^*_\delta(1),\alpha_\delta \mathbb{E}[V^*_\delta(S(x_k))]\},&\text{if}\ x_k>0 \\
c+a+\alpha_\delta V^*_\delta(1),&\text{else.}
\end{cases}
\end{equation}
Under the optimal policy, the total discounted cost $V_\delta(x_k,\mu;k)=V^*_\delta(x_k)$ for all $x_k,k$.
Since we only consider stationary policies, the $k$ will also be suppressed in the notation of $V_\delta(x_k,\mu)$.

\subsection{Continuous-time MDP}
In the remainder of the chapter, we will consider a continuous-time MDP that is obtained by letting $\delta\rightarrow0$.
We will occasionally return to the discrete MDP to prove certain properties.
For small $\delta$ the discount $\alpha_\delta$ is given by
\[
\alpha_\delta=1-\delta\beta+o(\delta^2).
\]
When action $a_W$ is chosen, at age $x_k$, the transition probabilities become
$$
\mathbb{P}(\omega_k(x_k)=1)=\frac{1-F(\delta x_k)}{1-F(\delta (x_k-1))}=1-\delta h(\delta x_k)+o(\delta^2),
$$
and
\[
\mathbb{P}(\omega_k(x_k)=0)=\frac{F(\delta x_k)-F(\delta (x_k-1))}{1-F(\delta (x_k-1))}=\delta h(\delta x_k)+o(\delta^2).
\]
This hazard rate $h$ is assumed to be increasing.
For the value functions, we will write $V^*(x):=\lim\limits_{\delta\rightarrow0}V_\delta^*(\lfloor x/\delta\rfloor)$ and similarly $V(x,\mu):=\lim\limits_{\delta\rightarrow0}V_\delta(\lfloor x/\delta\rfloor,\mu)$.
Moreover $V^*(0^+):=\lim\limits_{\delta\rightarrow0}V_\delta^*(1)$.
Note that we have to write $V^*(0^+)$ instead of $V^*(0)$ for a new asset as the latter corresponds to the asset being broken.

\subsection{Alternative models}
The problem can be formalized in many different ways.
We will briefly show some alternatives to the modeling choices that were made in the above problem definition.
\subsubsection{Instantaneous repairs}
If we would want to make repairs take zero time, we would have to change the definition of $x_{k+1}$ to 
$$
x_{k+1}=f_2(x_k,u_k,\omega_k):=\begin{cases}
0,&\text{if}\ \omega_k=0 \\
2,&\text{if}\ u_k=a_R\ \text{and}\ \omega_k=1\\
x_k+1,&\text{if}\ u_k=a_W\ \text{and}\ \omega_k=1.
\end{cases}
$$
This would however, introduce the possibility of having to correctively repair the asset twice in a row.
However, when we let $\delta\rightarrow 0$, this would not make any difference.

\subsubsection{Stochastic inter-decision times}
Another possibility would be to have positive random i.i.d. inter-decision times $\Delta_k$ and to use a continuous discount such that costs at time $t$ are discounted by $e^{-\beta t}$ for $\beta>0$.
The state space could then be modeled as $X=\mathbb{R}_0^+\cup\{x_{BREAK}\}$ where $x_{BREAK}$ is the state where the asset is broken.
The state evolution would be as follows:

$$
x_{k+1}=f(x_k,u_k,\omega_k,\Delta_k):=\begin{cases}
\Delta_k,&\text{if}\ u_k=a_R \\
x_f,&\text{if}\ u_k=a_W\ \text{and}\ \omega_k=0 \\
x_k+\Delta_k,&\text{if}\ u_k=a_W\ \text{and}\ \omega_k=1.
\end{cases}
$$
The Bellman equations should then be changed to
$$
V^*(x_k)=\begin{cases}
\min\{c+\mathbb{E}[e^{-\beta \Delta} V^*(\Delta)],\mathbb{E}[e^{-\beta \Delta} V^*(f(x_k,a_W,\omega_k,\Delta))],&\text{if}\ x_k\neq x_f \\
c+a+\mathbb{E}[e^{-\beta \Delta} V^*(\Delta)],&\text{else.}
\end{cases}
$$
Where repair would again take one inter-decision time. Where $\Delta$ is of the same family of i.i.d. random variables as the $\Delta_i$'s.

%
 \section{Structure of optimal policy}
In this section, we will establish that for the age-based maintenance problem, the optimal policy is a stationary control limit policy.
This means that repair is chosen if and only if the age has exceeded a certain threshold $\mu^*$ (the control limit).
If no repair is chosen, then we set $\mu^*=\infty$.

\subsection{Stationary policy}\label{section:AgeBasedStationaryPolicy}
\cite{Puterman2008} proves that for a discounted infinite-horizon countable-state MDP where the cost function does not depend on the decision stage, there exists a stationary policy that is optimal.
This proves that there exists an optimal stationary policy to this age-based preventive maintenance policy.

\subsection{Control limit}\label{section:AgeBasedControlLimit}
From the Bellman equations \eqref{eq:AgeBasedBellman} we can see that, by letting $\delta\rightarrow 0$, repair is for chosen $x>0$ whenever
\begin{equation}\label{eq:AgeBasedRepairCondition}
 c+\alpha V^*(0^+) \leq V^*(x). 
 \end{equation}
Now we can distinguish two cases:
\begin{enumerate}
	\item There is no age $x$ that satisfies \eqref{eq:AgeBasedRepairCondition} and preventive repair is never the optimal choice.
	In this case we set control limit $\mu^*=\infty$.
	\item There are ages $x_1,x_2,...$ that satisfy \eqref{eq:AgeBasedRepairCondition}.
	The control limit will now simply be the smallest such age.
	What happens for ages greater than this $\mu^*$ is not relevant as these will never be reached.
\end{enumerate}
Later in this chapter, we will prove that the right hand side of \eqref{eq:AgeBasedRepairCondition} is increasing for $x<\mu^*$.
Hence, we have established that the optimal policy must be of control limit type where the asset is repaired whenever its age exceeds some threshold $\mu^*$. \section{Computation of total discounted cost}
In this section, the Bellman equations will be used to find the expected total discounted cost of the optimal cost.
From the discrete Bellman equations \eqref{eq:AgeBasedBellman}, differential equations will be derived.
The following Bellman equations will be considered
\[V_\delta^*(x)=\begin{cases}
\min\{c+\alpha_\delta V^*_\delta(1),\alpha_\delta \mathbb{E}[V^*_\delta(S(x))]\},&\text{if}\ x>0 \\
c+a+\alpha_\delta V^*_\delta(1),&\text{else.}
\end{cases}\]
We assume that for $x$
$$
c+\alpha_\delta V^*_\delta(0^+)>\alpha_\delta \mathbb{E}[V^*_\delta(S(x)\delta)],
$$
i.e. the optimal control limit $\mu^*>\delta x$.
Now, we can write $V^*_\delta(x)$ in the following way
\[V^*_\delta(x)=\alpha_\delta \bar F(x;x-\delta) (c+a+\alpha_\delta V^*_\delta(0^+))
+\alpha_\delta \bar F(x;x-\delta)V^*_\delta(x+\delta)
\]
We are now going to let $\delta$ approach zero.
\begin{equation}
\begin{split}
\lim\limits_{\delta\rightarrow 0} V_\delta^*(x) &=
\lim\limits_{\delta\rightarrow 0}(1-\beta\delta+o(\delta^2)) (\delta h(x)+o(\delta^2))(c+a+(1-\beta\delta+o(\delta^2)) V^*_\delta(0^+))\\
&+(1-\beta\delta+o(\delta^2)) (1-\delta h(x)+o(\delta^2))V_\delta^*(x+\delta).
\end{split}
\end{equation}
Gathering the terms of $o(\delta^2)$, we get
\begin{equation}\label{eq:gatheredDelta}
\begin{split}
\lim\limits_{\delta\rightarrow 0} V_\delta^*(x) =
\lim\limits_{\delta\rightarrow 0}\delta h(x)(c+a+ V_\delta^*(0^+))+(1-\delta\beta-\delta h(x)) V_\delta^*(x+\delta)+o(\delta^2).
\end{split}
\end{equation}
By moving one $V_\delta^*(x+\delta)$ to the left and dividing by $-\delta$, we get
\begin{equation}\label{eq:AgeBasedBellmanODE}
\begin{split}
\frac{d}{dx}V^*(x)&=\lim\limits_{\delta\rightarrow 0} \frac{V_\delta^*(x+\delta)-V_\delta^*(x)}{\delta} \\
&=\lim\limits_{\delta\rightarrow 0} -h(x)(c+a+ V_\delta^*(0^+))+(\beta+ h(x)) V_\delta^*(x+\delta)+o(\delta)\\
&=-h(x)(c+a+ V^*(0^+))+(\beta+ h(x)) V^*(x).
\end{split}
\end{equation}
\begin{remark}\label{remark:AgeBasedWeirdODE}
	The differential equation \eqref{eq:AgeBasedBellmanODE} seems counterintuitive as for high hazard rates, the expected total discounted cost would be decreasing for increasing age of the asset.
	We will return to this later on.
\end{remark}
We will now try to solve this O.D.E.
We use the method of the integrating factor.
Our integrating factor will be
$$
e^{\int\limits_0^x (-\beta - h(q))dq}=e^{-\beta x -H(x)}.
$$
Where $H(x)$ is the cumulative hazard function.
We get
$$
V^*(x)=e^{\beta x +H(x)} [C + \int\limits_0^x e^{-\beta q -H(q)}(-h(q)(c+a+V^*(0^+)))dq]
$$
$$
=\frac{e^{\beta x}}{\bar F(x)} [C - (c+a+V^*(0^+))\int\limits_0^x e^{-\beta q}f(q)dq].
$$
Using the identities 
\[e^{H(x)}=(e^{-H(x)})^{-1}=\frac{1}{\bar F(x)},\]
and
\[h(x)e^{-H(x)}=f(x).\]
$C$ is an integrating constant and since $\lim\limits_{x\rightarrow 0}V^*(x)=V^*(0^+)$ should hold, we find $C=V^*(0^+)$.
We can rewrite the expression to
$$
V^*(x)=\frac{e^{\beta x}}{\bar F(x)} [V^*(0^+)  - (c+a+V^*(0^+))F(x)\mathbb{E}[e^{-\beta Q_0}|Q_0<x]].
$$
Which results in the following theorem:
\begin{theorem}
	When the asset has age $x$, the expected remaining total discounted cost equals
	\begin{equation}\label{eq:AgeBasedSolvedBellman}
	\begin{split}
	V^*(x)=\min\{&c+V^*(0^+),\\
	&\frac{ e^{\beta x}}{\bar F(x)} [V^*(0^+) - (c+a+V(0^+))F(x)\mathbb{E}[e^{-\beta Q_0}|Q_0<x]]
	\}
	\end{split}
	\end{equation}
	and preventive maintenance is chosen if and only if $V^*(x)\geq c+V^*(0^+)$.
\end{theorem}
Unfortunately, the value of $V^*(0^+)$ depends on the optimal policy and it is also difficult to solve $V^*(x)=c+V(0^+)$ analytically for $x$.
Control limit $\mu^*$ is then chosen as the smallest positive $x$ that satisfies $V(x)=c+V(0^+)$ if such $x$ exist and $\mu^*=\infty$ else.
The policy that we just derived, schedules preventive maintenance at time $\mu^*$ if the asset has not already failed by then.
We denote the total discounted cost of this policy by $V(0^+,\mu^*)$.

For any (possibly sub-optimal) control limit $\mu$, we can derive the expected remaining total discounted cost.
The length of one run of the asset is the minimum of its lifetime $Q_0\sim F$ and the chosen control limit $\mu$.
At the end of each run, at least $c$ is paid.
If the run ends because the asset broke (i.e. $Q_0<\mu$), an additional cost of $a$ is paid.
Hence, we get the following expression for $V(0^+,\mu)$
\begin{equation}\label{eq:AgeBasedPolicyTDC}
V(0^+,\mu)=aF(\mu)\mathbb{E}[e^{-\beta Q_0}|Q_0\leq \mu]+(c+V(0^+,\mu))\mathbb{E}[e^{-\beta(Q_0\wedge\mu)}].
\end{equation}
Where $A\wedge B$ denotes the minimum af $A$ and $B$.
We get a similar expression for $V(x,\mu)$:

\begin{theorem}
	Given control limit $\mu$ and an asset of age $x$, the expected remaining total cost equals 
	\begin{equation}\label{eq:AgeBasedPolicyRemainingTDC}
	V(x,\mu)=aF(\mu;x)\mathbb{E}[e^{-\beta Q_0}|x<Q_0\leq \mu]+(c+V(0^+,\mu))\mathbb{E}[e^{-\beta(Q_0\wedge\mu)}|Q_0>x].
	\end{equation}
\end{theorem}

\begin{remark}
	By taking the derivative of \eqref{eq:AgeBasedPolicyRemainingTDC}, one can see that this also adheres to the differential equation \eqref{eq:AgeBasedBellmanODE} that resulted from the Bellman equations.
\end{remark}

\begin{remark}
	In theorem \ref{theorem:TdcNonDecreasing}, we will prove that for increasing hazard rates, $V(x,\mu)$ is increasing for $x<\mu$.
\end{remark}

\begin{remark}
	\eqref{eq:AgeBasedPolicyTDC} can also be rewritten to get an explicit expression for $V(0^+,\mu)$:
	\begin{equation}\label{eq:AgeBasedOptimalTDC}
	V(0^+,\mu)=\frac{aF(\mu)\mathbb{E}[e^{-\beta Q_0}|Q_0\leq \mu]+c\mathbb{E}[e^{-\beta(Q_0\wedge\mu)}]}{1-\mathbb{E}[e^{-\beta (Q_0\wedge\mu)}]}.
	\end{equation}
\end{remark}

\begin{remark}
	If $\mu^*=\infty$, then the expected total discounted cost equals
	\[V(0^+,\infty)=\mathbb{E}[e^{-\beta Q_0}](c+a+V(0^+,\infty)).\]
	Which can be rewritten to
	\[V(0^+,\infty)=\frac{\tilde{F}(-\beta)}{1-\tilde{F}(-\beta)}(c+a),\]
	where $\tilde{F}$ is the moment generating function of $Q_0$.
\end{remark}

\begin{example}
	Let $Q_0\sim\text{Exp}(\lambda)$.
	Because of the memoryless property, we would expect $V(x,\mu^*)$ to be constant.
	Filling this in into \eqref{eq:AgeBasedBellmanODE}, we get
	
	\[
	\begin{split}
	0&=\frac{d}{dx}V(x,\mu^*)\\
	&=-\lambda(c+a+ V(0^+,\mu^*))+(\beta+ \lambda) V(x,\mu^*)\\
	&=-\lambda(c+a+ V(0^+,\mu^*))+(\beta+ \lambda) V(0^+,\mu^*).
	\end{split}
	\]
	Where the last equality holds as $V(x,\mu^*)$ is constant.
	This can be rewritten to
	$$
	V(0^+,\mu^*)=\frac{\lambda}{\beta}(c+a)
	$$
	which equals exactly the total discounted cost for control limit $\mu^*=\infty$.
\end{example} \section{Analysis of the optimal policy}\label{section:AgeBasedOptimalPolicy}
Instead of finding the optimal control limit $\mu^*$ by solving the Bellman equations, we can also minimize $V(0^+,\mu)$ by looking for critical points of the expected total discounted cost.
Although we could use \eqref{eq:AgeBasedPolicyTDC} for the total discounted cost, we will use a slightly different formula to simplify the analysis.
Instead of using $V(0^+,\mu)$ on the right hand side of \eqref{eq:AgeBasedPolicyTDC}, we will use $V(0^+,\mu^*)$.
This corresponds to minimizing the expected total discounted cost for an asset using control limit $\mu$ in the first run and optimal control limit $\mu^*$ afterwards.
Obviously, this would be minimized by $\mu=\mu^*$.
We will look at critical points of
\begin{equation}\label{eq:AgeBasedHatTDC}
\hat{V}(0^+,\mu)=aF(\mu)\mathbb{E}[e^{-\beta Q_0}|Q_0\leq \mu]+(c+V(0^+,\mu^*))\mathbb{E}[e^{-\beta(Q_0\wedge\mu)}].
\end{equation}
Note that 
\[
F(\mu)\mathbb{E}[e^{-\beta Q_0}|Q_0\leq \mu]=\mathbb{E}[\mathds{1}\{Q_0\leq \mu\}e^{-\beta Q_0}]=\int\limits_0^\mu f(x)e^{-\beta x}dx
\]
So that
\[
\frac{d}{d\mu}\left[F(\mu)\mathbb{E}[e^{-\beta Q_0}|Q_0\leq \mu]\right]=f(\mu)e^{-\beta \mu}.
\]
Furthermore,
\[
\begin{split}
&\mathbb{E}[e^{-\beta(Q_0\wedge\mu)}]=\int\limits_0^\mu f(x)e^{-\beta x}dx+\bar{F}(\mu)e^{-\beta\mu}\\
&\Rightarrow \frac{d}{d\mu}\mathbb{E}[e^{-\beta(Q_0\wedge\mu)}]=-\beta\bar{F}(\mu)e^{-\beta\mu}.
\end{split}
\]
So that taking the derivative of \eqref{eq:AgeBasedHatTDC} yields
\[\frac{d}{d\mu}\hat{V}(0^+,\mu)=af(\mu)e^{-\beta\mu}-(c+V(0^+,\mu^*))\beta\bar{F}(\mu)e^{-\beta\mu}.\]
We are interested in the zeroes of this derivative:
\[
\begin{split}
&af(\mu)e^{-\beta\mu}-(c+V(0^+,\mu^*))\beta\bar{F}(\mu)e^{-\beta\mu}=0\\
&\Rightarrow h(\mu)=\frac{f(\mu)}{\bar{F}(\mu)}=\beta\frac{c+V(0^+,\mu^*)}{a}
\end{split}
.\]
Note that the right hand side of this equation is a constant and the left hand side is increasing by assumption.
Hence, there is at most one $\mu$ that satisfies the above equation.
From the above bounds it can also be seen that $\hat{V}(0^+,\mu)$ is decreasing when $h(\mu)$ is smaller than this constant and increasing when it is larger.
We will now establish that if there is one $\mu$ that satisfies the equation above, it is also the global minimum of $\hat{V}(0^+,\mu)$:
\begin{lemma}\label{lemma:AgeBasedControlLimit}
	If there is a $\hat{\mu}$ that satisfies
	\begin{equation}\label{eq:AgeBasedHazardBound}
	h(\hat{\mu})=\beta\frac{c+V(0^+,\mu^*)}{a},
	\end{equation}
	then this $\hat{\mu}$ is the optimal control limit.
	\begin{proof}
		From the previous derivation, it follows that this $\hat{\mu}$ is a stationary point of $\hat{V}(0^+,\mu)$.
		Since $h$ is increasing by assumption, we know that
		\begin{itemize}
			\item $\mu<\hat{\mu}\Rightarrow h(\mu)<h(\hat{\mu})$ so that $\frac{d}{d\mu}\hat{V}(0^+,\mu)<0$.
			\item $\mu>\hat{\mu}\Rightarrow h(\mu)>h(\hat{\mu})$ so that $\frac{d}{d\mu}\hat{V}(0^+,\mu)>0$.
		\end{itemize}
		Which establishes that $\hat{\mu}$ is the global minimum of $\hat{V}(0^+,\mu)$.
		Concluding the control limit $\hat{\mu}$ that satisfies \eqref{eq:AgeBasedHazardBound} equals the optimal control limit $\mu^*$.
	\end{proof}
\end{lemma}
\begin{corollary}
	From \eqref{eq:AgeBasedHazardBound} and the fact that $\hat{V}(0^+,\mu)$ is decreasing at $\mu=0$, it follows that
	\[
	h(0)<\beta\frac{c+V(0^+,\mu^*)}{a}.
	\]
\end{corollary}
\begin{corollary}
If for all $\mu>0$
\[
h(\mu)<\beta\frac{c+V(0^+,\mu^*)}{a},
\]
then $\hat{V}(0^+,\mu)$ is strictly decreasing and has an asymptotic minimum, concluding $\mu^*=\infty$.
Note that this also implies that for decreasing hazard rates $\mu^*=\infty$.
\end{corollary}

\begin{remark}
	Using the Bellman equations, it can also be proven without the assumption of an increasing hazard rate that if there is an optimal control limit $\mu^*$, $\mu^*$ must satisfy \eqref{eq:AgeBasedHazardBound} and the hazard rate must be increasing at $\mu^*$.
	For a proof of this, we refer to appendix \ref{AppendixAgeBasedControlLimit}.
\end{remark}

	Returning to remark \ref{remark:AgeBasedWeirdODE}:
	The differential equation \eqref{eq:AgeBasedBellmanODE} seemed counterintuitive as the total discounted cost would be decreasing for high hazards.
	
	Consider the cost of one run of the asset, we replace the repair cost by $c^*=c+V(0^+,\mu^*)$ so that the expected discounted cost of the first repair equals the expected total discounted cost of the original problem.
	$V(x,\mu^*)$ now corresponds to the cost of this altered problem, but starting with an asset of age $x$.
	If $V(x,\mu^*)$ were to be decreasing in the neighborhood of some $x$, this would mean that for that $x$, the problem would have a lower expected optimal cost if we started with a slightly older asset.
	This seems to conflict with the assumption that $h$ is increasing so that the asset deteriorates over time.
	However, we can prove that $V(x,\mu^*)$ is increasing for $x<\mu^*$:

\begin{theorem}\label{theorem:TdcNonDecreasing}
	The expected total discounted cost \eqref{eq:AgeBasedPolicyRemainingTDC} is increasing for $x< \mu^*$, i.e.
	\[
	\frac{d}{dx}V(x,\mu^*)> 0.
	\]
	\begin{proof}
		We will prove that $\frac{d}{dx}V(x,\mu^*)\leq0$ for some $x$ implies $\frac{d^2}{dx^2}V(x,\mu^*)<0$ so that $V(x,\mu^*)$ remains decreasing and will eventually be negative, contradicting the fact that all costs are positive.
		
		Let $x'<\mu^*$, it holds that
		\[
		V(x',\mu^*)\leq V(\mu^*,\mu^*)=c+V(0^+,\mu^*).
		\]
		Now we will prove that if $\frac{d}{dx}V(x',\mu^*)\leq 0$, this implies that $\frac{d^2}{dx^2}V(x',\mu^*)<0$.
		We take the derivative of \eqref{eq:AgeBasedBellmanODE}:
		\[
		\frac{d^2}{dx^2}V(x,\mu^*)=-h'(x)[c+a+V(0^+,\mu^*)-V(x,\mu^*)]+(\beta+h(x))\frac{d}{dx}V(x,\mu^*).
		\]
		Note that, in order to take the derivative of $h$, we have to assume that $h$ (or equivalently $f$) is differentiable.
		We know that for our $x'$, $\frac{d}{dx}V(x,\mu^*)\leq 0$ and $V(x,\mu^*)\leq c+V(0^+,\mu^*)$.
		Furthermore, by assumption $h'(x')>0$.
		Concluding
		\[
		\frac{d^2}{dx^2}V(x',\mu^*)<0.
		\]
		This implies that if $\frac{d}{dx}V(x',\mu^*)\leq0$ for some $x'$, $V(x,\mu^*)$ is concave down after $x'$ so that for all $x>x'$
		\[
		V(x,\mu^*)< c+V(0^+,\mu^*).
		\]
		Hence no control limit will ever be reached and $V(x,\mu^*)$ will eventually become negative.
		This contradicts the fact that all costs are positive so that it is proven that for increasing hazard rates, $V(x,\mu^*)$ is nondecreasing for $x\leq\mu^*$.
	\end{proof}
\end{theorem}

\begin{corollary}
	The remaining discounted cost $V(x,\mu^*)$ has the following lower bound:
	\[
	V(x,\mu^*)\geq\frac{h(x)}{\beta+ h(x)}(c+a+ V(0^+,\mu^*)).
	\]
	\begin{proof}
		By theorem \ref{theorem:TdcNonDecreasing}, $\frac{d}{dx}V(x,\mu^*)\geq 0$ holds.
		The lower bound then follows from the differential equation of $V(x,\mu^*)$ \ref{eq:AgeBasedBellmanODE}.
	\end{proof}
\end{corollary} \section{Policy iteration}\label{section:AgeBasedOptimalPolicyComputation}
We know that for the optimal policy $\mu^*$, \eqref{eq:AgeBasedHazardBound} holds.
This allows us to choose a control limit based on the total discounted cost.
Unfortunately, the total discounted cost also depends on the control limit.
Multiple numerical methods could be used to find the optimal control limit.
In this section we propose a policy iteration method to find the optimal control limit and the total discounted cost.
Alternatively, value iteration could be used to solve the Bellman equations or the expected total discounted cost \eqref{eq:AgeBasedPolicyTDC} could simply be minimized numerically for $\mu$.

\subsection{Description of iteration method}\label{section:AgeBasedIterationDescription}
We know that if a control limit $\hat{\mu}$ satisfies
\[h(\hat{\mu})=\beta\frac{c+V(0^+,\mu^*)}{a},\]
then $\hat{\mu}=\mu^*$.
At the $k+1$'th iteration, we will update the estimate of the optimal control limit $\mu^*$ by finding the $\hat{\mu}^{(k+1)}$ that minimizes
\[
aF(\hat{\mu}^{(k+1)})\mathbb{E}[e^{-\beta Q_0}|Q_0\leq \hat{\mu}^{(k+1)}]+(c+\hat{V}^{(k)})\mathbb{E}[e^{-\beta(Q_0\wedge\hat{\mu}^{(k+1)})}],
\]
where $\hat{V}^{(k)}$ is the current estimate of $V(0^+,\mu^*)$.
This could be found by looking for the control limit that satisfies
\begin{equation}\label{eq:AgeBasedIterationBound}
h(\hat{\mu}^{(k+1)})=\beta\frac{c+\hat{V}^{(k)}}{a}.\end{equation}
For convenience, we define the function $\mu(\hat{V}^{(k)}):=\hat{\mu}^{(k+1)}$.
Note that by lemma \ref{lemma:AgeBasedControlLimit}
\begin{equation}\label{eq:AgeBasedIterationControlConvergence}
\mu(V(0^+,\mu^*))=\mu^*.
\end{equation}
The estimation of the expected total discounted cost will be updated in the following way:
\[\hat{V}^{(k+1)}=aF(\hat{\mu}^{(k+1)})\mathbb{E}[e^{-\beta Q_0}|Q_0\leq \hat{\mu}^{(k+1)}]+(c+\hat{V}^{(k)})\mathbb{E}[e^{-\beta(Q_0\wedge\hat{\mu}^{(k+1)})}].\]
We define an operator $T$ to denote one iteration for the estimate of the expected total discounted cost:
\[T(\hat{V}^{(k)}):=\hat{V}^{(k+1)}.\]
Similarly:
\[T^m(\hat{V}^{(k)})=\hat{V}^{(k+m)}.\]
Note that $T^m(V(0^+,\mu^*))=V(0^+,\mu^*)$.
For this iteration, we need an initial value of the expected total discounted cost $\hat{V}^{(0)}$.
This iteration can be interpreted in the following way:
If the asset were to run just once and at the end of the run (so either after paying $c$ or $c+a$ for preventive or corrective repair respectively), a cost $\hat{V}^{(k)}$ will be paid, then $\hat{\mu}^{(k+1)}$ will be the control limit that minimizes the expected total discounted cost for this scenario.
In this way, we can interpret $\hat{V}^{(k)}$ as the expected total discounted cost when in the first run $\hat{\mu}^{(k)}$ will be used as the control limit, $\hat{\mu}^{(k-1)}$ will be used as control limit in the second run, etcetera, $\hat{\mu}^{(1)}$ in the last run and afterwards the terminal cost $\hat{V}^{(0)}$ will be paid.

\subsection{Proof of convergence}
The convergence of the proposed iteration method will now be proven.
Let $\alpha_\mu=\mathbb{E}[e^{-\beta (Q_0\wedge\mu)}]$ denote the expected discount over one run of the asset using control limit $\mu$.
The expected cost that is incurred in one  run when control limit $\mu$ is used equals
$$
g(\mu):=aF(\mu)\mathbb{E}[e^{-\beta Q_0}|Q_0\leq \mu]+c\mathbb{E}[e^{-\beta(Q_0\wedge\mu)}].
$$
We can now write
$$
V(0^+,\mu^*)=\sum\limits_{n=0}^\infty \alpha_{\mu^*}^kg(\mu^*).
$$
And we can rewrite $T$ in the following way
\[
T(V)=g(\mu(V))+\alpha_{\mu(V)}V.
\]
Note that $\alpha_\mu$ is decreasing in $\mu$ since $\frac{d}{d\mu}\alpha_\mu=-\beta\bar F(\mu)e^{-\beta \mu}<0$.
For technical reasons, we have to assume that for all $\hat{V}^{k}$, $\mu(\hat{V}^{k})\geq\varepsilon>0$.
In practice, this is not a big problem since we know that $\mu^*>0$ as $\lim\limits_{\mu\rightarrow 0}V(0^+,\mu)=\infty$.
Hence we can pick a $\varepsilon$ sufficiently small so that we are convinced that $\varepsilon<\mu^*$ and just adjust the definition of $\mu(\hat{V}^{(k)})$ to the maximum of $\varepsilon$ and $\mu(\hat{V}^{(k)})$.
For $T$, we will prove the following properties:
\begin{lemma}\label{lemma:Tproperties}
	For $A_1,A_2$ such that $A_1\geq A_2\geq 0$: 
	\begin{enumerate}
		\item $T(A_1+A_2)\leq TA_1+\alpha_\varepsilon A_2$,
		\item $T(A_1)\geq T(A_2)$,
		\item $T(A_1-A_2)\geq TA_1-\alpha_\varepsilon A_2$.
	\end{enumerate}
	\begin{proof}
		\begin{enumerate}
			\item 
			\begin{equation}
			\begin{split}
			T(A_1+A_2)&=g(\mu(A_1+A_2))+\alpha_{\mu(A_1+A_2)}(A_1+A_2)\\
			&\leq g(\mu(A_1))+\alpha_{\mu(A_1)}(A_1+A_2)\\
			&\leq g(\mu(A_1))+\alpha_{\mu(A_1)}A_1+\alpha_\varepsilon A_2\\
			&=TA_1+\alpha_\varepsilon A_2
			\end{split}
			\end{equation} 
			where the first inequality follows from the fact that $\mu(A_1+A_2)$ minimizes $g(\mu)+\alpha_\mu (A_1+A_2)$ and the second from the fact that $a_\varepsilon>a_{\mu(A_1+A_2)}$.
			\item 
			\begin{equation}
			\begin{split}
			T(A_2)&=g(\mu(A_2))+\alpha_{\mu(A_2)}A_2\\
			&\leq g(\mu(A_1))+\alpha_{\mu(A_1)}A_2\\
			&\leq g(\mu(A_1))+\alpha_{\mu(A_1)}A_1\\
			&=T(A_1)
			\end{split}
			\end{equation}
			where the first inequality follows from the fact that $\mu(A_2)$ minimizes $g(\mu)+\alpha_\mu A_2$ and the second from $A_1\geq A_2$.
			\item 
			\begin{equation}
			\begin{split}
			T(A_1-A_2)&=g(\mu(A_1-A_2))+\alpha_{\mu(A_1-A_2)}(A_1-A_2)\\
			&\geq g(\mu(A_1-A_2))+\alpha_{\mu(A_1-A_2)}A_1 - \alpha_\varepsilon A_2\\
			&\geq g(\mu(A_1))+\alpha_{\mu(A_1)}A_1-\alpha_\varepsilon A_2\\
			&=TA_1-\alpha_\varepsilon A_2
			\end{split}
			\end{equation}
			where the first inequality follows from $a_\varepsilon>a_{\mu(A_1-A_2)}$ and the second from the fact that $\mu(A_1)$ minimizes $g(\mu)+\alpha_\mu A_1$.
		\end{enumerate}
	\end{proof}
\end{lemma}
Note that $g(\mu)<c+a$ for all $\mu$ so that 
$$
V(0^+,\mu^*)=\sum\limits_{n=0}^\infty \alpha_{\mu^*}^kg(\mu^*)\leq \sum\limits_{n=0}^\infty \alpha_\varepsilon^k(c+a)=\frac{c+a}{1-\alpha_\varepsilon}.
$$
If our initial $0\leq \hat{V}^{(0)}<B$, then the following inequality now holds
$$
V(0^+,\mu^*)-\frac{c+a}{1-\alpha_\varepsilon}\leq 0\leq \hat{V}^{(0)}\leq B\leq V(0^+,\mu^*)+B.
$$
If we now apply $T$ $k$ times on this inequality, we get
\[\begin{split}
V(0^+,\mu^*)-\alpha_\varepsilon^k\frac{c+a}{1-\alpha_\varepsilon} &\leq T^k(V(0^+,\mu^*)-\frac{c+a}{1-\alpha_\varepsilon})\\
&\leq  T^k\hat{V}^{(0)}=V_k\\
&\leq T^k(V(0^+,\mu^*)+B) \\
&\leq V(0^+,\mu^*)+\alpha_\varepsilon^kB.
\end{split}\]
Where the first and last inequalities follow from Lemma \ref{lemma:Tproperties}.
This proves that $\hat{V}^{(k)}$ converges.
Convergence in $\hat\mu^{(k)}$ follows from \eqref{eq:AgeBasedIterationControlConvergence}.
Concluding:
\begin{theorem}
	The policy iteration method as described in section \ref*{section:AgeBasedIterationDescription} converges, i.e.
	\[\lim\limits_{k\rightarrow\infty}\hat{V}^{(k)}=V(0^+,\mu^*),\]
	and
	\[\lim\limits_{k\rightarrow\infty}\hat{\mu}^{(k)}=\mu^*.\]
\end{theorem} \section{Structural properties}\label{section:AgeBasedStructuralProperties}
In this section, the effect of changing problem parameters is investigated.

\subsection{Effect on control limit}
From \eqref{eq:AgeBasedHazardBound}, we can see what effects changing $h,\beta,c$ and $a$ has on the control limit:
\[h(\hat{\mu})=\beta\frac{c+V(0^+,\mu^*)}{a}.\]
\begin{remark}
	Decreasing  $a$ would result in an increase of the right hand side (the hazard bound) of this equation, increasing the control limit.
	This is expected, as this would decrease the incentive to prevent the asset from failing.
\end{remark}
\begin{remark}
	Decreasing $c$ would result in a decrease of the hazard bound, decreasing the control limit.
	This is also natural as this would make $a$ relatively larger.
\end{remark}
\begin{remark}
	If we would multiply $c$ and $a$ by a constant, then the control limit would not change as the sizes of these costs relative to each other remains the same.
	This can be proven using remark \ref{remark:AgeBasedCostRatio}.
\end{remark}
\begin{remark}\label{remark:AgeBasedControlLimitDiscountIncrease}
	Increasing $\beta$ will result in an increase in hazard bound, resulting in an increase in the control limit.
	This can be explained by the fact that with a higher discount, costs further in the future weigh less so that you would want to move costs as far into the future as possible.
\end{remark}
\begin{remark}
	A higher hazard (or a faster increasing hazard) results in a lower control limit as expected.
\end{remark}
\begin{remark}\label{remark:AgeBasedControlLimitDiscountAndHazardIncrease}
	If the hazard rate and the discount exponent are both multiplied by a constant, then the hazard rate remains the same as this constant can just be divided out of this equation.
\end{remark}

\subsection{Effect on expected total discounted cost}
From \eqref{eq:AgeBasedOptimalTDC}, we can see what effects changing $h,\beta,c$ and $a$ has on the expected total discounted cost:
\[V(0^+,\mu)=\frac{aF(\mu)\mathbb{E}[e^{-\beta Q_0}|Q_0\leq \mu]+c\mathbb{E}[e^{-\beta(Q_0\wedge\mu)}]}{1-\mathbb{E}[e^{-\beta (Q_0\wedge\mu)}]}.\]
\begin{remark}
	Decreasing $c$ or $a$ results in a decrease of this total cost as expected.
\end{remark}
\begin{remark}\label{remark:AgeBasedCostRatio}
	If we multiply both $c$ and $a$ by a constant, the cost will also be multiplied by this constant.
	This is natural as changing the currency the costs are expressed in should not be relevant.
\end{remark}
\begin{remark}
	A higher hazard would result in a higher expected value for the discount, decreasing the denominator and increasing the total discounted cost.
	This is natural as an asset that breaks quicker is more expensive to maintain.
\end{remark}
\begin{remark}\label{remark:AgeBasedTDCDiscountIncrease}
	Increasing the discount increases the denominator and the numerator so that the discounted cost decreases, as expected.
\end{remark}
For various parameters and distributions, the optimal control limit and total discounted cost are summarized in appendix \ref{AppendixComputationsTable}. 
\chapter{Simple fluid model with jumps}\label{chapter:SimpleFluid}
The problem of the previous chapter can be seen as a very simple Markov modulated fluid model:
Initially, the bucket has a random amount of fluid $Q_0\sim F$.
The fluid decreases constantly with rate $1$ and no fluid jumps occur.
In this chapter, we extend this model by allowing jumps to occur according to a Poisson process with rate $\lambda$.
The jumps all have the same constant (and known size) $J$.
In the real world, these fluid jumps could correspond to a partial repair of the asset.
The presence of jumps introduces the following complications:
\begin{itemize}
	\item The hazard of the asset failing at some time $t$ cannot be derived directly from the age only but also depends on the number of jumps that occurred before $t$.
	\item Furthermore, the times at which these jumps occurred also matter.
	When a jump occurs at time $t$, it is certain that the fluid quantity is at least $J$ so that you know for certain that in the interval $[t,t+J)$ the asset cannot fail.
\end{itemize}
In this chapter, the expected total discounted cost is calculated and methods are introduced to find the optimal replacement policy.
\section{Problem formulation and definition}
In this section, we extend the definition of age-based maintenance from section \ref{section:AgeBasedDefinition}.
First we define the underlying stochastic process of the the asset degrading over time and instantaneously increasing at the occurrence of jumps.
After that, we define a Markov decision process similarly to section \ref{section:AgeBasedDefinition}.

\subsection{Stochastic asset degradation}
We define the random process $Q(t)$ as the fluid level at age $t$.
Initially, the fluid level is given by $Q(0)=Q_0\sim F$.
Then over time this level decreases at a constant rate of $1$.
The jumps occur according to a Poisson process with rate $\lambda$, i.e. the time interval between two consecutive jumps is exponentially distributed with rate $\lambda$.
The fluid process is absorbing at $Q(t)=0$.
Hence, let $P_\lambda(t_1,t_2)$ be a Poisson distributed random variable with rate $\lambda (t_2-t_1)$.
Then the fluid level at time $t$ is given by 
\[
Q(t)\stackrel d=(Q_0+P_\lambda(0,t)J-t)\vee 0.
\]
Where $\stackrel d=$ denotes that the random variables on the left and right have the same distribution and $A\vee B$ denotes the maximum of $A$ and $B$.
$Q(t)$ has the property that
\[
\begin{split}
Q(t_1+t_2)&\stackrel d=( Q_0+P_\lambda(0,t_1)J+P_\lambda(t_1,t_1+t_2)J-t_1-t_2)\vee0\\
&\stackrel d= (Q(t_1)+P_\lambda(0,t_2)J-t_2)\vee0.
\end{split}
\]
The asset breaks when the fluid level reaches $0$, i.e. at the time $T^*$ given by
\[
T^*=\inf\{t|Q(t)=0\}.
\]
When the asset is repaired, it starts with an age of zero again.

To derive the distribution of $Q(t)$ for a certain $t$ from the observed jumps, it seems we need to keep track of the exact times at which these jumps occurred.
This would be a very inconvenient format of the state of the asset.
Luckily, this information can be condensed into a simpler state description.
First, we will illustrate this with the following example:
\begin{example}
	If the first jump of the process would have occur at some time $t$, then we would know the following at this time $t$:
	\begin{enumerate}
		\item $Q(t)\geq J$.
		Hence, we have a lower bound on the current fluid level.
		\item Initially, the fluid level was at least $t$, i.e. $Q_0\geq t$.
		Hence, we have a certain lower bound on the initial fluid level.
	\end{enumerate}
	If now, after some time $\tau<J$ another jump occurs, we know that:
	\begin{enumerate}
		\item At time $t+\tau$, $Q(t)\geq 2J-\tau$.
		The passage of time has hence decreased our lower bound of the current fluid level by $\tau$ and the jump has increased this bound by $J$.
		\item Our lower bound of the initial fluid level has remained unchanged.
		When our lower bound of the current fluid level is positive, our lower bound of the initial fluid level remains the same.
	\end{enumerate}
\end{example}
This suggests that the only two parameters we need to keep track of, are the lower bound of the current fluid level $L_c(t)$ and the lower bound of the initial fluid level $L_0(t)$.
We will refer to this $L_0$ as the drained initial fluid.
The asset cannot break if 
\[L_c(t)>0,\]
since we know with certainty that there is still remaining fluid.
We will refer to this quantity $L_c(t)$ as the fluid buffer.
The asset breaks whenever
\[L_0(t)=Q_0,\]
i.e. when the initial fluid level is drained.
Hence, we maintain the two quantities $L_c(t)$ and $L_0(t)$ as the description of the state the asset is in.
\[
X(t)=(L_0(t),L_c(t)).
\]
Initially
\[
X(0)=x_{NEW}:=(0,0).
\]
Furthermore, we also define a state $x_{BREAK}$ for when the asset is broken.
When $X(t)=x_{BREAK}$, $L_0(t)$ and $L_c(t)$ are undefined.
These two quantities evolve in the following way:
\begin{itemize}
	\item When a jump occurs at time $t$, $L_c$ increases by $J$, i.e.
	\begin{equation}\label{eq:SimpleJumpEvolution}
	X(t^+)=(L_0(t),L_c(t)+J).
	\end{equation}
	\item When no jump occurs in a neighborhood of $t$, $S(t)$ remains constant and $L_0$ and $L_c$ evolve according to
		\begin{equation}\label{eq:SimpleAgeEvolution}
		\begin{split}
		\frac{d}{dt}L_c(t)&=\begin{cases}
		0&\ \text{if }L_c(t)=0,\\
		-1&\ \text{else.}
		\end{cases}\\
		\frac{d}{dt}L_0(t)&=\begin{cases}
		0&\ \text{if }L_c(t)>0,\\
		1&\ \text{else.}
		\end{cases}
		\end{split}
		\end{equation}
		Note that we always have
		\begin{equation}\label{eq:SimpleSameDecrease}
		\frac{d}{dt}\left[L_c(t)-L_0(t)\right]=\frac{d}{dt}Q(t)=-1.
		\end{equation}
	\item When the fluid drains, i.e. $Q(t)=0$ or equivalently $L_0(t)=Q_0$, the asset breaks so that
	\[
	X(t)=x_{BREAK},
	\]
	until it is being repaired.
\end{itemize}
\begin{theorem}\label{theorem:SimpleCurrentLevel}
	Using the $L_c(t)$ and the $L_0(t)$ as defined above.
	For $x\neq x_{BREAK}$, the fluid level is given by
	\begin{equation}\label{eq:SimpleCurrentLevel}
	Q(t)=L_c(t)+Q_0-L_0(t).
	\end{equation}
	\begin{proof}
		At the start of the process, $X(0)=(0,0)$ so that
		\[
		Q(0)=0+Q_0-0=Q_0.
		\]
		When a jump occurs, we know that $Q(t)$ increases by $J$.
		By \eqref{eq:SimpleJumpEvolution}, $L_c$ also increases by $J$ such that jumps preserve \eqref{eq:SimpleCurrentLevel}.
		When no jump occurs, we have by \eqref{eq:SimpleSameDecrease} that $Q(t)$ and $L_c(t)-L_0(t)$ decrease at the same speed.
		This completes the proof.
	\end{proof}
\end{theorem}

\begin{example}\label{example:SimpleFluidState}
	For example, if we have the jump quantity $J=3$ and the initial fluid level for a run of the asset equals $5$.
	If after 1.5 time units and after 2.5 time units a jump occurred, $Q,L_0$ and $L_c$ would evolve as in figure \ref{figure:SimpleFluidExampleQuantities}.
	As you can see, when $Q(t)=0$, it holds that $L_0(t)=Q(0)$.
\end{example}
\begin{figure}[H]
\centering
\setlength\fwidth{0.7\textwidth}
\definecolor{mycolor1}{rgb}{0.00000,0.44700,0.74100}
\definecolor{mycolor2}{rgb}{0.85000,0.32500,0.09800}
\definecolor{mycolor3}{rgb}{0.92900,0.69400,0.12500}
\begin{tikzpicture}

\begin{axis}[
width=0.951\fwidth,
height=0.75\fwidth,
at={(0\fwidth,0\fwidth)},
scale only axis,
xmin=0,
xmax=12,
xlabel style={font=\color{white!15!black}},
xlabel={Time},
ymin=0,
ymax=8,
ylabel style={font=\color{white!15!black}},
ylabel={Fluid},
axis background/.style={fill=white},
legend style={legend cell align=left, align=left, draw=white!15!black}
]
\addplot [color=mycolor1]
  table[row sep=crcr]{
0	5\\
1.5	3.5\\
1.51	6.5\\
3.5	4.5\\
3.51	7.5\\
7.5	3.5\\
11	0\\
};
\addlegendentry{$Q$}

\addplot [color=mycolor2]
  table[row sep=crcr]{
0	0\\
1.5	1.5\\
1.51	1.5\\
3.5	1.5\\
3.51	1.5\\
7.5	1.5\\
11	5\\
};
\addlegendentry{$L_0$}

\addplot [color=mycolor3]
  table[row sep=crcr]{
0	0\\
1.5	0\\
1.51	3\\
3.5	1\\
3.51	4\\
7.5	0\\
11	0\\
};
\addlegendentry{$L_c$}

\end{axis}
\end{tikzpicture}% \caption{$Q(t),L_0(t),L_c(t)$ for example \ref{example:SimpleFluidState}.}
\label{figure:SimpleFluidExampleQuantities}
\end{figure}

\begin{corollary}\label{corollary:SimpleFluidDistribution}
	Theorem \ref{theorem:SimpleCurrentLevel} implies that $Q(t)\sim F_{X(t)}$, where
	\begin{equation}\label{eq:SimpleCurrentDistribution}
	\begin{split}
	F_{X(t)}(q)&:=\mathbb{P}(Q(t)<q)\\
	&=\mathbb{P}(L_c(t)+Q_0-L_0(t)<q|Q_0>L_0(t))\\
	&=\mathbb{P}(Q_0<q+L_0(t)-L_c(t)|Q_0>L_0(t))\\
	&=\frac{F(q+L_0(t)-L_c(t))-F(L_0(t))}{\bar{F}(L_0(t))}.\\
	\end{split}
	\end{equation}
\end{corollary}

We use the same discretization $t_k=\delta k$ as in the previous chapter.
For $x_k=X(t_k)$, we describe the random variables $\omega_k=\omega_k(x_k)$ of the Markov decision process in the following way
\[
\omega_k(x_k):=\begin{cases}
\Omega_{SURVIVE}&\ \begin{split}&\text{if the asset does not break and no jump occurs}\\
&\text{in the $k$'th time interval.}\end{split}\\
\Omega_{BREAK}&\ \text{if the asset breaks in the $k$'th time interval.}\\
\Omega_{JUMP}&\ \begin{split}&\text{if the asset does not break and a jump occurs}\\
&\text{in the $k$'th time interval.}\end{split}\\
\end{cases}
\]
Note that the asset can only break whenever $L_c(t)=0$.
Assuming only one jump can occur in a time interval and letting $x_k=X(t_k)=(l_0,l_c)$, we get the following probabilities:
\[
\begin{split}
\mathbb{P}(\omega_k(x_k)=\Omega_{SURVIVE})&=\begin{cases}
e^{-\lambda \delta}=1-\delta\lambda+o(\delta^2)&\text{ if }l_c>0,\\
\begin{split}
e^{-\lambda \delta} & \bar{F}_{x_k}(l_0+\delta)\\
=1&-\delta h(l_c)-\delta\lambda+o(\delta^2)
\end{split}&\text{ if }l_c=0.\\
\end{cases}\\
\mathbb{P}(\omega_k(x_k)=\Omega_{BREAK})&=\begin{cases}
0&\text{ if }l_c>0,\\
\begin{split}
e^{-\lambda \delta}F_{x_k}&(l_0+\delta)\\
=&\delta h(l_c)+o(\delta^2)
\end{split}&\text{ if }l_c=0.\\
\end{cases}\\
\mathbb{P}(\omega_k(x_k)=\Omega_{JUMP})&=\begin{cases}
1-e^{-\lambda \delta} & \text{ if }l_c>0,\\
\begin{split}
1-&e^{-\lambda \delta}\\
=&\delta\lambda+o(\delta^2)
\end{split}&\text{ if }l_c=0.\\
\end{cases}
\end{split}
\]
Where $F_x$ is given by corollary \ref{corollary:SimpleFluidDistribution}.

\subsection{Control actions}
We introduce a state $x_{BREAK}$ for when the asset is broken.
and in this state the only available action is $a_R$.
In all other states, both actions $a_W$ and $a_R$ may be chosen.
The definitions of these actions remains the same as in the definition of the age-based maintenance problem.

\subsection{State evolution}
Initially $x_{NEW}=(0,0)$.
The state of the Markov decision process now evolves in the following way:
\[
x_{k+1}=f(x_k, u_k, \omega_k):=\begin{cases}
x_{NEW}&\ \text{if }u_k=a_R,\\
\begin{split}(l_0+\delta-\min\{l_c,\delta\}&,\\l_c-\min\{l_c,\delta\}&)\end{split}&\ \text{if }u_k=a_W\text{ and }\omega_k=\Omega_{SURVIVE},\\
(l_0,l_c+J-\delta)&\ \text{if }u_k=a_W\text{ and }\omega_k=\Omega_{JUMP},\\
x_{BREAK}&\ \text{if }u_k=a_W\text{ and }\omega_k=\Omega_{BREAK}.\\
\end{cases}
\]
Here we assumed that jumps occur at the start of time intervals.
For small $\delta$, this approximates the fluid model defined above.
Again, we use the definition of the random variable $S(x_k):=f(x_k,a_W,\omega_k(x_k))$ as the state after $x_k$.

\subsection{Costs and discounting}
The costs and discounting remain the same as in the age-based maintenance problem.

\subsection{Optimal policy and Bellman equations}
In the next section, we will prove that the optimal policy is a stationary policy.
Hence, we want to find a stationary policy $\mu:X\rightarrow \{a_W,a_R\}$ that chooses the action $u_k=\mu(x_k)$ that minimizes the expected total discounted cost $V_\delta(x_k,\mu)$ for each state.
Similarly as in the definition of age-based maintenance, $V_\delta(x_k,\mu)$ is given by
\[V_\delta(x_k,\mu)=g(x_k,\mu(x_k))+\alpha_\delta \mathbb{E}[V_\delta(S(x_k),\mu)].\]
The Bellman equations for the optimal cost $V_\delta(x_k,\mu^*)$ read
\begin{equation}\label{eq:SimpleFluidBellman}
V_\delta(x_k,\mu^*)=\begin{cases}
c+a+\alpha_\delta V_\delta(x_{NEW},\mu^*),&\text{ if }x_k=x_{BREAK},\\
\min\left\{\begin{split}&c+\alpha_\delta V_\delta(x_{NEW},\mu^*),\\&\alpha_\delta \mathbb{E}[V_\delta(S(x_k),\mu^*)]\end{split}\right\},&\text{else.}\\
\end{cases}
\end{equation}
$\mu$ is optimal if $V_\delta(x,\mu)=V_\delta(x,\mu^*)$ for all $x$.
$\mathbb{E}[V_\delta(S(x_k),\mu^*)]$ when $x_k\neq x_{BREAK}$ is given by 
\begin{equation}\label{eq:SimpleFluidNextState}
\begin{split}
&\mathbb{E}[V_\delta(S(l_0,l_c),\mu^*)]\\
&=\begin{cases}
\begin{split}
&(1-e^{-\lambda \delta})V_\delta(l_0,l_c+J-\delta,\mu^*)\\
&+e^{-\lambda \delta}V_\delta(l_0,l_c-\delta,\mu^*),
\end{split}&\ \text{If $l_c=0$,}\\
\begin{split}
&e^{-\lambda \delta} \bar{F}_{t_k}(l_0+\delta)V_\delta(l_0+\delta,0,\mu^*)\\
&+ e^{-\lambda \delta}F_{t_k}(l_0+\delta)V_\delta(x_{BREAK},\mu^*)\\
&+(1-e^{-\lambda \delta})V_\delta(l_0,J-\delta,\mu^*),
\end{split}&\ \text{If $l_c>0$.}\\
\end{cases}\\
&=\begin{cases}
\begin{split}
&\lambda\delta V_\delta(l_0,l_c+J-\delta,\mu^*)\\
&+(1-\lambda \delta)V_\delta(l_0,l_c-\delta,\mu^*)+o(\delta^2),
\end{split}
&\ \text{If $l_c=0$,}\\
\begin{split}
&(1-\lambda \delta-\delta h(l_0))V_\delta(l_0+\delta,0,\mu^*)\\
&+ \delta h(l_0)V_\delta(x_{BREAK},\mu^*)\\
&+\lambda \delta V_\delta(l_0,J-\delta,\mu^*)+o(\delta^2),
\end{split}&\ \text{If $l_c>0$.}\\
\end{cases}
\end{split}
\end{equation}
Similar to the previous chapter, we will consider a continuous MDP by letting $\delta\rightarrow0$.

\subsection{Alternative models}
The occurrence of fluid jumps can be modeled in many different ways.
We will briefly mention some alternatives to design choices that were made in the definition above.
\subsubsection{Decisions at jumps only}
We could also model the problem such that the choice to repair the asset can only be made the instant after a jump occurs.
This might be more realistic as the jump could be caused by some mechanic performing some partial maintenance and a mechanic might be needed to completely repair the asset.

\subsubsection{Jumps not according to a Poisson process}
The time in between the jumps could also have another distribution than the exponential distribution.
This would, however, make the problem significantly more complicated as the memorylessness simplifies the problem slightly. \section{Structure of optimal policy}
In this section, we will establish that for the simple fluid model with jumps, the optimal policy is a stationary policy to repair whenever the buffer is empty and the used initial fluid $L_0(t)$ exceeds a certain control limit.
By this, we mean that there exists some optimal control limit $\mu^*>0$ and repair should be chosen whenever the buffer $L_c(t)=0$ and $L_0(t)\geq\mu^*$.

\subsection{Stationary policy}
Any discretization of $L_0$ and $L_c$ results in a countable state space and the cost function is again independent of the decision epoch.
Hence, by section 6.2.4 of \cite{Puterman2008}, any discrete approximation of the continuous-time MDP has a stationary optimal policy.

\subsection{Empty buffer}
Repairing when $L_c>0$ cannot be optimal since it is certain that the machine will not break in the next $L_0$ time units and waiting more would decrease the cost.
This proves that in the optimal policy $L_c$ must be zero whenever repair is chosen.

\subsection{Control limit}
The optimal policy is a control limit policy by the same argument as for the age-based problem (see section \ref{section:AgeBasedControlLimit}). 

Hence, we have established that the optimal policy is a control limit on the used initial fluid $L_0$. \section{Computation of total discounted cost}
In this section the expected total discounted cost is calculated corresponding to following a control limit policy with control limit $\mu$.
As in the age-based maintenance problem, we can use the Bellman equations to find differential equations to which the total discounted cost adheres.
But for this problem, we will opt for the simpler approach of directly calculating the total discounted costs corresponding to the policies.

The challenge lies in calculating the discount over these costs.
In the age-based problem, this was simple as there were no jumps and the discount after $q$ fluid (age) was depleted was simply $e^{-\beta q}$.
In this problem, we need the distribution of the time it takes until $q$ initial fluid is depleted.

\subsection{Time until control limit}
Let $T_t(q)$ be the random variable denoting the time until the fluid level is $q$ lower than it was at time $t$, i.e.
$$
T_t(q)=\min\{\tau\geq0|Q(t+\tau)\leq Q(t)-q\}.
$$
Note that, using this definition, $T_0(\mu)$ equals the time until the control limit is reached ($L_0(t)=\mu$) and $T_0(Q_0)$ equals the time until the asset fails.
\begin{lemma}\label{lemma:TimeUntilFluidLemma}
	For any $A,B>0$:
	$A\leq\mu\Leftrightarrow T_t(A)\leq T_t(B)$
	\begin{proof}
		$\Rightarrow$: 
		\[\begin{split}
		A\leq\mu&\Rightarrow Q(t)-B\leq Q(t)-A\\
		&\Rightarrow (Q(t+\tau)\leq Q(t)-B\Rightarrow Q(t+\tau)\leq Q(t)-A)\\
		&\Rightarrow T_t(A)\leq T_t(B)\\
		\end{split}\]
		$\Leftarrow$: We will prove that $A>B\Rightarrow T_t(A)> T_t(B)$:\\
		We know that
		$$
		A>B\Rightarrow Q(t)-B > Q(t)-A.
		$$
		Since $Q(t)$ is piecewise continuous and does not decrease at the discontinuities, we know that 
		$$
		Q(t+T_t(B))=Q(t)-\mu>Q(t)-A\Rightarrow T_t(A)> T_t(B).
		$$
	\end{proof}
\end{lemma}
To find the distribution of $T_t(q)$, we will condition on the number of jumps.
Let $N_t(q)$ be the random variable denoting the number of jumps that occur in the interval $(t,t+T_t(q)]$.
We will now compute its distribution.
The probability that zero jumps occur equals the probability that the exponentially distributed time interval is larger than $q$:
$$
\mathbb{P}(N_t(q)=0)=e^{-\lambda q}.
$$
The probability that exactly one jump occurs equals the probability that exactly one Poisson event happens in the interval $(t,t+q]$ while none happen in $(t+q,t+q+J]$. Resulting in
$$
\mathbb{P}(N_t(q)=1)=\lambda q e^{-\lambda q} e^{-\lambda J}=\lambda q e^{-\lambda (q+J)}.
$$

For each $k\geq0$, by conditioning on the time until the first jump, we get the following recursion
\begin{equation}\label{eq:SimpleFluidJumpsRecursion}
\begin{split}
\mathbb{P}(N_t(q)=k+1)&=\int\limits_0^{q}\lambda e^{-\lambda x}\mathbb{P}(N_t(q-x+J)=k)dx\\
&=\int\limits_0^{q}\lambda e^{-\lambda (q-y)}\mathbb{P}(N_t(y+J)=k)dy,
\end{split}
\end{equation}
since after this first jump, the fluid level equals $q-x+J$ and $k$ jumps should occur. The second equality follows after the substition $y=q-x$.
The solution of this recursion, is given by the following lemma.
\begin{lemma}
	The probability that $k$ jumps occur before the fluid is decreased by $q$ equals
	
	\[\mathbb{P}(N_t(q)=k)=\lambda q\frac{(\lambda (q+kJ))^{k-1}}{k!}e^{-\lambda(q+kJ)}.\]
	
	\begin{proof}
		This can be seen by substituting this expression into \eqref{eq:SimpleFluidJumpsRecursion} and setting $k=1$ to see that it also satisfies the calculated expression for $\mathbb{P}(N_t(q)=1)$.
	\end{proof}
\end{lemma}

Now we can define the quantity $D(q)$ as the expected discount over the time until $q$ initial fluid is used in the following way
\begin{equation}\label{eq:SimpleFluidDiscountDefinition}
D(q):=\mathbb{E}[e^{-\beta T_t(q)}]=\sum\limits_{k=0}^\infty e^{-\beta(q+kJ)}\mathbb{P}(N_t(q)=k).
\end{equation}
Note that this $D$ does not depend on $t$ because the time intervals in between jumps are memoryless.
This quantity has the following properties:
\begin{lemma}\label{lemma:SimpleFluidDiscountLogLinear}
	\[D(A)D(B)=D(A+B).\]
	\begin{proof}
		\begin{equation}
		\begin{split}
		D(A)D(B)&=\left[\sum\limits_{k=0}^\infty e^{-\beta(A+kJ)}\mathbb{P}(N_t(A)=k)\right]\left[\sum\limits_{m=0}^\infty e^{-\beta(B+mJ)}\mathbb{P}(N_t(B)=m)\right]\\
		&=\sum\limits_{n=0}^\infty e^{-\beta(A+B+nJ)}\sum\limits_{k=0}^n \mathbb{P}(N_t(A)=k)\mathbb{P}(N_t(B)=n-k)\\
		&=\sum\limits_{n=0}^\infty e^{-\beta(A+B+nJ)} \mathbb{P}(N_t(A+B)=n).\\
		\end{split}
		\end{equation}
		The last step holds since on the second last line, the second sum equals the probability that $n$ jumps occur before a fluid quantity $A+B$ is drained, conditioned on the number of jumps that occur before a quantity $A$ is drained.
	\end{proof}
\end{lemma}

\begin{lemma}\label{lemma:SimpleFluidDiscountODE}
	$$\frac{d}{dA}D(A)=-(\beta+\lambda)D(A)+\lambda D(A+J)$$
	\begin{proof}
		This can be seen from taking the derivative of \eqref{eq:SimpleFluidDiscountDefinition}.
	\end{proof}
\end{lemma}
Using these lemmas we can find a simpler expression for $D(q)$ than \eqref{eq:SimpleFluidDiscountDefinition}:
\begin{theorem}\label{theorem:SimpleFluidDiscountExpression}
	The expected discount over the time until the fluid has decreased by $q$, is given by
	\[
	D(A)=e^{-(\beta+\lambda(1-D(J)))A}.
	\]
	\begin{proof}
		Using lemma \ref{lemma:SimpleFluidDiscountLogLinear}, we can rewrite the derivative of $D(A)$ given by \ref{lemma:SimpleFluidDiscountODE} to
		\[
		\frac{d}{dA}D(A)=-(\beta+\lambda)D(A)+\lambda D(A)D(J)=-(\beta+\lambda(1-D(J)))D(A).
		\]
		Which leads to solution
		\[
		D(A)=Ce^{-(\beta+\lambda(1-D(J)))A}.
		\]
		For some integration constant $C$. Since $D(0)=1$, we know that $C=1$, which completes the proof.
	\end{proof}
\end{theorem}
\begin{corollary}
	The value $D(J)$ is now implicitly given by
	\[
	D(J)=e^{-(\beta+\lambda(1-D(J)))J}.
	\]
	This quantity can be approximated by a method of successive approximation.
	For the parameters that were used in appendix \ref{AppendixComputationsTable}, this quantity converged within ten iterations up to five decimals.
\end{corollary}
\begin{remark}\label{remark:SimpleFluidDiscountEquivalence}
	From theorem \ref{theorem:SimpleFluidDiscountExpression}, it can be seen that this expected discount factor of the simple fluid model is actually the same as the discount factor for the age-based model with adjusted discount exponent $\beta^*=\beta+\lambda(1-D(J))$.
	That is,
	\[
	D(q)=e^{-\beta^*q}.
	\]
\end{remark}

Now we will derive the expected total discounted cost:
If $T_0(Q_0)\leq T_0(\mu)$, the asset will break in the first run and expected value at which the corrective repair cost is discounted is $\mathbb{E}[D(Q_0)|T_0(Q_0)\leq T_0(\mu)]$.
Note that $\mathbb{P}(T_0(Q_0)\leq T_0(\mu))=\mathbb{P}(Q_0\leq\mu)$ by lemma \ref{lemma:TimeUntilFluidLemma}.
If $T_0(Q_0)> T_0(\mu)$, the expected value at which the preventive repair cost is discounted is $D(\mu)$.
This results in the following expression for the expected total discounted cost:
\begin{theorem}
	The expected total discounted cost of an asset with control limit $\mu$, is given by
	\begin{equation}\label{eq:SimpleFluidImplicitTDC}
	V(x_{NEW},\mu)=F(\mu)\mathbb{E}[D(Q_0)|Q_0\leq \mu]a+\mathbb{E}[D(Q_0\wedge\mu)](c+V(x_{NEW},\mu)).
	\end{equation}
\end{theorem}

\begin{corollary}
	Alternatively \eqref{eq:SimpleFluidImplicitTDC} can be written as
	\begin{equation}\label{eq:SimpleFluidExplicitTDC}
	V(x_{NEW},\mu)=\frac{F(\mu)\mathbb{E}[D(Q_0)|Q_0\leq \mu]a+\mathbb{E}[D(Q_0\wedge\mu)]c}{1-\mathbb{E}[D(Q_0\wedge\mu)]}.
	\end{equation}
\end{corollary}

\begin{remark}\label{remark:SimpleFluidTDCEquivalence}
	Using remark \ref{remark:SimpleFluidDiscountEquivalence}, we can see that \eqref{eq:SimpleFluidImplicitTDC} is again the same as for the age-based maintenance problem \eqref{eq:AgeBasedHatTDC} for the adjusted discount factor $\beta^*=\beta+\lambda(1-D(J))$.
\end{remark} \section{Optimal policy}
In this section, we will look for the optimal control limit $\mu^*$.
From remark \ref{remark:SimpleFluidDiscountEquivalence}, it follows that if we use the adjusted discount $\beta^*=\beta+\lambda(1-D(J))$, this problem completely reduces to the age-based maintenance problem.
Hence, we can use \eqref{eq:AgeBasedHazardBound} with this adjusted discount as condition for the optimal control limit.
The same properties proven in chapter \ref{chapter:AgeBased} also apply for this problem and the same policy iteration can also be applied to compute the optimal control limit and corresponding expected total discounted cost.
There is one important conceptual difference between the control limit of the age-based problem and this simple fluid problem:
if $\lambda J>1$, the system is instable and the fluid level can diverge to infinity.
This means that there is a positive probability that the control limit will never be reached (i.e. $T_t(Q_0\wedge\mu)=\infty$) and that the asset will never fail. \section{Structural properties}\label{section:SimpleStructuralProperties}
In this section, the effect of changing the parameters to the expected total discounted cost and the control limit are investigated.
By the equivalence explained in the previous chapter, the same structural properties as in section \ref{section:AgeBasedStructuralProperties} for the parameters $c,a$ and $h$ apply.
Remarks \ref{remark:AgeBasedControlLimitDiscountIncrease}, \ref{remark:AgeBasedControlLimitDiscountAndHazardIncrease} and \ref{remark:AgeBasedTDCDiscountIncrease} also apply for the adjusted discount $\beta^*$.
Hence, we discuss the effect changing $\lambda,J$ and $\beta$ has to the adjusted discount $\beta^*$.
\[
\beta^*=\beta+\lambda(1-D(J))
\]
\begin{remark}
	Obviously, increasing $\beta$ will result in an increase in $\beta^*$.
\end{remark}
\begin{remark}
Similarly, increasing $\lambda$ will result in an increase in $\beta^*$ if $J>0$ ($J=0$ implies $D(J)=1$).
This means that frequent jumps increase the control limit and decrease the total discounted cost, which seems natural.
\end{remark}
\begin{remark}
	Increasing $J$ results in a decrease in $D(J)$, which results in an increase in $\beta^*$.
	This means that greater jumps, again, increase the control limit and decrease the total discount cost, which also seems natural.
\end{remark}
Then there is also another important subtlety: For the age-based maintenance problem we needed to assume that the distribution of the age of the asset has an increasing hazard rate.
Similarly, we need the assumption that the distribution of the initial fluid level has an increasing hazard rate.
This does, however, not mean that the lifetime distribution of this asset with fluid jumps has an increasing hazard rate.
For instance if the system is unstable ($\lambda J>1$), the probability of ever reaching an empty fluid level decreases as the fluid level increases and the expected fluid level increases over its age so that the hazard will be decreasing.

Appendix \ref{AppendixComputationsTable} contains computed values of the optimal control limit and the corresponding expected total discounted cost. 
\chapter{Markov Modulated Fluid Model with jumps}\label{chapter:Mmfm}
In this chapter, we extend the model of the simple fluid model with jumps from the previous chapter to a Markov modulated fluid model (MMFM) with various states, various fluid jump sizes and fluid rates.
The fluid jumps occur when a transition occurs in the underlying Markov chain.
The MMFM that is used is similar to the first-order fluid model considered in \cite{Gribaudo2007}, with the addition of constant jumps.
The size of the jumps are constant.
The various fluid rates, transition rates and jump sizes introduce the following complications with regard to computing the total discounted cost and the optimal policy:
\begin{enumerate}
	\item The computation of the expected discount factors $D(q)$ is more difficult as we need to take multiple
	paths with different probabilities and jump sizes into account.
	Moreover, it is also relevant from which state you start and where you end.
	\item There are different control limits $\mu_i$ for different states $s_i$, all depending on each other.
	\item A jump can cause the asset to be repaired when the amount of used fluid has exceeded the control limit.
\end{enumerate}
These complications will be explained and tackled in the following sections.
\section{Problem formulation and definition}
In this section, we extend the problem definition of preventive maintenance on an asset modeled as the simple fluid model from the previous chapter.
First we extend the stochastic process from the last chapter to a MMFM, then we define a Markov decision process.

\subsection{Stochastic asset degradation}
First, we define a left-continuous Continuous Time Markov Chain (CTMC) $S(t)$ with state space $S=\{s_1,...,s_N\}$, initial state $s_1$ and transition rates $\lambda_{ij}$ from state $s_i$ to $s_j$, with $\lambda_{ii}=-\sum_{j\neq i}\lambda_{ij}$.
Furthermore, we define $\lambda_i=-\lambda_{ii}$ for convenience.
In figure \ref{figure:MmfmNotation}, a MMFM with states $s_i,s_j$ is drawn.
We draw MMFMs with multiple states in a similar way.
\begin{figure}
	\centering
	\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=3cm,
	thick,main node/.style={circle,draw,font=\sffamily\Large\bfseries}]
	
	\node[main node] (1) {$s_i:r_i$};
	\node[main node] (2) [right of=1] {$s_j:r_j$};
	
	\path[every node/.style={font=\sffamily\small}]
	(1) edge [bend left] node {$\lambda_{ij}:J_{ij}$} (2)
	(2) edge [bend left] node {$\lambda_{ji}:J_{ji}$} (1);
	\end{tikzpicture}
	\caption{A drawing of a MMFM with two states $s_i$ and $s_j$ with fluid rates $r_i$ and $r_j$ respectively.
		The transition from $s_i$ to $s_j$ has rate $\lambda_{ij}$ and jump quantity $J_{ij}$.
		Similarly, the transition from $s_j$ to $s_i$ has rate $\lambda_{ji}$ and jump quantity $J_{ji}$}
	\label{figure:MmfmNotation}
\end{figure}
We let $S(t)$ denote the (index of the) state the CTMC is in at time $t$.
Similar to the previous chapter, we represent the fluid level at time $t$ by $Q(t)$ with $Q(0)=Q_0\sim F$.
When the CTMC is in state $s_i$, the fluid level $Q(t)$ decreases with rate $r_i>0$:
\[
\frac{d}{dt}Q(t)=-r_{S(t)}.
\]
When a transition from $s_i$ to $s_j$ occurs, the fluid rate instantaneously increases by $J_{ij}\geq 0$.
Again, the asset breaks when the fluid reaches zero so that the process is absorbing at $Q(t)=0$.
When the asset is repaired, the process is restarted with an initial fluid level with distribution $F$.

Similar to the simple fluid model, the state information can be condensed with a few variables.
These are the amount of used initial fluid $L_0(t)$, the buffer level $L_c(t)$ and the current CTMC-state $S(t)$.
The definitions of $L_0$ and $L_c$ are exactly the same as in the previous chapter:
\begin{enumerate}
	\item $L_0(t)$ is the lower bound of the initial fluid level $Q_0$ known at time $t$.
	\item $L_c(t)$ is the lower bound of the current fluid level $Q(t)$ known at time $t$.
\end{enumerate}
Hence,
\[
X(t)=(S(t),L_0(t),L_c(t)),
\]
when the asset is not broken (i.e. the fluid level is positive) and initially $X(0)=x_{NEW}=(1,0,0)$.
Again, we define a special state $x_{BREAK}$ for when the asset is broken.
When $X(t)=x_{BREAK}$, the quantities $L_0(t)$ and $L_c(t)$ are undefined.

The values $L_0$ and $L_c$ evolve in a similar way as in the previous chapter:
\begin{itemize}
	\item When a transition from $s_i$ to $s_j$ occurs at time $t$, the buffer $L_c$ increases by $J_{ij}$:
	\begin{equation}\label{eq:MmfmJumpEvolution}
	X(t^+)=(j,L_0(t),L_c(t)+J_{ij}).
	\end{equation}
	\item When no jump occurs in a neighborhood of $t$, $S(t)$ remains constant and $L_0$ and $L_c$ evolve according to
	\begin{equation}\label{eq:MmfmAgeEvolution}
	\begin{split}
	\frac{d}{dt}L_c(t)&=\begin{cases}
	0&\ \text{if }L_c(t)=0,\\
	-r_{S(t)}&\ \text{else.}
	\end{cases}\\
	\frac{d}{dt}L_0(t)&=\begin{cases}
	0&\ \text{if }L_c(t)>0,\\
	r_{S(t)}&\ \text{else.}
	\end{cases}
	\end{split}
	\end{equation}
	Note that we then always have
	\[
	\frac{d}{dt}\left[L_c(t)-L_0(t)\right]=\frac{d}{dt}Q(t)=-r_{S(t)}.
	\]
	\item When the asset breaks (i.e. whenever $Q(t)=0$ or equivalently $L_0(t^-)=Q_0$) the process moves to $x_{BREAK}$:
	\[
	X(t)=x_{BREAK}.
	\]
\end{itemize}
With these definitions, $Q(t)$ is again given by \eqref{eq:SimpleCurrentLevel} and it has distribution $F_{X(t)}(q)$,  again given by \eqref{eq:SimpleCurrentDistribution}.

\begin{example}\label{example:MmfmState}
	Consider the MMFM depicted by figure \ref{figure:MmfmExample}.
	Now consider the following run of the asset:
	\begin{itemize}
		\item The asset starts in $s_1$ with initial fluid level $5$
		\item After 1 time unit, a transition to $s_2$ occurs
		\item The asset stays in $s_1$ for half a time unit, then it transitions to $s_3$
		\item It stays in this state for $1.5$ time units before transitioning to $s_1$ again.
		\item Here it breaks after $2$ time units.
	\end{itemize}
	Figure \ref{figure:MmfmExampleQuantities} shows the evolution of the quantities $Q(t),L_(t)$ and $L_c(t)$ over this time period.
	As you can see, $L_0(t)$ is nondecreasing and the asset breaks when $L_0(t)=Q(0)$.
\end{example}
\begin{figure}
\centering
\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=3cm,
thick,main node/.style={circle,draw,font=\sffamily\Large\bfseries}]

\node[main node] (1) {$s_1:1$};
\node[main node] (2) [right of=1] {$s_2:4$};
\node[main node] (3) [below right of=1] {$s_3:2$};

\path[every node/.style={font=\sffamily\small}]
(1) edge node {$1:3$} (2)
(2) edge node {$2:0$} (3)
(3) edge node {$2:0$} (1);
\end{tikzpicture}
\caption{Depiction of the MMFM for example \ref{example:MmfmState}.}
\label{figure:MmfmExample}
\end{figure}
\begin{figure}[H]
\centering
\setlength\fwidth{0.7\textwidth}
\definecolor{mycolor1}{rgb}{0.00000,0.44700,0.74100}
\definecolor{mycolor2}{rgb}{0.85000,0.32500,0.09800}
\definecolor{mycolor3}{rgb}{0.92900,0.69400,0.12500}
\begin{tikzpicture}

\begin{axis}[
width=0.951\fwidth,
height=0.75\fwidth,
at={(0\fwidth,0\fwidth)},
scale only axis,
xmin=0,
xmax=5,
xlabel style={font=\color{white!15!black}},
xlabel={Time},
ymin=-1,
ymax=7,
ylabel style={font=\color{white!15!black}},
ylabel={Fluid},
axis background/.style={fill=white},
legend style={legend cell align=left, align=left, draw=white!15!black}
]
\addplot [color=mycolor1]
  table[row sep=crcr]{
0	5\\
1	4\\
1.01	7\\
1.5	5\\
2	4\\
3	2\\
5	0\\
};
\addlegendentry{$Q$}

\addplot [color=mycolor2]
  table[row sep=crcr]{
0	0\\
1	1\\
1.01	1\\
1.5	1\\
2	1\\
3	3\\
5	5\\
};
\addlegendentry{$L_0$}

\addplot [color=mycolor3]
  table[row sep=crcr]{
0	0\\
1	0\\
1.01	3\\
1.5	1\\
2	0\\
3	0\\
5	0\\
};
\addlegendentry{$L_c$}

\end{axis}
\end{tikzpicture}% \caption{$Q(t),L_0(t),L_c(t)$ for example \ref{example:MmfmState}.}
\label{figure:MmfmExampleQuantities}
\end{figure}

Now, for defining the MDP, we will briefly return to discretized time.
For $x_k=X(t_k)$, we describe the random variables $\omega_k=\omega_k(x_k)$ of the Markov decision process as the (index of the) state of the continuous Markov chain at the next decision stage or $\Omega_{BREAK}$ if the asset will break before then:
\[
\omega_k(x_k):=\begin{cases}
\Omega_{BREAK},&\ \text{if the asset breaks,}\\
S(t_{k+1}),&\ \text{else.}
\end{cases}
\]
A jump then occurs when $S(t_k)\neq\omega_k(x_k)\neq\Omega_{BREAK}$.
Assuming only one jump can occur in a time interval, $\omega_k$ has the following probabilities:
\[
\begin{split}
\mathbb{P}(\omega_k(i,l_0,l_c)=\Omega_{BREAK})&=\begin{cases}
	0&\text{ if }l_c>0,\\
	\begin{split}
	e^{-\lambda_{i}\delta}F_{x_k}(l_0+r_i\delta)&\\
	=\delta r_ih(l_0)+o(\delta^2)&
	\end{split}&\text{ if }l_c=0.\\
\end{cases}\\
\mathbb{P}(\omega_k(i,l_0,l_c)=i)&=\begin{cases}
	e^{-\lambda_i \delta}=1-\delta\lambda_i+o(\delta^2)&\text{ if }l_c>0,\\
	\begin{split}
	&e^{-\lambda_i \delta} \bar{F}_{x_k}(l_0+r_i\delta)\\
	&=1-\delta r_ih(l_0)-\delta\lambda_i+o(\delta^2)
	\end{split}&\text{ if }l_c=0.\\
\end{cases}\\
\mathbb{P}(\omega_k(i,l_0,l_c)=j)&=\begin{cases}
	\frac{\lambda_{ij}}{\lambda_i}(1-e^{-\lambda_i \delta})=\delta\lambda_{ij}+o(\delta^2) & \text{ if }l_c>0,\\
	\begin{split}
	\frac{\lambda_{ij}}{\lambda_i}(1-e^{-\lambda_i \delta})\bar{F}_{x_k}(l_0+r_i\delta)&\\
	=\delta\lambda_{ij}+o(\delta^2)&
	\end{split}&\text{ if }l_c=0.\\
\end{cases}
\end{split}
\]
Where $i\neq j$.

\subsection{Control actions}
Similar to the previous chapter, we have a repair action $a_R$ and a wait action $a_W$ and $a_W$ may only be chosen whenever $x_k\neq x_{BREAK}$.
The definitions of these actions remain the same as in the definition of the age-based maintenance problem.

\subsection{State evolution}
Initially, $x_{NEW}=(s_1,0,0)$.
For $x_k=(i,l_0,l_c)$, the state of the Markov decision process now evolves in the following way:
\[
x_{k+1}=f(x_k, u_k, \omega_k):=\begin{cases}
x_{NEW}&\ \text{if }u_k=a_R,\\
\begin{split}(i,l_0+r_i\delta-\min\{l_c,r_i\delta\}&,\\l_c-\min\{l_c,r_i\delta\}&)\end{split}&\ \text{if }u_k=a_W\text{ and }\omega_k=i,\\
(j,l_0,l_c+J_{ij}-r_j\delta)&\ \text{if }u_k=a_W\text{ and }\omega_k=j\neq i,\\
x_{BREAK}&\ \text{if }u_k=a_W\text{ and }\omega_k=\Omega_{BREAK}.\\
\end{cases}
\]
In this definition, we assumed that jumps occur at the start of time intervals.
Again, we use the definition of the random variable $S(x_k):=f(x_k,a_W,\omega_k(x_k))$ as the state after $x_k$.

\subsection{Costs and discounting}
The costs and discounting remain the same as in the age-based maintenance problem.

\subsection{Optimal policy and Bellman equations}
We want to find a stationary policy $\pi= \{\mu_1,...,\mu^N\}$ that chooses the action $u_k=\pi(x_k)=\mu_i(i,l_0,l_c)$ that minimizes the expected total discounted cost $V_\delta(x_k,\pi)$ for each state $x_k=(i,l_0,l_c)$.
Similarly as in the definition of age-based maintenance, $V_\delta(x_k,\pi)$ is given by
\[V_\delta(x_k,\pi)=g(x_k,\pi(x_k))+\alpha_\delta \mathbb{E}[V_\delta(S(x_k),\pi)].\]
The Bellman equations for the optimal cost $V_\delta(x_k,\pi^*)$ read
\begin{equation}\label{eq:MmfmBellman}
V_\delta(x_k,\pi^*)=\begin{cases}
c+a+\alpha_\delta V_\delta(x_{NEW},\pi^*),&\text{ if }x_k=x_{BREAK},\\
\min\left\{\begin{split}&c+\alpha_\delta V_\delta(x_{NEW},\pi^*),\\&\alpha_\delta \mathbb{E}[V_\delta(S(x_k),\pi^*)]\end{split}\right\},&\text{else.}\\
\end{cases}
\end{equation}
$\pi$ is optimal if $V_\delta(x,\pi)=V_\delta(x,\pi^*)$ for all $x\in X$.
$\mathbb{E}[V_\delta(S(x_k),\pi^*)]$ when $x_k\neq x_{BREAK}$ is given by 
\begin{equation}\label{eq:MmfmNextState}
\begin{split}
&\mathbb{E}[V_\delta(S(i,l_0,l_c),\pi^*)]\\
&=\begin{cases}
\begin{split}
&\sum\limits_{j\neq i}(1-e^{-\lambda_i \delta})V_\delta(j,l_0,l_c+J_{ij}-r_j\delta,\pi^*)\\
&+e^{-\lambda_i \delta}V_\delta(i,l_0,l_c-r_i\delta,\pi^*),
\end{split}&\ \text{If $l_c>0$,}\\
\begin{split}
&e^{-\lambda_i \delta} \bar{F}_{t_k}(l_0+r_i\delta)V_\delta(i,l_0+r_i\delta,0,\pi^*)\\
&+ e^{-\lambda_i \delta}F_{t_k}(l_0+r_i\delta)V_\delta(x_{BREAK},\pi^*)\\
&+\sum\limits_{j\neq i}(1-e^{-\lambda_i \delta})V_\delta(j,l_0,J_{ij}-r_j\delta,\pi^*),
\end{split}&\ \text{If $l_c=0$.}\\
\end{cases}\\
&=\begin{cases}
\begin{split}
&\sum\limits_{j\neq i}\lambda_{ij}\delta V_\delta(j,l_0,l_c+J_{ij}-r_j\delta,\pi^*)\\
&+(1-\lambda_i \delta)V_\delta(i,l_0,l_c-r_i\delta,\pi^*)+o(\delta^2),
\end{split}
&\ \text{If $l_c>0$,}\\
\begin{split}
&(1-\lambda_i \delta-\delta r_ih(l_0))V_\delta(i,l_0+r_i\delta,0,\pi^*)\\
&+ \delta r_ih(l_0)V_\delta(x_{BREAK},\pi^*)\\
&+\sum\limits_{j\neq i}\lambda_{ij} \delta V_\delta(j,l_0,J_{ij}-r_j\delta,\pi^*)+o(\delta^2),
\end{split}&\ \text{If $l_c=0$.}\\
\end{cases}
\end{split}
\end{equation}

\subsection{Continuous-time MDP}
Again, we will consider a continuous-time MDP by letting $\delta\rightarrow0$.

\begin{remark}
	Note that the simple fluid model of the previous chapter corresponds to a MMFM model with two states, both with fluid rate $1$, transition rate $\lambda$ and jump size $J$.
	This MMFM is drawn in figure \ref{figure:SimpleFluidAsMmfm}.
	\begin{figure}[H]\label{figure:SimpleFluidAsMmfm}
		\centering
		\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=3cm,
		thick,main node/.style={circle,draw,font=\sffamily\Large\bfseries}]
		
		\node[main node] (1) {$s_1:1$};
		\node[main node] (2) [right of=1] {$s_2:1$};
		
		\path[every node/.style={font=\sffamily\small}]
		(1) edge [bend left] node {$\lambda:J$} (2)
		(2) edge [bend left] node {$\lambda:J$} (1);
		\end{tikzpicture}
		\caption{The MMFM corresponding to the simple fluid problem from the previous chapter.}
	\end{figure}
\end{remark}


\subsection{Alternative models}
Again, there are various alternatives to the design choices that were made in the definition of the MMFM above.
We will briefly mention some alternatives with their characteristics.

\subsubsection{Decisions as jumps only}
Again, we could model the problem so that the choice to repair the asset can only be made at the instant that a transition occurs.
This might be more realistic for similar reasons as for the simple fluid model: The jump could be caused by some mechanic performing some partial maintenance and a mechanic might be needed to completely repair the asset so that CTMC-transitions are the only opportunities to repair the asset.

\subsubsection{Transitions to the same state}
We could also allow transitions from certain CTMC-states to themselves (again at exponentially distributed time intervals).
This could simply be modeled by adding a copy $s'$ for each of these states $s$ to the CTMC (with the same outgoing transitions) and transitions between $s$ and $s'$ with the desired transition rate and jump size.

\subsection{Transitions in a semi-Markov process}
Instead of exponentially distributed time intervals between transitions we could also consider a semi-Markov model where the distributions of the transition times are not exponential.
This complicates the model as we lose the memorylessness property, so that we must keep track of the time from the last transition.

\subsubsection{Second-order fluid model}
Similarly to the second-order fluid model of \cite{Gribaudo2007}, we could model the depletion of fluid (in between jumps) as Brownian motion.
This would make the model more complicated but might also make it more realistic. \section{Structure of optimal policy}
In this section, we will establish that for the MMFM preventive maintenance problem, the optimal policy is a stationary policy to repair in CTMC-state $s_i$ whenever the buffer $L_c$ is empty and the used initial fluid $L_0$ exceeds a certain control limit $\mu_i^*$.
Note that 'stationary' in this sense means independent of the time. 
The control limit does depend on the state of the CTMC.

\subsection{Stationary policy}
By the same reasoning as for the previous chapter, we can prove that every discrete approximation of the continuous-time MDP has a countable state space so that section 6.2.4 of \cite{Puterman2008} again proves that the there exists a stationary policy that is discount-optimal.

\subsection{Empty buffer}
By the same reasoning as for the simple fluid problem, an optimal policy will never perform preventive maintenance if the buffer $L_c$ is non-empty.

\subsection{Control limit}
Compared to the previous problem, proving that the optimal policy is a control limit policy is slightly more difficult:
In the simple fluid problem, it was never possible to reach states 'after the control limit' so that it wasn't relevant whether for higher fluid levels repair should also always be chosen.
For this problem, it is possible that these states are reached.
This is illustrated by the following example:
\begin{example}
	Consider a MMFM with two states and control limits $\mu_1<l<\mu_2$ for some $q$.
	If at some time $t$, $X(t)=(2,l,L_c(t))$, then it is possible that for some $t'>t$, $X(t')=(1,l,0)$ so that $L_0(t')>\mu_1$ and the control limit is exceeded.
\end{example}
Although no rigorous proof was found that asserts the optimal policy is a control limit on $L_0$, results from value iteration seem to suggest that this is always the case.
This also seems natural as for states with used initial fluid $L_0$ higher than the control limit, the asset is in a worse condition than at the control limit and is more likely to fail earlier so that repair would still be chosen after the control limit.

Hence, we will consider stationary policies of the form $\pi=[\mu_1,...,\mu_N]$, where preventive repair is chosen in states $x=(i,l_0,l_c)\in X$ if and only if $l_c=0$ and $l_0\geq \mu_i$. \section{Computation of total discounted cost}
In this section, the expected total discounted cost when using a control limit policy $\pi=[\mu_1,...,\mu_N]$ is calculated.

Similar to \eqref{eq:SimpleFluidDiscountDefinition}, but keeping in mind that there are multiple CTMC-states, we define
\[
D_{i}^t(q):=\mathbb{E}[e^{-\beta T_t(q)}|S(t)=i],
\]
as the expected discount over the time until the fluid level $Q(t)$ is decreased by $q$, given that it starts in $s_i$.
In this definition, we disregard failures and policies (i.e. we briefly assume that $Q_0=\infty$ and all control limits $\mu_i=\infty$).
Furthermore, we define
\[
D_{ij}^t(q):=\mathbb{E}[e^{-\beta T_t(q)}\mathds{1}\{S(t+T_t(q))=j\}|S(t)=i].
\]
Note that these expectations do not depend on calendar time but only on the state of the background CTMC when the fluid is at level $Q(t)$.
Hence, we will omit $t$ in these notations.
Note that
\[
D_{i}(q)=\sum\limits_{j}D_{ij}(q).
\]
When we take the policy $\pi=[\mu_1,...,\mu_N]$ into account, states cannot be reached via paths that go over a control limit.
We define similar quantities:
\[
\begin{split}
&D_{ij}^t(q,\pi,l)\\
&:=\mathbb{E}\left[e^{-\beta T_t(q)}\mathds{1}\left\{\begin{split}
&S(t+T_t(q)=j),\\
&\forall \tau\in[t,t+T_t(q)):
\begin{split}
&L_c(\tau)>0\\&\vee L_0(\tau)<\mu_{S(\tau)}
\end{split}
\end{split}\right\}\middle| S(t)=i,L_0(t)=l\right],
\end{split}
\]
and
\[
D_{i}^t(q,\pi,l):=\sum\limits_{\mu_j\leq l+q}D_{ij}^t(q,\pi,l).
\]
Where these are similar to the earlier defined $D_{ij}$ but without the asset being repaired before fluid level $Q(t)-q$ is reached.
These expectations also do not depend on $t$.
Hence, $t$ will again be omitted in the notation.
If preventive repair is chosen, then it is chosen when $L_0$ equals some random variable $R$.
We define the following quantity
\[
\begin{split}
\Gamma_i^t(q,\pi,l):=\lim\limits_{\delta\rightarrow 0}\frac1\delta&\mathbb{P}(q\leq R<q+\delta|S(t)=i,L_0(t)=l)\\
&\times\mathbb{E}[e^{-\beta T_t(R)}|q\leq R<q+\delta,S(t)=i,L_0(t)=l].
\end{split}
\]
The interpretation of this quantity can be difficult, it could be seen as the density of $R$ multiplied by the expected discount factor given that repair is chosen at this level of $L_0$.
Note that $\Gamma_i^t(q,\pi)$ also does not depend on $t$ so that $t$ will again be omitted in the notation.
\begin{remark}
	These defined quantities should be interpreted as neither probabilities nor discount factors but more as a combination of these two: The expected discount factor given some event, multiplied by the probability (or density) of this event.
	We will refer to $D_{ij},D_{i}(q,\pi)$ and $D_{i}(q,\pi,l)$ as 'discounted probabilities' and $\Gamma_i(q,\pi,l)$ as a 'discounted density'.
\end{remark}
These discount quantities will be computed in the next section.
We will now derive the expected total discounted cost of a policy $\pi$.
Each run of the asset can end in two ways:
\begin{enumerate}
	\item The asset breaks,
	\item or preventive maintenance is chosen.
\end{enumerate}
We will split the total discounted cost in terms corresponding to these two scenarios.

\subsubsection{The asset breaks}
When the asset breaks, it means that $L_0(t)$ has reached $Q_0$ without encountering a control limit.
Hence, the repair costs are discounted at $D_0(Q_0,\pi,0)$.
The expected value of this, is given by
\[
\mathbb{E}[D_{i}(Q_0,\pi,0)]=\int\limits_0^\infty f(q)D_{i}(q,\pi,0)dq.
\]
We get the following term in the expression of the total discounted cost
\[
\mathbb{E}[D_{i}(Q_0,\pi,0)](c+a+V(x_{NEW},\pi)).
\]

\subsection{Preventive maintenance is chosen}
When preventive maintenance is chosen, it can either be chosen in a state $x=(i,l_0,0)\in X$ where
\begin{enumerate}
	\item $l_0=\mu_i$, preventive maintenance is chosen 'at the control limit';
	\item or $l_0>\mu_i$, preventive maintenance is chosen 'after the control limit'.
\end{enumerate}
We will again split the total discounted cost in terms corresponding to these two scenarios.

\subsubsection{Preventive maintenance is chosen at the control limit}
In this case, repair is chosen in a state $s_i$ with $l_0=\mu_i$.
For this to happen, it must be the case that $Q_0>\mu_i$, with probability $\bar{F}(\mu_i)$.
Preventive maintenance has a cost $c$, discounted at $D_{i}(\mu_i,\pi,0)$.
Hence, we get the following term:
\[
\sum\limits_i\bar{F}(\mu_i)D_{i}(\mu_i,\pi,0)(c+V(x_{NEW},\pi)).
\]

\subsubsection{Preventive maintenance is chosen after the control limit}
In this case, repair is chosen in some CTMC-state $s_i$ and $l_0>\mu_i$.
For this to be able to happen, $Q_0>l_0$ must hold with probability $\bar{F}(l_0)$.
This event would have cost $c$ and discounted density $\Gamma_0(l_0,\pi,0)$.
Hence, this results in the following term:
\[
\left[\int\limits_0^\infty \bar{F}(q)\Gamma_0(q,\pi,0)dq\right](c+V(x_{NEW},\pi)).
\]
Concluding:
\begin{theorem}
	The expected total discounted cost of a policy $\pi$ is given by
	\begin{equation}\label{eq:MmfmTDC}
	\begin{split}
	V(x_{NEW},\pi)=&\mathbb{E}[D_{i}(Q_0,\pi,0)]\left(c+a+V(x_{NEW},\pi)\right)\\
	&+\left[\int\limits_0^\infty \bar{F}(q)\Gamma_0(q,\pi,0)dq+\sum\limits_i\bar{F}(\mu_i)D_{i}(\mu_i,\pi,0)\right]\left(c+V(x_{NEW},\pi)\right).
	\end{split}
	\end{equation}
\end{theorem} \section{Computation of discounted probabilities}
In this section, we will show how to compute the discounted probabilities $D_{ij}(q,\pi,l)$ and $D_{i}(q,\pi,l)$ and the discounted density $\Gamma_i(q,\pi,l)$.
We will do this, by first deriving $D_{ij}(q)$.

\begin{remark}
Note that
\[
D_i^t(q)=\mathbb{E}[e^{-\beta T_t(q)}|S(t)=i]
\]	
equals the value of the moment generating function of $T_t(q)$ (conditioned on $S(t)=i$) evaluated at $-\beta$.
Furthermore, when all jump quantities are 0 (i.e. $J_{ij}=0$ for all $i,j$), $T_t(q)$ corresponds to the busy period of the fluid flow process considered in \cite{Asmussen1994}. 
\cite{Asmussen1994} derives the moment generating function of this busy period, which also corresponds to our results.
\end{remark}

\subsection{Disregarding failures and policies}
We repeat the definition of $D_{ij}(q)$:
\[
D_{ij}^t(q):=\mathbb{E}[e^{-\beta T_t(q)}\mathds{1}\{S(t+T_t(q))=j\}|S(t)=i].
\]
We will now prove a few properties regarding $D_{ij}(q)$:
\begin{lemma}\label{lemma:MmfmDiscountsExponentLinear}
	\[
	D_{ij}(A+B)=\sum\limits_k D_{ik}(A)D_{kj}(B)
	\]
	\begin{proof}
		At the time when the fluid level has decreased by $A$, the process must be in some CTMC-state $s_k$.
		Furthermore, the time until the fluid is decreased by $A$ is independent of the time until the fluid is decreased by $A$ because of the Markov property.
	\end{proof}
\end{lemma}
\begin{lemma}\label{lemma:MmfmDiscountsInfinitisimal}
	For small $\delta$, $D_{ij}(\delta r_i)$ is given by
	\[
	D_{ij}(\delta r_i)=(1-\delta\lambda_i-\delta\beta)\mathds{1}\{i=j\}+\sum\limits_{k\neq i}\delta\lambda_{ik}D_{kj}(J_{ik})+o(\delta^2).
	\]
	\begin{proof}
		In a time period of length $\delta$, either a transition occurs to some state $s_k$ ($k\neq i$) or no transition occurs.
		These have probabilities $\delta\lambda_{ik}+o(\delta^2)$ and $1-\delta\lambda_i+o(\delta^2)$ respectively.
		When a transition from $s_i$ to $s_k$ occurs, the fluid level increases by $J_{ik}$.
		Over this time interval, the discount factor is $1-\delta\beta$.
		Furthermore, $D_{ij}(0)=\mathds{1}\{i=j\}$.
		Putting these together results in
		\[
		\begin{split}
		D_{ij}(\delta r_i)&=(1-\delta\lambda_i)(1-\delta\beta)\mathds{1}\{i=j\}+\sum\limits_{k\neq i}\delta(1-\delta\beta)\lambda_{ik}D_{kj}(J_{ik})+o(\delta^2)\\
		&=(1-\delta\lambda_i-\delta\beta)\mathds{1}\{i=j\}+\sum\limits_{k\neq i}\delta\lambda_{ik}D_{kj}(J_{ik})+o(\delta^2).
		\end{split}
		\]
	\end{proof}
\end{lemma}
\begin{lemma}
	$D_{ij}$ adheres to the following differential equation:
	\begin{equation}\label{eq:MmfmDiscountDifferential}
	r_i\frac{d}{dq}D_{ij}(q)=\sum\limits_m\left[\sum\limits_{k\neq i}\lambda_{ik}D_{km}(J_{ik})\right] D_{mj}(q)-(\lambda_i+\beta)D_{ij}(q)
	\end{equation}
	\begin{proof}
		First we write
		\[
		\begin{split}
		D_{ij}(q+\delta r_i)&=\sum_mD_{im}(\delta r_i)D_{mj}(q)\\
		&=\sum\limits_m\left[(1-\delta\lambda_i-\delta\beta)\mathds{1}\{i=j\}+\sum\limits_{k\neq i}\delta\lambda_{ik}D_{kj}(J_{ik})+o(\delta^2)\right]D_{mj}(q)\\
		&=(1-\delta\lambda_i-\delta\beta)D_{ij}(q)+\sum\limits_m\left[\sum\limits_{k\neq i}\delta\lambda_{ij}D_{kj}(J_{ik})\right]D_{mj}(q)+o(\delta^2)\\
		&=D_{ij}(q)+\delta\left( \sum\limits_m\left[\sum\limits_{k\neq i}\lambda_{ik}D_{km}(J_{ik})\right] D_{mj}(q)-(\lambda_i+\beta)D_{ij}(q) \right)+o(\delta^2).\\
		\end{split}
		\]
		If we then subtract $D_{ij}(q)$ from both sides, divide by $\delta$ and let $\delta\rightarrow 0$, we get
		\[
		\begin{split}
		\lim\limits_{\delta\rightarrow 0}\frac{D_{ij}(q+\delta r_i)-D_{ij}(q)}{\delta}&=r_i\frac{d}{dq}D_{ij}(q)\\
		&=\sum\limits_m\left[\sum\limits_{k\neq i}\lambda_{ik}D_{km}(J_{ik})\right] D_{mj}(q)-(\lambda_i+\beta)D_{ij}(q).
		\end{split}
		\]
	\end{proof}
\end{lemma}
Hence, the derivative of $D_{ij}$ is a linear combination of $D_{kj}$.
This suggests defining the following matrix:
\begin{equation}\label{eq:MmfmDiscountGenerator}
\begin{split}
\Lambda^D_{im}:=\begin{cases}
\sum\limits_{k\neq i}\frac{\lambda_{ik}}{r_i}D_{km}(J_{ik})-\frac{(\lambda_i+\beta)}{r_i}&\text{ if }i=m\\
\sum\limits_{k\neq i}\frac{\lambda_{ik}}{r_i}D_{km}(J_{ik})&\text{ else.}
\end{cases}
\end{split}
\end{equation}
Furthermore, if we let $D(q)$ be the matrix with entries $D_{ij}(q)$, we can solve the differential equation \eqref{eq:MmfmDiscountDifferential} in the following way:
\begin{theorem}
	For $\Lambda^D$ as defined above, the solution to differential equation \eqref{eq:MmfmDiscountDifferential} is given by
	\begin{equation}\label{eq:MmfmDiscountMatrixSolution}
	D(q)=e^{\Lambda^D q}.
	\end{equation}
	So that the discounted probability of going from state $i$ to $j$ while $Q(t)$ decreases by $q$, is given by
	\begin{equation}\label{eq:MmfmDiscountEntrySolution}
	D_{ij}(q)=\left(e^{\Lambda^D q}\right)_{ij}.
	\end{equation}
	\begin{proof}
		The differential equation \eqref{eq:MmfmDiscountDifferential} can be rewritten to
		\[
			\frac{d}{dq}D_{ij}(q)=\sum\limits_m\Lambda^D_{im}D_{mj}(q).
		\]
		So that for the matrix $D(q)$, we have the following matrix differential equation
		\[
		\frac{d}{dq}D(q)=\Lambda^D D(q),
		\]
		of which \eqref{eq:MmfmDiscountMatrixSolution} is a solution.
		This combined with $D(0)=I$ completes the proof.
	\end{proof}
\end{theorem}

\begin{remark}
	To compute \eqref{eq:MmfmDiscountMatrixSolution}, we still need the constants $D_{km}(J_{ik})$.
	These $N^3$ values can be estimated using a method of successive approximation where iteratively these values $D_{km}(J_{ik})$ are calculated using \eqref{eq:MmfmDiscountMatrixSolution}.
	For the problem parameters that we used, ten iterations were enough to make these values converge for up to five decimals.
\end{remark}

\begin{remark}\label{remark:MmfmStochasticShortestPath}
	As $L_0(t)$ increases continuously when $L_c(t)=0$ and is constant when $L_c(t)>0$, we know that in each run of the asset for each value $l_0\geq0$, there exists a $t$ so that $L_0(t)=l_0$.
	If we omit all time intervals where $L_c(t)>0$, we can view the asset as a CTMC over $L_0$.
	That is, for the first run of the asset, we consider a CTMC $S^*(l_0)$ where
	\[
	S^*(l_0):=S(\min\{\tau|L_c(\tau)=0\wedge L_0(\tau)=l_0\}).
	\]
	When we would start in a state $s_i$ and pay a certain cost when $X(t)=(i,l_0,0)$, the expected value at which this cost would be discounted, would correspond to \eqref{eq:MmfmDiscountEntrySolution}.
	Transition probabilities of $S^*$ are given by generator $e^{\Lambda^D}$ for $\beta=0$.
	Viewing the process as this adjusted CTMC helps understanding the problem.
\end{remark}

\subsection{Taking policies into account}
When we take policies into account, the following complication arises in computing $D_{ij}(q, \pi,l)$:
In the path from $s_i$ to $s_j$, no state $s_k$ must be visited when $L_0(t)>\mu_k$.
This is summarized by the following lemma.
\begin{lemma}
	Similar to lemma \ref{lemma:MmfmDiscountsExponentLinear}, we have
	\[
	D_{ij}(A+B,\pi,l)=\sum\limits_{\mu_k>l+A} D_{ik}(A,\pi,l)D_{kj}(B,\pi,l+A)
	\]
	\begin{proof}
		The reasoning is the same as for lemma \ref{lemma:MmfmDiscountsExponentLinear}, but with the addition that we also need to keep into account that $L_0$ has been increased by $A$, this explains the $l+A$ on the right hand side.
	\end{proof}
\end{lemma}

\begin{lemma}
	For small $\delta$, we have
	\[
	D_{ij}(r_i\delta,\pi,l)=(1-\delta\lambda_i)\mathds{1}\{i=j\}+\sum\limits_{\mu_k>l+r_i\delta}\delta\lambda_{ij}D_{kj}(J_{ik})+o(\delta^2).
	\]
	\begin{proof}
		The reasoning is the same as in lemma \ref{lemma:MmfmDiscountsInfinitisimal}, but now we know that for $\mu_k\leq l+\delta r_i$, we have that $D_{kj}(J_{ik},\pi,l+\delta r_i)=0$.
	\end{proof}
\end{lemma}
Which suggests that we should replace the generator $\Lambda^D$ by a $\Lambda^D(l_0)$ dependent of the amount of used fluid $l_0$:
\begin{equation}
\begin{split}
\Lambda^D_{im}(l_0,\pi):=\begin{cases}
0&\text{ if }\mu_i<l_0\\
\Lambda^D_{im}&\text{ else.}
\end{cases}
\end{split}
\end{equation}
$D_{ij}(q, \pi,l)$ can now be calculated in the following straightforward way:
\begin{theorem}
	The discounted probabilities $D_{ij}(q, \pi,l)$ are given by
	\[
	D_{ij}(q, \pi,l)=\left(e^{\int_l^{l+q}\Lambda^D(x,\pi)dx}\right)_{ij}.
	\]
\end{theorem}
Now we will calculate the discounted density $\Gamma_i(q,\pi,l)$:

$\Gamma_i^t(q,\pi,l)$ corresponds to repairing when the fluid level $Q(t)$ reaches $Q(t)-q$.
The discounted probability of reaching fluid level $Q(t)-q$ in state $s_j$ equals $D_{ij}(q, \pi,l)$.
When the process reaches this state, the asset can be repaired by transitioning to a CTMC-state $s_k$ where the control limit has already been exceeded.
However, the presence of jumps complicates this:
If the transition from $s_j$ to $s_k$ has a fluid jump, then repair won't be chosen immediately.
This problem is solved by using transition rates $\Lambda^D_kj$ instead of $\lambda_{kj}$ since, referring back to remark \ref{remark:MmfmStochasticShortestPath}, are not interested in time intervals where the buffer $L_c$ is nonempty.
Concluding:

\begin{theorem}
	The discounted density corresponding to repairing when $L_0(t)=l+q$ given that initially the process is in CTMC-state $s_i$ with used initial fluid $l$ is given by
	\[
	\Gamma_i(q,\pi,l)=\sum\limits_{\mu_j>l+q}D_{ij}(q,\pi,l)\sum\limits_{\mu_k<l+q}\Lambda_{jk}^D.
	\]
\end{theorem}


%
 \section{The optimal policy}
In this section, we will analytically derive the control limits for the optimal MMFM maintenance policy.
This will be done using the Bellman equations.

If the optimal control limit in state $s_i$ is given by $\mu_i^*$, then in the state $x=(s_i,\mu_i^*,0)$ where repair is chosen, it holds that the expected cost of waiting one more time step of size $\delta$ is at least as large as the expected cost of repairing.
The repair cost equals $c+V(x_{NEW},\pi^*)$ and by \eqref{eq:MmfmNextState}, the cost of waiting equals
\[
\begin{split}
&(1-\lambda_i \delta-\delta r_ih(\mu_i^*))V_\delta(i,\mu_i^*+r_i\delta,0,\pi^*)\\
&+ \delta r_ih(\mu_i^*)V_\delta(x_{BREAK},\pi^*)\\
&+\sum\limits_{j\neq i}\lambda_{ij} \delta V_\delta(j,\mu_i^*,J_{ij}-r_j\delta,\pi^*)+o(\delta^2).
\end{split}
\]
So we know that
\[
\begin{split}
c+V(x_{NEW},\pi^*)\leq 
&(1-\lambda_i \delta-\delta r_ih(\mu_i^*))V_\delta(i,\mu_i^*+r_i\delta,0,\pi^*)\\
&+ \delta r_ih(\mu_i^*)V_\delta(x_{BREAK},\pi^*)\\
&+\sum\limits_{j\neq i}\lambda_{ij} \delta V_\delta(j,\mu_i^*,J_{ij}-r_j\delta,\pi^*)+o(\delta^2).
\end{split}
\]
Also, $V_\delta(x_{BREAK},\pi^*)=c+a+V_\delta(x_{NEW},\pi^*)$ and $V_\delta(i,\mu_i^*+r_i\delta,0,\pi^*)=c+V_\delta(x_{NEW},\pi^*)$ as repair is chosen next.
Substituting this, we get
\[\begin{split}
c+V(x_{NEW},\pi^*)\leq
&(1-\lambda_i \delta-\delta r_ih(\mu_i^*))(c+V(x_{NEW},\pi^*))\\
&+ \delta r_ih(\mu_i^*)(c+a+V(x_{NEW},\pi^*))\\
&+\sum\limits_{j\neq i}\lambda_{ij} \delta V_\delta(j,\mu_i^*,J_{ij}-r_j\delta,\pi^*)+o(\delta^2).
\end{split}
\]
Subtracting $c+V(x_{NEW},\pi^*)$ from both sides, dividing by $\delta$ and rewriting yields
\[
r_ih(\mu_i^*)a+\sum\limits_{j\neq i}\lambda_{ij} V_\delta(j,\mu_i^*,J_{ij}-r_j\delta,\pi^*)\geq
(\beta+\lambda_i)(c+V(x_{NEW},\pi^*))+o(\delta).
\]
If we were to do the same but starting at a state $x'=(s_i,\mu_i^*-r_i\delta,0)$ (i.e. just before the control limit is reached) so we know that the cost of waiting is smaller than the cost of preventive maintenance, we would get
\[
r_ih(\mu_i^*)a+\sum\limits_{j\neq i}\lambda_{ij} V_\delta(j,\mu_i^*,J_{ij}-r_j\delta,\pi^*)<
(\beta+\lambda_i)(c+V(x_{NEW},\pi^*))+o(\delta).
\]
Which together proves the following theorem:
\begin{theorem}
	If for the optimal control limit policy $\pi^*=[\mu_1^*,...,\mu_N^*]$ the control limit in CTMC-state $s_i$ is finite (i.e. $\mu_i^*<\infty$), then the following equation holds 
	
	\begin{equation}\label{eq:MmfmHazardBounds}
	r_ih(\mu_i^*)a+\sum\limits_{j\neq i}\lambda_{ij} V(j,\mu_i^*,J_{ij},\pi^*)=
	(\beta+\lambda_i)(c+V(x_{NEW},\pi^*)).
	\end{equation}
\end{theorem}
\begin{remark}
	We can rewrite the expected costs $V(j,\mu_i^*,J_{ij},\pi^*)$ in \eqref{eq:MmfmHazardBounds} to
	\[
	V(j,\mu_i^*,J_{ij},\pi^*)=\sum\limits_k D_{jk}(J_{ij},\pi,\mu_i^*)V(j,\mu_i^*,0,\pi^*),
	\]
	using the discounted probability $D_{jk}(J_{ij},\pi,\mu_i^*)$ that the process will be in CTMC-state $s_k$ when the buffer $L_c$ is emptied.
\end{remark}

\begin{remark}
	It is difficult to compute the control limits $\mu_i^*$ analytically since the total discounted costs depend on the control limit and the control limit depends on the total discounted costs.
\end{remark}

\begin{remark}
Note that using the generator matrix $\Lambda^D$ defined by \eqref{eq:MmfmDiscountGenerator}, equation for the optimal policy \eqref{eq:MmfmHazardBounds} could also be written as

\begin{equation}\label{eq:MmfmHazardBoundsShort}
h(\mu_i^*)a+\sum\limits_j\Lambda^D_{ij}V(j,\mu_i^*,0,\pi^*)=0.
\end{equation}
\end{remark}

\begin{remark}
Note that equation \eqref{eq:MmfmHazardBounds} is similar to the equation for the optimal control limit of the previous problems in the sense that it has a constant right-hand side and an increasing left hand side.
\end{remark} \section{Structural properties}\label{section:MmfmStructuralProperties}
In this section, the effect of changing the parameters to the expected total discounted cost and the control limits are investigated.
These structural properties are mostly similar to the simple fluid problem.
The main difference is that there are multiple control limits for the various CTMC-states and that the control limit in a certain state is also influenced by the costs in other states.

\begin{remark}
	Referring back to the equation for the optimal control limit $\mu_i^*$ for a CTMS-state $s_i$ \eqref{eq:MmfmHazardBoundsShort}: if some change of the parameters would cause an increase in the expected remaining cost for some state $s_j$ that neighbors $s_i$ in the CTMC defined by the generator $\Lambda^D$ (i.e. if $\Lambda^D_{ij}>0$), then $\Lambda^D_{ij}V(j,\mu_i^*,0,\pi^*)$ would increase so that the hazard at which repair is chosen must decrease.
	This results in a lower control limit.
\end{remark}

Furthermore, there are also different fluid rates for different CTMC-states:
\begin{remark}
	An increase in the fluid rate $r_i$ for some state $s_i$ increases the hazard in that state.
	This results in a lower control limit, as one would expect as a higher fluid rate corresponds to the asset deteriorating quicker in that state.
\end{remark}

Again, appendix \ref{AppendixComputationsTable} contains computed values of the optimal control limit and the corresponding expected total discounted cost. \section{Heuristic policies}\label{section:MmfmHeuristics}
As it is difficult to find an optimal policy that satisfies \eqref{eq:MmfmHazardBoundsShort}, it might be useful to find heuristic policies that minimize the expected total discounted cost reasonably well.

\subsection{Uniform control limit}
If the CTMC-states are similar to each other (i.e. similar fluid rates, transition rates and jump sizes), then we could also just use the same control limit $\mu$ for all the CTMC-states.
This would simplify the expressions 
Finding the policy that minimizes the cost within this class of control limit policies would be relatively easy.
The expected total discounted cost would be
\[
V(x_{NEW},\mu)=\int\limits_0^\mu f(x)D_0(x)dx (c+a+V(x_{NEW},\mu))+\bar{F}(\mu)D_0(\mu)(c+V(x_{NEW},\mu)),
\]
which is easier to minimize numerically than \eqref{eq:MmfmTDC}.
This heuristic would be a crude estimation of the optimal policy if the  CTMC-states are not very similar. 
The heuristic was implemented in Matlab and the resulting policies and total discounted costs were compared with the exact solutions.
The results can be found in appendix \ref{AppendixComputationsTable}.

\subsection{Assuming no jumps before the next failure}
When we compare the equation for the optimal policy of age-based maintenance \eqref{eq:AgeBasedHazardBound} with that of the MMFM problem \eqref{eq:MmfmHazardBounds},
we see that these two differ mostly by the term 
\[
\sum\limits_{j\neq i}\lambda_{ij}V(j,\mu_i^*,J_{ij},\pi^*).
\]
This term is caused by the possibility that a jump would occur around the time the control limit is reached.
If we would simply assume that no jump would occur before the next failure, we could omit this term and the problem would be easier to solve.
This heuristic results in an adjusted equation for the optimal control limits:
\[
r_ih(\mu_i^*)a=\beta(c+V(x_{NEW},\pi^*)).
\]
\begin{remark}
	Note that using this heuristic, all states with the fluid rate limit would have the same control limit, regardless of their outgoing edges.
\end{remark}
This heuristic was implemented in Matlab and the resulting policies and total discounted costs were compared with the exact solutions.
The results can be found in appendix \ref{AppendixComputationsTable}.
It turns out that the performance of this heuristic depends a lot on the size and frequencies that jumps would otherwise occur at.
For instance, if transitions would occur frequently and the jump sizes are large, then this heuristic is would be crude and the difference in control limit and cost would be significant. \section{Computing the optimal control limits}
In this section, a numeric method will be introduced to compute control limits that satisfy \eqref{eq:MmfmHazardBounds}.
The expected total discounted cost will also be computed.
The method is similar to the successive approximation method that has been presented in section \ref{section:AgeBasedOptimalPolicyComputation} for the problem of age-based maintenance.

From \eqref{eq:MmfmHazardBoundsShort}, we know that if a policy $\hat\pi=[\hat\mu_1,...,\hat\mu_N]$ $\hat{\mu}$ satisfies
\[
h(\hat\mu_i)a+\sum\limits_j\Lambda^D_{ij}V(j,\mu_i^*,0,\pi^*)=0,\]
then $\hat{\pi}=\pi^*$.
The total discounted cost would then be given by \eqref{eq:MmfmTDC}.
This suggests the following iteration method:
At the $k+1$'th iteration, we will update the estimates of the optimal control limits $\mu_i^*$ by finding the $\hat{\pi}_i^{(k+1)}=[\hat{\mu}_i^{(k+1)},...,\hat{\mu}_i^{(k+1)}]$ that minimizes
\[
\begin{split}
\hat{V}^{(k+1)}=&\mathbb{E}[D_{i}(Q_0,\hat\pi^{(k+1)},0)](c+a+\hat{V}^{(k)})\\
&+\left[\int\limits_0^\infty \bar{F}(q)\Gamma_0(q,\hat\pi^{(k+1)},0)dq+\sum\limits_i\bar{F}(\hat\mu_i^{(k+1)})D_{i}(\hat\mu_i,\hat\pi^{(k+1)},0)\right](c+\hat{V}^{(k)}),
\end{split}
\]
where $\hat{V}^{(k)}$ is the current estimate of $V(0^+,\pi^*)$.
This could be found by looking for the control limits that satisfy
\begin{equation}
h(\hat\mu_i)a+\sum\limits_j\Lambda^D_{ij}\hat V(j,\mu_i^{(k)},0,\pi^{(k)})=0.
\end{equation}
For this iteration, we also need an initial value of the expected total discounted cost $\hat{V}^{(0)}$.
Although we do not have a proof for the convergence of this iteration method, for the problem parameters that were used, it did converge to solutions similar to those attained via value iteration. 
\chapter{Data analysis}\label{chapter:DataAnalysis}
In this chapter, the data from the Philips machine will be investigated.
First, the data will be described and visualized, then we will attempt to fit the lifetimes of the machine to various lifetime distributions.
\section{Data description}
The data from the Philips machine contains information about which operation the machine was performing at each time.
The data is anonimized so that for each operation, no name or description is given, but only an identifier.
\subsection{Data format}
Each run of the machine is represented by a trace.
A trace is a sequence of events.
These events are either the start or the end of an operation.
Each event has a timestamp and an integer representing the identifier of the operation.
The breakdown of the machine is represented by the end of a trace.
The lifetime of the machine is then the length of the time interval between the start of the first event and the end of the last event.

\subsection{Cleaning}
Before the data could be used, it first needed to be cleaned.
Because of the transitions between summer and winter time, a few events ended before they started.
We resolved this by simply ignoring the traces for which there was such an event.
Furthermore, there were some other events with a time length of $-1$ seconds, these traces were also ignored.

\subsection{Visualization}
We will now visualize the distribution of the lengths of the runs of the machine.
In figure \ref{figure:distribution}, the empirical cumulative distribution function and the probability density function are plotted.
In these plots it is visible that the distribution has its mode around five days and has a part with a less steep downward slope around 6.5 days.
This part on the right hand side of the mode could be caused by intermediate repairs.
\begin{figure}[H]
	\setlength\fwidth{0.4\textwidth}
	\definecolor{mycolor1}{rgb}{0.00000,0.44700,0.74100}
\begin{tikzpicture}

\begin{axis}[
width=0.951\fwidth,
height=0.75\fwidth,
at={(0\fwidth,0\fwidth)},
scale only axis,
xmin=3,
xmax=9,
xlabel style={font=\color{white!15!black}},
xlabel={Lifetime (d)},
ymin=0,
ymax=1,
ylabel style={font=\color{white!15!black}},
ylabel={Probability},
axis background/.style={fill=white}
]
\addplot [color=mycolor1, forget plot]
  table[row sep=crcr]{
3.65539351851852	0\\
3.65539351851852	0.00431034482758619\\
3.88612268518519	0.00862068965517238\\
4.04607638888889	0.0129310344827586\\
4.05780092592593	0.0172413793103448\\
4.05827546296296	0.0215517241379309\\
4.06336805555556	0.0258620689655171\\
4.16209490740741	0.0301724137931033\\
4.16583333333333	0.0344827586206895\\
4.16824074074074	0.0387931034482757\\
4.17811342592593	0.0431034482758619\\
4.23090277777778	0.0474137931034481\\
4.23425925925926	0.0517241379310343\\
4.34474537037037	0.0560344827586204\\
4.34844907407407	0.0603448275862066\\
4.35103009259259	0.0646551724137928\\
4.39923611111111	0.068965517241379\\
4.40034722222222	0.0732758620689652\\
4.40402777777778	0.0775862068965514\\
4.45054398148148	0.0818965517241376\\
4.45975694444444	0.0862068965517238\\
4.46435185185185	0.0905172413793101\\
4.46532407407407	0.0948275862068964\\
4.51805555555556	0.0991379310344825\\
4.51966435185185	0.103448275862069\\
4.52009259259259	0.107758620689655\\
4.52246527777778	0.112068965517241\\
4.52336805555556	0.116379310344827\\
4.52395833333333	0.120689655172413\\
4.57143518518519	0.125\\
4.57194444444444	0.129310344827586\\
4.57393518518519	0.133620689655172\\
4.5762962962963	0.137931034482758\\
4.57699074074074	0.142241379310344\\
4.58032407407407	0.146551724137931\\
4.58097222222222	0.150862068965517\\
4.58162037037037	0.155172413793103\\
4.61822916666667	0.159482758620689\\
4.62917824074074	0.163793103448275\\
4.62978009259259	0.168103448275862\\
4.63076388888889	0.172413793103448\\
4.63206018518519	0.176724137931034\\
4.63226851851852	0.18103448275862\\
4.6349537037037	0.185344827586206\\
4.63815972222222	0.189655172413793\\
4.68565972222222	0.193965517241379\\
4.6862962962963	0.198275862068965\\
4.6946412037037	0.202586206896551\\
4.69556712962963	0.206896551724137\\
4.74951388888889	0.211206896551724\\
4.75083333333333	0.21551724137931\\
4.75155092592593	0.219827586206896\\
4.80350694444444	0.224137931034482\\
4.80724537037037	0.228448275862068\\
4.81015046296296	0.232758620689655\\
4.81168981481482	0.237068965517241\\
4.8565162037037	0.241379310344827\\
4.85902777777778	0.245689655172413\\
4.86289351851852	0.249999999999999\\
4.86568287037037	0.254310344827586\\
4.86581018518519	0.258620689655172\\
4.86608796296296	0.262931034482758\\
4.86652777777778	0.267241379310344\\
4.8666087962963	0.271551724137931\\
4.86809027777778	0.275862068965517\\
4.86835648148148	0.280172413793103\\
4.86905092592593	0.284482758620689\\
4.869375	0.288793103448275\\
4.91210648148148	0.293103448275862\\
4.9234837962963	0.297413793103448\\
4.92386574074074	0.301724137931034\\
4.92396990740741	0.30603448275862\\
4.9243287037037	0.310344827586206\\
4.9250462962963	0.314655172413793\\
4.92568287037037	0.318965517241379\\
4.92667824074074	0.323275862068965\\
4.97186342592593	0.327586206896551\\
4.98336805555556	0.331896551724137\\
4.98383101851852	0.336206896551724\\
5.02824074074074	0.34051724137931\\
5.03604166666667	0.344827586206896\\
5.03638888888889	0.349137931034482\\
5.0368287037037	0.353448275862068\\
5.03813657407407	0.357758620689654\\
5.03834490740741	0.362068965517241\\
5.03850694444444	0.366379310344827\\
5.03966435185185	0.370689655172413\\
5.03972222222222	0.374999999999999\\
5.03991898148148	0.379310344827585\\
5.04091435185185	0.383620689655172\\
5.04208333333333	0.387931034482758\\
5.04222222222222	0.392241379310344\\
5.08837962962963	0.39655172413793\\
5.09479166666667	0.400862068965516\\
5.09842592592593	0.405172413793103\\
5.0990162037037	0.409482758620689\\
5.09925925925926	0.413793103448275\\
5.14765046296296	0.418103448275861\\
5.15236111111111	0.422413793103447\\
5.15459490740741	0.426724137931033\\
5.1550462962963	0.43103448275862\\
5.15631944444444	0.435344827586206\\
5.20888888888889	0.439655172413792\\
5.21149305555556	0.443965517241378\\
5.21186342592593	0.448275862068965\\
5.21314814814815	0.452586206896551\\
5.21327546296296	0.456896551724137\\
5.21475694444444	0.461206896551723\\
5.26159722222222	0.465517241379309\\
5.27122685185185	0.469827586206895\\
5.27228009259259	0.474137931034482\\
5.27280092592593	0.478448275862068\\
5.31628472222222	0.482758620689654\\
5.32148148148148	0.48706896551724\\
5.32450231481482	0.491379310344826\\
5.32523148148148	0.495689655172413\\
5.3290625	0.499999999999999\\
5.32938657407407	0.504310344827585\\
5.32986111111111	0.508620689655171\\
5.33034722222222	0.512931034482757\\
5.37268518518519	0.517241379310344\\
5.38502314814815	0.52155172413793\\
5.38523148148148	0.525862068965516\\
5.38607638888889	0.530172413793102\\
5.38643518518519	0.534482758620688\\
5.38741898148148	0.538793103448275\\
5.38778935185185	0.543103448275861\\
5.42561342592593	0.547413793103447\\
5.43828703703704	0.551724137931033\\
5.45168981481481	0.55603448275862\\
5.49454861111111	0.560344827586206\\
5.49575231481481	0.564655172413792\\
5.498125	0.568965517241378\\
5.55136574074074	0.573275862068964\\
5.55638888888889	0.577586206896551\\
5.55946759259259	0.581896551724137\\
5.56048611111111	0.586206896551723\\
5.60539351851852	0.590517241379309\\
5.61043981481482	0.594827586206895\\
5.61315972222222	0.599137931034482\\
5.61460648148148	0.603448275862068\\
5.61685185185185	0.607758620689654\\
5.61778935185185	0.61206896551724\\
5.63293981481482	0.616379310344827\\
5.67181712962963	0.620689655172413\\
5.67417824074074	0.624999999999999\\
5.67565972222222	0.629310344827585\\
5.67583333333333	0.633620689655171\\
5.72508101851852	0.637931034482758\\
5.72584490740741	0.642241379310344\\
5.72984953703704	0.64655172413793\\
5.73196759259259	0.650862068965516\\
5.73237268518518	0.655172413793103\\
5.7333912037037	0.659482758620689\\
5.78729166666667	0.663793103448275\\
5.84063657407407	0.668103448275861\\
5.84469907407407	0.672413793103447\\
5.84494212962963	0.676724137931034\\
5.84501157407407	0.68103448275862\\
5.84572916666667	0.685344827586206\\
5.84731481481481	0.689655172413792\\
5.84744212962963	0.693965517241378\\
5.84780092592593	0.698275862068965\\
5.84868055555556	0.702586206896551\\
5.90346064814815	0.706896551724137\\
5.90456018518519	0.711206896551723\\
5.90581018518519	0.715517241379309\\
5.95017361111111	0.719827586206896\\
5.95128472222222	0.724137931034482\\
5.95733796296296	0.728448275862068\\
5.95859953703704	0.732758620689654\\
5.99944444444444	0.73706896551724\\
6.01927083333333	0.741379310344827\\
6.02068287037037	0.745689655172413\\
6.07572916666667	0.749999999999999\\
6.07767361111111	0.754310344827585\\
6.12369212962963	0.758620689655172\\
6.13309027777778	0.762931034482758\\
6.13498842592593	0.767241379310344\\
6.13619212962963	0.77155172413793\\
6.17320601851852	0.775862068965516\\
6.18494212962963	0.780172413793103\\
6.24876157407407	0.784482758620689\\
6.25163194444444	0.788793103448275\\
6.25172453703704	0.793103448275861\\
6.3034837962963	0.797413793103448\\
6.30511574074074	0.801724137931034\\
6.30893518518519	0.80603448275862\\
6.30917824074074	0.810344827586206\\
6.36299768518519	0.814655172413792\\
6.36516203703704	0.818965517241379\\
6.36681712962963	0.823275862068965\\
6.37883101851852	0.827586206896551\\
6.42065972222222	0.831896551724137\\
6.42096064814815	0.836206896551724\\
6.47592592592593	0.84051724137931\\
6.5343287037037	0.844827586206896\\
6.5375462962963	0.849137931034482\\
6.53884259259259	0.853448275862068\\
6.59601851851852	0.857758620689655\\
6.64996527777778	0.862068965517241\\
6.65070601851852	0.866379310344827\\
6.65076388888889	0.870689655172413\\
6.69883101851852	0.875\\
6.70283564814815	0.879310344827586\\
6.70502314814815	0.883620689655172\\
6.70605324074074	0.887931034482758\\
6.71027777777778	0.892241379310344\\
6.71064814814815	0.896551724137931\\
6.71068287037037	0.900862068965517\\
6.71171296296296	0.905172413793103\\
6.71193287037037	0.909482758620689\\
6.73209490740741	0.913793103448275\\
6.75421296296296	0.918103448275862\\
6.76596064814815	0.922413793103448\\
6.81811342592593	0.926724137931034\\
6.88480324074074	0.93103448275862\\
6.94032407407407	0.935344827586207\\
6.94290509259259	0.939655172413793\\
6.98989583333333	0.943965517241379\\
7.05606481481481	0.948275862068965\\
7.15710648148148	0.952586206896551\\
7.16491898148148	0.956896551724138\\
7.28027777777778	0.961206896551724\\
7.28799768518518	0.96551724137931\\
7.28805555555556	0.969827586206896\\
7.4034375	0.974137931034483\\
7.45590277777778	0.978448275862069\\
7.69079861111111	0.982758620689655\\
7.74900462962963	0.987068965517241\\
8.03364583333333	0.991379310344828\\
8.08883101851852	0.995689655172414\\
8.84060185185185	1\\
};
\end{axis}
\end{tikzpicture}% 	\setlength\fwidth{0.4\textwidth}
	\definecolor{mycolor1}{rgb}{0.00000,0.44700,0.74100}
\begin{tikzpicture}

\begin{axis}[
width=0.951\fwidth,
height=0.75\fwidth,
at={(0\fwidth,0\fwidth)},
scale only axis,
xmin=3,
xmax=9,
xlabel style={font=\color{white!15!black}},
xlabel={Lifetime (d)},
ymin=0,
ymax=0.5,
ylabel style={font=\color{white!15!black}},
ylabel={Probability density},
axis background/.style={fill=white}
]
\addplot [color=mycolor1, forget plot]
  table[row sep=crcr]{
3.65539351851852	0.0311060613415889\\
3.65539351851852	0.0311060613415889\\
3.88612268518519	0.0746253089773507\\
4.04607638888889	0.123071799241282\\
4.05780092592593	0.127260318602443\\
4.05827546296296	0.127431461243989\\
4.06336805555556	0.129276898782796\\
4.16209490740741	0.168146163176176\\
4.16583333333333	0.169734343907335\\
4.16824074074074	0.170759418377405\\
4.17811342592593	0.174982656334577\\
4.23090277777778	0.198382132389908\\
4.23425925925926	0.199912541349046\\
4.34474537037037	0.252402378945583\\
4.34844907407407	0.254211073003693\\
4.35103009259259	0.255472496776924\\
4.39923611111111	0.279123202489396\\
4.40034722222222	0.279668462445415\\
4.40402777777778	0.281474209298978\\
4.45054398148148	0.304175146339895\\
4.45975694444444	0.308631239966174\\
4.46435185185185	0.310843709669417\\
4.46532407407407	0.311311134444933\\
4.51805555555556	0.336210692488908\\
4.51966435185185	0.336953134075069\\
4.52009259259259	0.337150565141363\\
4.52246527777778	0.338242920655672\\
4.52336805555556	0.338657866443379\\
4.52395833333333	0.33892897192696\\
4.57143518518519	0.360142241614023\\
4.57194444444444	0.360362785263918\\
4.57393518518519	0.361223353467588\\
4.5762962962963	0.36224078682367\\
4.57699074074074	0.362539357159603\\
4.58032407407407	0.363968180905486\\
4.58097222222222	0.36424517235094\\
4.58162037037037	0.364521889805077\\
4.61822916666667	0.37968063473534\\
4.62917824074074	0.384039203306384\\
4.62978009259259	0.384275265977709\\
4.63076388888889	0.384660519508577\\
4.63206018518519	0.385166972627279\\
4.63226851851852	0.385248241904796\\
4.6349537037037	0.386292600308746\\
4.63815972222222	0.387531910989408\\
4.68565972222222	0.404871800094251\\
4.6862962962963	0.405090451855561\\
4.6946412037037	0.407921643805695\\
4.69556712962963	0.408231729408636\\
4.74951388888889	0.424844467361337\\
4.75083333333333	0.425213435099512\\
4.75155092592593	0.425413331542827\\
4.80350694444444	0.438414238138172\\
4.80724537037037	0.439234718987131\\
4.81015046296296	0.439861458694081\\
4.81168981481482	0.440189701985337\\
4.8565162037037	0.448567522944882\\
4.85902777777778	0.448968572866692\\
4.86289351851852	0.449571613617826\\
4.86568287037037	0.449996009578901\\
4.86581018518519	0.450015165572552\\
4.86608796296296	0.450056895372192\\
4.86652777777778	0.450122784969028\\
4.8666087962963	0.450134898113357\\
4.86809027777778	0.450355056247529\\
4.86835648148148	0.450394346698338\\
4.86905092592593	0.450496457452213\\
4.869375	0.450543918105183\\
4.91210648148148	0.455739643129222\\
4.9234837962963	0.456771204537073\\
4.92386574074074	0.456803160732379\\
4.92396990740741	0.456811847081443\\
4.9243287037037	0.456841671685796\\
4.9250462962963	0.45690087904012\\
4.92568287037037	0.456952908724559\\
4.92667824074074	0.457033335688471\\
4.97186342592593	0.459507417443618\\
4.98336805555556	0.459774481144679\\
4.98383101851852	0.459782212039674\\
5.02824074074074	0.459469506883455\\
5.03604166666667	0.459207876861199\\
5.03638888888889	0.45919470071338\\
5.0368287037037	0.459177839698741\\
5.03813657407407	0.459126571373713\\
5.03834490740741	0.459118248935525\\
5.03850694444444	0.459111746362447\\
5.03966435185185	0.459064547899184\\
5.03972222222222	0.459062153401258\\
5.03991898148148	0.459053987503064\\
5.04091435185185	0.45901209543166\\
5.04208333333333	0.458961657305564\\
5.04222222222222	0.458955575831265\\
5.08837962962963	0.455935004692026\\
5.09479166666667	0.455363516501769\\
5.09842592592593	0.455024089911181\\
5.0990162037037	0.454967912461828\\
5.09925925925926	0.454944695887363\\
5.14765046296296	0.449397553350645\\
5.15236111111111	0.448765269795688\\
5.15459490740741	0.44846015201853\\
5.1550462962963	0.448398087517995\\
5.15631944444444	0.448222298152631\\
5.20888888888889	0.440100784291771\\
5.21149305555556	0.439658562703536\\
5.21186342592593	0.439595396311849\\
5.21314814814815	0.439375766414825\\
5.21327546296296	0.439353957369841\\
5.21475694444444	0.439099600736633\\
5.26159722222222	0.430566129820649\\
5.27122685185185	0.428707767851718\\
5.27228009259259	0.428502943070104\\
5.27280092592593	0.428401530144731\\
5.31628472222222	0.419681539505363\\
5.32148148148148	0.418612978213793\\
5.32450231481482	0.417989156139148\\
5.32523148148148	0.41783834921183\\
5.3290625	0.417044604331096\\
5.32938657407407	0.41697735373287\\
5.32986111111111	0.41687885051349\\
5.33034722222222	0.416777909123169\\
5.37268518518519	0.407877823186896\\
5.38502314814815	0.405256123744893\\
5.38523148148148	0.405211817188985\\
5.38607638888889	0.405032112784854\\
5.38643518518519	0.404955792023614\\
5.38741898148148	0.40474461334853\\
5.38778935185185	0.404665822294029\\
5.42561342592593	0.39660651876914\\
5.43828703703704	0.393915792319455\\
5.45168981481481	0.391071603188613\\
5.49454861111111	0.382058207357328\\
5.49575231481481	0.381806687525811\\
5.498125	0.381311221377449\\
5.55136574074074	0.370314503350382\\
5.55638888888889	0.369288266429788\\
5.55946759259259	0.368660229595307\\
5.56048611111111	0.368452614718545\\
5.60539351851852	0.359367260943744\\
5.61043981481482	0.35835466385146\\
5.61315972222222	0.357809431401849\\
5.61460648148148	0.357519565306394\\
5.61685185185185	0.35706989590712\\
5.61778935185185	0.356882218991164\\
5.63293981481482	0.353849716757515\\
5.67181712962963	0.346118508407335\\
5.67417824074074	0.345648109441022\\
5.67565972222222	0.345354180232946\\
5.67583333333333	0.345319736963845\\
5.72508101851852	0.33555056870579\\
5.72584490740741	0.33539896294851\\
5.72984953703704	0.334604028450754\\
5.73196759259259	0.33418347667351\\
5.73237268518518	0.334103034219292\\
5.7333912037037	0.333900765746892\\
5.78729166666667	0.323156903394869\\
5.84063657407407	0.312447894171271\\
5.84469907407407	0.311631133166836\\
5.84494212962963	0.311582258483435\\
5.84501157407407	0.311568294117013\\
5.84572916666667	0.311423991259582\\
5.84731481481481	0.311105100765924\\
5.84744212962963	0.31107949481046\\
5.84780092592593	0.311007331317359\\
5.84868055555556	0.310830406661559\\
5.90346064814815	0.299802129527457\\
5.90456018518519	0.299581380799908\\
5.90581018518519	0.299330464076039\\
5.95017361111111	0.290466596293458\\
5.95128472222222	0.29024626058022\\
5.95733796296296	0.289047601921\\
5.95859953703704	0.288798165750233\\
5.99944444444444	0.280806289857521\\
6.01927083333333	0.277006981640479\\
6.02068287037037	0.276738705901988\\
6.07572916666667	0.266570062085861\\
6.07767361111111	0.266222677158962\\
6.12369212962963	0.25825983008255\\
6.13309027777778	0.256707050641493\\
6.13498842592593	0.256394560169394\\
6.13619212962963	0.256198126939575\\
6.17320601851852	0.250352953324108\\
6.18494212962963	0.248589826283529\\
6.24876157407407	0.239723892180693\\
6.25163194444444	0.239352118852701\\
6.25172453703704	0.2393402276219\\
6.3034837962963	0.233050427279844\\
6.30511574074074	0.232864116000349\\
6.30893518518519	0.232430538301331\\
6.30917824074074	0.232403062995238\\
6.36299768518519	0.226617445316686\\
6.36516203703704	0.226396034748598\\
6.36681712962963	0.226227185658025\\
6.37883101851852	0.225003885183884\\
6.42065972222222	0.220894727144977\\
6.42096064814815	0.22086557571531\\
6.47592592592593	0.215529433667882\\
6.5343287037037	0.209577949937548\\
6.5375462962963	0.209233526838778\\
6.53884259259259	0.209092274835756\\
6.59601851851852	0.202516105094586\\
6.64996527777778	0.19539186592084\\
6.65070601851852	0.195287086321773\\
6.65076388888889	0.195278891889695\\
6.69883101851852	0.188035951460756\\
6.70283564814815	0.187393364968611\\
6.70502314814815	0.187039790829892\\
6.70605324074074	0.186872666029378\\
6.71027777777778	0.186183075356191\\
6.71064814814815	0.186122297266695\\
6.71068287037037	0.186116596672719\\
6.71171296296296	0.185947272643141\\
6.71193287037037	0.185911073109487\\
6.73209490740741	0.182510800128473\\
6.75421296296296	0.178616530074655\\
6.76596064814815	0.176478360351458\\
6.81811342592593	0.166453773871518\\
6.88480324074074	0.152653308857269\\
6.94032407407407	0.140711601082539\\
6.94290509259259	0.140153255561151\\
6.98989583333333	0.130011523070882\\
7.05606481481481	0.116117647440739\\
7.15710648148148	0.0966285800115478\\
7.16491898148148	0.095234596354422\\
7.28027777777778	0.0766719943892029\\
7.28799768518518	0.0755646585877256\\
7.28805555555556	0.0755564189315758\\
7.4034375	0.0608310644793743\\
7.45590277777778	0.0551738275332293\\
7.69079861111111	0.0362658725559196\\
7.74900462962963	0.0329266889235524\\
8.03364583333333	0.0207032976089452\\
8.08883101851852	0.0186753166915754\\
8.84060185185185	0.00608852609872549\\
};
\end{axis}
\end{tikzpicture}% 	\caption{The empirical cumulative distribution function and the probability density function of the lifetime of the machine.}
	\label{figure:distribution} 
\end{figure}

For survival analysis, the hazard rate of the lifetime is important.
The observed hazard rate over time is plotted in figure \ref{figure:hazard}.
As you can see, the hazard rate is increasing for lifetimes shorter than 6.5 days.
For lifetimes larger than 6.5 days, the hazard rate seems to jump up and down a lot.
This is likely because these large lifetimes did not occur frequently enough in the dataset to smoothen out the hazard rate.
Hence, we can safely assume that the lifetime has an increasing hazard rate.
\begin{figure}[H]
	\centering
	\setlength\fwidth{0.5\textwidth}
\definecolor{mycolor1}{rgb}{0.00000,0.44700,0.74100}
\begin{tikzpicture}

\begin{axis}[
width=0.951\fwidth,
height=0.75\fwidth,
at={(0\fwidth,0\fwidth)},
scale only axis,
unbounded coords=jump,
xmin=3.5,
xmax=8.5,
xlabel style={font=\color{white!15!black}},
xlabel={Lifetime (d)},
ymin=0,
ymax=4.5,
ylabel style={font=\color{white!15!black}},
ylabel={Hazard rate},
axis background/.style={fill=white}
]
\addplot [color=mycolor1, forget plot]
  table[row sep=crcr]{
3.65539351851852	0.0311060613415889\\
3.65539351851852	0.031240719615795\\
3.88612268518519	0.0752742247075886\\
4.04607638888889	0.124684093554486\\
4.05780092592593	0.129492955770907\\
4.05827546296296	0.130238321623813\\
4.06336805555556	0.132709028838976\\
4.16209490740741	0.173377377141657\\
4.16583333333333	0.175796284761168\\
4.16824074074074	0.177651054096672\\
4.17811342592593	0.18286475797127\\
4.23090277777778	0.208256356174021\\
4.23425925925926	0.210816861786267\\
4.34474537037037	0.267385168563358\\
4.34844907407407	0.270536554756224\\
4.35103009259259	0.273131885955053\\
4.39923611111111	0.299798995266389\\
4.40034722222222	0.301781782731797\\
4.40402777777778	0.305149610081135\\
4.45054398148148	0.331308140614345\\
4.45975694444444	0.337747394679964\\
4.46435185185185	0.341780761342676\\
4.46532407407407	0.343924681862973\\
4.51805555555556	0.373209955298692\\
4.51966435185185	0.375832341852962\\
4.52009259259259	0.377869232428967\\
4.52246527777778	0.380933774719009\\
4.52336805555556	0.38326158543836\\
4.52395833333333	0.385448634740464\\
4.57143518518519	0.411591133273169\\
4.57194444444444	0.413882010798163\\
4.57393518518519	0.416934417932739\\
4.5762962962963	0.420199312715457\\
4.57699074074074	0.422658949050391\\
4.58032407407407	0.42646776752562\\
4.58097222222222	0.428958781651868\\
4.58162037037037	0.431474889973356\\
4.61822916666667	0.451722601326148\\
4.62917824074074	0.459263377149903\\
4.62978009259259	0.461926744594966\\
4.63076388888889	0.46479812773953\\
4.63206018518519	0.46784679397659\\
4.63226851851852	0.470408379589013\\
4.6349537037037	0.474179276569466\\
4.63815972222222	0.478230868880545\\
4.68565972222222	0.50230084289768\\
4.6862962962963	0.505274111991882\\
4.6946412037037	0.511555791150925\\
4.69556712962963	0.514726963167411\\
4.74951388888889	0.538600636217651\\
4.75083333333333	0.542030312874102\\
4.75155092592593	0.545281176342187\\
4.80350694444444	0.565067240266977\\
4.80724537037037	0.569287457011253\\
4.81015046296296	0.573302575376555\\
4.81168981481482	0.576971812771741\\
4.8565162037037	0.591293552972798\\
4.85902777777778	0.595204050886129\\
4.86289351851852	0.599428818157101\\
4.86568287037037	0.603462856776329\\
4.86581018518519	0.606997200074605\\
4.86608796296296	0.610603507171628\\
4.86652777777778	0.61428521242832\\
4.8666087962963	0.617936664865673\\
4.86809027777778	0.621918887198969\\
4.86835648148148	0.62569753553302\\
4.86905092592593	0.629609506800682\\
4.869375	0.633492054547893\\
4.91210648148148	0.64470486101207\\
4.9234837962963	0.650128340200006\\
4.92386574074074	0.65418724253032\\
4.92396990740741	0.658263034303693\\
4.9243287037037	0.662420423944404\\
4.9250462962963	0.666672980737785\\
4.92568287037037	0.670968828000618\\
4.92667824074074	0.675361362291244\\
4.97186342592593	0.683370005428969\\
4.98336805555556	0.688178578229455\\
4.98383101851852	0.692658916838989\\
5.02824074074074	0.696711932006284\\
5.03604166666667	0.700896233103934\\
5.03638888888889	0.705517685864266\\
5.0368287037037	0.710195058734052\\
5.03813657407407	0.714881641333566\\
5.03834490740741	0.71969887670974\\
5.03850694444444	0.724584524871344\\
5.03966435185185	0.729472432278155\\
5.03972222222222	0.734499445442012\\
5.03991898148148	0.739586979866047\\
5.04091435185185	0.744690952028987\\
5.04208333333333	0.749852848555568\\
5.04222222222222	0.755160947467045\\
5.08837962962963	0.755549436346785\\
5.09479166666667	0.760031193010146\\
5.09842592592593	0.764968035212999\\
5.0990162037037	0.770456610884263\\
5.09925925925926	0.776082128278441\\
5.14765046296296	0.772298017609996\\
5.15236111111111	0.776966735765668\\
5.15459490740741	0.782276355400743\\
5.1550462962963	0.78809360836496\\
5.15631944444444	0.793798268484048\\
5.20888888888889	0.78541063042839\\
5.21149305555556	0.790703771683877\\
5.21186342592593	0.796766655815225\\
5.21314814814815	0.802639195340466\\
5.21327546296296	0.808969191347642\\
5.21475694444444	0.81496885896719\\
5.26159722222222	0.805575339664438\\
5.27122685185185	0.808619529606491\\
5.27228009259259	0.814858055674293\\
5.27280092592593	0.821397975153531\\
5.31628472222222	0.811384309710366\\
5.32148148148148	0.816119419710922\\
5.32450231481482	0.821809188341374\\
5.32523148148148	0.828534162539694\\
5.3290625	0.834089208662191\\
5.32938657407407	0.841206487530658\\
5.32986111111111	0.848385029115171\\
5.33034722222222	0.855685618730752\\
5.37268518518519	0.844889776601425\\
5.38502314814815	0.847021808187522\\
5.38523148148148	0.854628559889492\\
5.38607638888889	0.862086698771431\\
5.38643518518519	0.86990503471739\\
5.38741898148148	0.877577105578119\\
5.38778935185185	0.885683686530327\\
5.42561342592593	0.876311546232764\\
5.43828703703704	0.87873522902032\\
5.45168981481481	0.880860310094738\\
5.49454861111111	0.868995138302941\\
5.49575231481481	0.877021302039485\\
5.498125	0.884642033595679\\
5.55136574074074	0.867807725023116\\
5.55638888888889	0.874233447058272\\
5.55946759259259	0.881744054289805\\
5.56048611111111	0.890427152236483\\
5.60539351851852	0.877612679357351\\
5.61043981481482	0.884449808654666\\
5.61315972222222	0.892599871884181\\
5.61460648148148	0.901571077729166\\
5.61685185185185	0.910332042312656\\
5.61778935185185	0.919963053399442\\
5.63293981481482	0.922394767278013\\
5.67181712962963	0.912494249437516\\
5.67417824074074	0.921728291842722\\
5.67565972222222	0.931653137372595\\
5.67583333333333	0.942519752654258\\
5.72508101851852	0.926758713568369\\
5.72584490740741	0.937500715711494\\
5.72984953703704	0.946684568299691\\
5.73196759259259	0.957167488743879\\
5.73237268518518	0.968898799235943\\
5.7333912037037	0.980569337383274\\
5.78729166666667	0.961184635738582\\
5.84063657407407	0.941401447373176\\
5.84469907407407	0.951295038088234\\
5.84494212962963	0.963827786242089\\
5.84501157407407	0.976808705880363\\
5.84572916666667	0.989731040715382\\
5.84731481481481	1.00244976913464\\
5.84744212962963	1.01648510980319\\
5.84780092592593	1.03076715522324\\
5.84868055555556	1.04511093254321\\
5.90346064814815	1.02285432427014\\
5.90456018518519	1.03735642306833\\
5.90581018518519	1.05219193432789\\
5.95017361111111	1.03674231292434\\
5.95128472222222	1.0521426946033\\
5.95733796296296	1.06442926421701\\
5.95859953703704	1.08066410409764\\
5.99944444444444	1.06798457781877\\
6.01927083333333	1.07109366234318\\
6.02068287037037	1.0881928774451\\
6.07572916666667	1.06628024834344\\
6.07767361111111	1.08357300176981\\
6.12369212962963	1.06993358177056\\
6.13309027777778	1.08283701361502\\
6.13498842592593	1.10154699924628\\
6.13619212962963	1.12147104622606\\
6.17320601851852	1.11695933021525\\
6.18494212962963	1.13083999407409\\
6.24876157407407	1.11231885971841\\
6.25163194444444	1.13325901171074\\
6.25172453703704	1.15681110017252\\
6.3034837962963	1.15037657721114\\
6.30511574074074	1.17444510678436\\
6.30893518518519	1.19830855302019\\
6.30917824074074	1.22539796852034\\
6.36299768518519	1.22268017008072\\
6.36516203703704	1.25056857289701\\
6.36681712962963	1.28011480665028\\
6.37883101851852	1.30502253406652\\
6.42065972222222	1.31404042814447\\
6.42096064814815	1.34844246226189\\
6.47592592592593	1.3514278002959\\
6.5343287037037	1.35061345515308\\
6.5375462962963	1.38691937790275\\
6.53884259259259	1.42674728711457\\
6.59601851851852	1.42374958733163\\
6.64996527777778	1.41659102792609\\
6.65070601851852	1.46150335569843\\
6.65076388888889	1.51015676394697\\
6.69883101851852	1.50428761168604\\
6.70283564814815	1.55268788116849\\
6.70502314814815	1.60715672120499\\
6.70605324074074	1.66747917380059\\
6.71027777777778	1.72777893930545\\
6.71064814814815	1.79918220691138\\
6.71068287037037	1.87735001861177\\
6.71171296296296	1.96089851150948\\
6.71193287037037	2.05387471244765\\
6.73209490740741	2.11712528149027\\
6.75421296296296	2.18100184091157\\
6.76596064814815	2.27460997786323\\
6.81811342592593	2.27160444342306\\
6.88480324074074	2.21347297843039\\
6.94032407407407	2.1763394300766\\
6.94290509259259	2.32253966358478\\
6.98989583333333	2.32020564249573\\
7.05606481481481	2.24494118385428\\
7.15710648148148	2.03798459660718\\
7.16491898148148	2.20944263542258\\
7.28027777777778	1.97643363314389\\
7.28799768518518	2.19137509904403\\
7.28805555555556	2.50415559887508\\
7.4034375	2.35213449320246\\
7.45590277777778	2.56006559754183\\
7.69079861111111	2.10342060824333\\
7.74900462962963	2.54633061008805\\
8.03364583333333	2.40158252263762\\
8.08883101851852	4.3326734724455\\
8.84060185185185	inf\\
};
\end{axis}
\end{tikzpicture}% \caption{The hazard rate of the lifetime of the machine.}
\label{figure:hazard}
\end{figure}

\section{Fitting lifetime distributions}
To be able to predict the remaining time until a failure, it is helpful to know how the lifetime of the machine is distributed.
In this section we will attempt to fit the lifetime to a distribution.

\cite{Lai2006} mentions a few common lifetime distributions.
We tried to fit these distributions over the observed lifetimes of the machine (using maximum likelihood estimation).
The Gamma distribution and the log-normal distribution fitted the data best, although still not very well.
The probability densities of these distributions are plotted over the density of the observed lifetimes in figure \ref{figure:fits}.
As you can see, these estimations are still not very accurate as they do not include the blob on the right side of the mode.

\begin{figure}[H]\label{figure:fits}
	\centering
	\setlength\fwidth{0.7\textwidth}
	\definecolor{mycolor1}{rgb}{0.00000,0.44700,0.74100}
\definecolor{mycolor2}{rgb}{0.85000,0.32500,0.09800}
\definecolor{mycolor3}{rgb}{0.92900,0.69400,0.12500}
\begin{tikzpicture}

\begin{axis}[
width=0.951\fwidth,
height=0.75\fwidth,
at={(0\fwidth,0\fwidth)},
scale only axis,
xmin=3,
xmax=9,
xlabel style={font=\color{white!15!black}},
xlabel={Lifetime (d)},
ymin=0,
ymax=0.5,
ylabel style={font=\color{white!15!black}},
ylabel={Probability density},
axis background/.style={fill=white},
legend style={legend cell align=left, align=left, draw=white!15!black}
]
\addplot [color=mycolor1]
  table[row sep=crcr]{
3.65539351851852	0.0311060613415889\\
3.65539351851852	0.0311060613415889\\
3.88612268518519	0.0746253089773507\\
4.04607638888889	0.123071799241282\\
4.05780092592593	0.127260318602443\\
4.05827546296296	0.127431461243989\\
4.06336805555556	0.129276898782796\\
4.16209490740741	0.168146163176176\\
4.16583333333333	0.169734343907335\\
4.16824074074074	0.170759418377405\\
4.17811342592593	0.174982656334577\\
4.23090277777778	0.198382132389908\\
4.23425925925926	0.199912541349046\\
4.34474537037037	0.252402378945583\\
4.34844907407407	0.254211073003693\\
4.35103009259259	0.255472496776924\\
4.39923611111111	0.279123202489396\\
4.40034722222222	0.279668462445415\\
4.40402777777778	0.281474209298978\\
4.45054398148148	0.304175146339895\\
4.45975694444444	0.308631239966174\\
4.46435185185185	0.310843709669417\\
4.46532407407407	0.311311134444933\\
4.51805555555556	0.336210692488908\\
4.51966435185185	0.336953134075069\\
4.52009259259259	0.337150565141363\\
4.52246527777778	0.338242920655672\\
4.52336805555556	0.338657866443379\\
4.52395833333333	0.33892897192696\\
4.57143518518519	0.360142241614023\\
4.57194444444444	0.360362785263918\\
4.57393518518519	0.361223353467588\\
4.5762962962963	0.36224078682367\\
4.57699074074074	0.362539357159603\\
4.58032407407407	0.363968180905486\\
4.58097222222222	0.36424517235094\\
4.58162037037037	0.364521889805077\\
4.61822916666667	0.37968063473534\\
4.62917824074074	0.384039203306384\\
4.62978009259259	0.384275265977709\\
4.63076388888889	0.384660519508577\\
4.63206018518519	0.385166972627279\\
4.63226851851852	0.385248241904796\\
4.6349537037037	0.386292600308746\\
4.63815972222222	0.387531910989408\\
4.68565972222222	0.404871800094251\\
4.6862962962963	0.405090451855561\\
4.6946412037037	0.407921643805695\\
4.69556712962963	0.408231729408636\\
4.74951388888889	0.424844467361337\\
4.75083333333333	0.425213435099512\\
4.75155092592593	0.425413331542827\\
4.80350694444444	0.438414238138172\\
4.80724537037037	0.439234718987131\\
4.81015046296296	0.439861458694081\\
4.81168981481482	0.440189701985337\\
4.8565162037037	0.448567522944882\\
4.85902777777778	0.448968572866692\\
4.86289351851852	0.449571613617826\\
4.86568287037037	0.449996009578901\\
4.86581018518519	0.450015165572552\\
4.86608796296296	0.450056895372192\\
4.86652777777778	0.450122784969028\\
4.8666087962963	0.450134898113357\\
4.86809027777778	0.450355056247529\\
4.86835648148148	0.450394346698338\\
4.86905092592593	0.450496457452213\\
4.869375	0.450543918105183\\
4.91210648148148	0.455739643129222\\
4.9234837962963	0.456771204537073\\
4.92386574074074	0.456803160732379\\
4.92396990740741	0.456811847081443\\
4.9243287037037	0.456841671685796\\
4.9250462962963	0.45690087904012\\
4.92568287037037	0.456952908724559\\
4.92667824074074	0.457033335688471\\
4.97186342592593	0.459507417443618\\
4.98336805555556	0.459774481144679\\
4.98383101851852	0.459782212039674\\
5.02824074074074	0.459469506883455\\
5.03604166666667	0.459207876861199\\
5.03638888888889	0.45919470071338\\
5.0368287037037	0.459177839698741\\
5.03813657407407	0.459126571373713\\
5.03834490740741	0.459118248935525\\
5.03850694444444	0.459111746362447\\
5.03966435185185	0.459064547899184\\
5.03972222222222	0.459062153401258\\
5.03991898148148	0.459053987503064\\
5.04091435185185	0.45901209543166\\
5.04208333333333	0.458961657305564\\
5.04222222222222	0.458955575831265\\
5.08837962962963	0.455935004692026\\
5.09479166666667	0.455363516501769\\
5.09842592592593	0.455024089911181\\
5.0990162037037	0.454967912461828\\
5.09925925925926	0.454944695887363\\
5.14765046296296	0.449397553350645\\
5.15236111111111	0.448765269795688\\
5.15459490740741	0.44846015201853\\
5.1550462962963	0.448398087517995\\
5.15631944444444	0.448222298152631\\
5.20888888888889	0.440100784291771\\
5.21149305555556	0.439658562703536\\
5.21186342592593	0.439595396311849\\
5.21314814814815	0.439375766414825\\
5.21327546296296	0.439353957369841\\
5.21475694444444	0.439099600736633\\
5.26159722222222	0.430566129820649\\
5.27122685185185	0.428707767851718\\
5.27228009259259	0.428502943070104\\
5.27280092592593	0.428401530144731\\
5.31628472222222	0.419681539505363\\
5.32148148148148	0.418612978213793\\
5.32450231481482	0.417989156139148\\
5.32523148148148	0.41783834921183\\
5.3290625	0.417044604331096\\
5.32938657407407	0.41697735373287\\
5.32986111111111	0.41687885051349\\
5.33034722222222	0.416777909123169\\
5.37268518518519	0.407877823186896\\
5.38502314814815	0.405256123744893\\
5.38523148148148	0.405211817188985\\
5.38607638888889	0.405032112784854\\
5.38643518518519	0.404955792023614\\
5.38741898148148	0.40474461334853\\
5.38778935185185	0.404665822294029\\
5.42561342592593	0.39660651876914\\
5.43828703703704	0.393915792319455\\
5.45168981481481	0.391071603188613\\
5.49454861111111	0.382058207357328\\
5.49575231481481	0.381806687525811\\
5.498125	0.381311221377449\\
5.55136574074074	0.370314503350382\\
5.55638888888889	0.369288266429788\\
5.55946759259259	0.368660229595307\\
5.56048611111111	0.368452614718545\\
5.60539351851852	0.359367260943744\\
5.61043981481482	0.35835466385146\\
5.61315972222222	0.357809431401849\\
5.61460648148148	0.357519565306394\\
5.61685185185185	0.35706989590712\\
5.61778935185185	0.356882218991164\\
5.63293981481482	0.353849716757515\\
5.67181712962963	0.346118508407335\\
5.67417824074074	0.345648109441022\\
5.67565972222222	0.345354180232946\\
5.67583333333333	0.345319736963845\\
5.72508101851852	0.33555056870579\\
5.72584490740741	0.33539896294851\\
5.72984953703704	0.334604028450754\\
5.73196759259259	0.33418347667351\\
5.73237268518518	0.334103034219292\\
5.7333912037037	0.333900765746892\\
5.78729166666667	0.323156903394869\\
5.84063657407407	0.312447894171271\\
5.84469907407407	0.311631133166836\\
5.84494212962963	0.311582258483435\\
5.84501157407407	0.311568294117013\\
5.84572916666667	0.311423991259582\\
5.84731481481481	0.311105100765924\\
5.84744212962963	0.31107949481046\\
5.84780092592593	0.311007331317359\\
5.84868055555556	0.310830406661559\\
5.90346064814815	0.299802129527457\\
5.90456018518519	0.299581380799908\\
5.90581018518519	0.299330464076039\\
5.95017361111111	0.290466596293458\\
5.95128472222222	0.29024626058022\\
5.95733796296296	0.289047601921\\
5.95859953703704	0.288798165750233\\
5.99944444444444	0.280806289857521\\
6.01927083333333	0.277006981640479\\
6.02068287037037	0.276738705901988\\
6.07572916666667	0.266570062085861\\
6.07767361111111	0.266222677158962\\
6.12369212962963	0.25825983008255\\
6.13309027777778	0.256707050641493\\
6.13498842592593	0.256394560169394\\
6.13619212962963	0.256198126939575\\
6.17320601851852	0.250352953324108\\
6.18494212962963	0.248589826283529\\
6.24876157407407	0.239723892180693\\
6.25163194444444	0.239352118852701\\
6.25172453703704	0.2393402276219\\
6.3034837962963	0.233050427279844\\
6.30511574074074	0.232864116000349\\
6.30893518518519	0.232430538301331\\
6.30917824074074	0.232403062995238\\
6.36299768518519	0.226617445316686\\
6.36516203703704	0.226396034748598\\
6.36681712962963	0.226227185658025\\
6.37883101851852	0.225003885183884\\
6.42065972222222	0.220894727144977\\
6.42096064814815	0.22086557571531\\
6.47592592592593	0.215529433667882\\
6.5343287037037	0.209577949937548\\
6.5375462962963	0.209233526838778\\
6.53884259259259	0.209092274835756\\
6.59601851851852	0.202516105094586\\
6.64996527777778	0.19539186592084\\
6.65070601851852	0.195287086321773\\
6.65076388888889	0.195278891889695\\
6.69883101851852	0.188035951460756\\
6.70283564814815	0.187393364968611\\
6.70502314814815	0.187039790829892\\
6.70605324074074	0.186872666029378\\
6.71027777777778	0.186183075356191\\
6.71064814814815	0.186122297266695\\
6.71068287037037	0.186116596672719\\
6.71171296296296	0.185947272643141\\
6.71193287037037	0.185911073109487\\
6.73209490740741	0.182510800128473\\
6.75421296296296	0.178616530074655\\
6.76596064814815	0.176478360351458\\
6.81811342592593	0.166453773871518\\
6.88480324074074	0.152653308857269\\
6.94032407407407	0.140711601082539\\
6.94290509259259	0.140153255561151\\
6.98989583333333	0.130011523070882\\
7.05606481481481	0.116117647440739\\
7.15710648148148	0.0966285800115478\\
7.16491898148148	0.095234596354422\\
7.28027777777778	0.0766719943892029\\
7.28799768518518	0.0755646585877256\\
7.28805555555556	0.0755564189315758\\
7.4034375	0.0608310644793743\\
7.45590277777778	0.0551738275332293\\
7.69079861111111	0.0362658725559196\\
7.74900462962963	0.0329266889235524\\
8.03364583333333	0.0207032976089452\\
8.08883101851852	0.0186753166915754\\
8.84060185185185	0.00608852609872549\\
};
\addlegendentry{Observed}

\addplot [color=mycolor2]
  table[row sep=crcr]{
3.65539351851852	0.0391965073696616\\
3.65539351851852	0.0391965073696616\\
3.88612268518519	0.0782714425008287\\
4.04607638888889	0.116703631748607\\
4.05780092592593	0.119882649173509\\
4.05827546296296	0.120012317661526\\
4.06336805555556	0.121408758707586\\
4.16209490740741	0.150171059820832\\
4.16583333333333	0.151320119383177\\
4.16824074074074	0.152062247519286\\
4.17811342592593	0.155123325984739\\
4.23090277777778	0.171949231709942\\
4.23425925925926	0.173043766137226\\
4.34474537037037	0.210451255921093\\
4.34844907407407	0.211744455730498\\
4.35103009259259	0.212646869938005\\
4.39923611111111	0.229662908761296\\
4.40034722222222	0.230058252682247\\
4.40402777777778	0.231368678910887\\
4.45054398148148	0.248021566788717\\
4.45975694444444	0.251334387949898\\
4.46435185185185	0.252987734353704\\
4.46532407407407	0.25333763954495\\
4.51805555555556	0.272325869822675\\
4.51966435185185	0.272904573025265\\
4.52009259259259	0.273058601007824\\
4.52246527777778	0.2739118769187\\
4.52336805555556	0.274236481420118\\
4.52395833333333	0.274448705300261\\
4.57143518518519	0.291450940362877\\
4.57194444444444	0.291632361467382\\
4.57393518518519	0.292341309957968\\
4.5762962962963	0.293181644062963\\
4.57699074074074	0.293428693348531\\
4.58032407407407	0.294613830844281\\
4.58097222222222	0.294844137489713\\
4.58162037037037	0.295074398839929\\
4.61822916666667	0.307996281907833\\
4.62917824074074	0.311824044017845\\
4.62978009259259	0.312033889858613\\
4.63076388888889	0.31237677764191\\
4.63206018518519	0.312828335753722\\
4.63226851851852	0.312900881246795\\
4.6349537037037	0.313835252585219\\
4.63815972222222	0.314949233894136\\
4.68565972222222	0.331221211620492\\
4.6862962962963	0.331436013490677\\
4.6946412037037	0.334243053111763\\
4.69556712962963	0.33455348747899\\
4.74951388888889	0.352250423989753\\
4.75083333333333	0.352672884459663\\
4.75155092592593	0.352902420363506\\
4.80350694444444	0.369076576225681\\
4.80724537037037	0.370204405660797\\
4.81015046296296	0.371077297871569\\
4.81168981481482	0.371538564522719\\
4.8565162037037	0.384570091932575\\
4.85902777777778	0.385276348313898\\
4.86289351851852	0.386358239378235\\
4.86568287037037	0.387134974485335\\
4.86581018518519	0.387170348496339\\
4.86608796296296	0.387247504273229\\
4.86652777777778	0.387369600557244\\
4.8666087962963	0.38739208301078\\
4.86809027777778	0.387802698090007\\
4.86835648148148	0.387876381340508\\
4.86905092592593	0.38806845609253\\
4.869375	0.388158020442473\\
4.91210648148148	0.399562247194678\\
4.9234837962963	0.402457982949802\\
4.92386574074074	0.402554133335406\\
4.92396990740741	0.402580344116426\\
4.9243287037037	0.402670586142284\\
4.9250462962963	0.402850886145214\\
4.92568287037037	0.403010624088795\\
4.92667824074074	0.403260008175751\\
4.97186342592593	0.41406941063572\\
4.98336805555556	0.416656891674948\\
4.98383101851852	0.416759577328118\\
5.02824074074074	0.426079576784174\\
5.03604166666667	0.427606053211011\\
5.03638888888889	0.427673213377648\\
5.0368287037037	0.427758186726089\\
5.03813657407407	0.428010234957295\\
5.03834490740741	0.428050296327786\\
5.03850694444444	0.428081438460618\\
5.03966435185185	0.428303456811925\\
5.03972222222222	0.428314538126971\\
5.03991898148148	0.428352200626944\\
5.04091435185185	0.428542397527174\\
5.04208333333333	0.428765061896776\\
5.04222222222222	0.428791466313086\\
5.08837962962963	0.436960385793963\\
5.09479166666667	0.4379980859819\\
5.09842592592593	0.438575564049152\\
5.0990162037037	0.438668627133959\\
5.09925925925926	0.438706887778474\\
5.14765046296296	0.445626114821438\\
5.15236111111111	0.446224660171915\\
5.15459490740741	0.4465037941149\\
5.1550462962963	0.446559831987159\\
5.15631944444444	0.446717221537875\\
5.20888888888889	0.452351260388676\\
5.21149305555556	0.452586187546755\\
5.21186342592593	0.452619259037844\\
5.21314814814815	0.452733318631911\\
5.21327546296296	0.452744566269484\\
5.21475694444444	0.45287471105012\\
5.26159722222222	0.456288104501826\\
5.27122685185185	0.456821036766911\\
5.27228009259259	0.456875831417636\\
5.27280092592593	0.456902673058496\\
5.31628472222222	0.458550136536001\\
5.32148148148148	0.458668730738072\\
5.32450231481482	0.458730010600388\\
5.32523148148148	0.458743959362839\\
5.3290625	0.458811863600415\\
5.32938657407407	0.458817193099953\\
5.32986111111111	0.458824880355624\\
5.33034722222222	0.458832611376051\\
5.37268518518519	0.458950418363649\\
5.38502314814815	0.458779445378623\\
5.38523148148148	0.45877576903849\\
5.38607638888889	0.458760591262025\\
5.38643518518519	0.458754015783501\\
5.38741898148148	0.458735588436396\\
5.38778935185185	0.458728500070289\\
5.42561342592593	0.457572630938337\\
5.43828703703704	0.456995858263498\\
5.45168981481481	0.456283845450251\\
5.49454861111111	0.453314929113886\\
5.49575231481481	0.453216561637211\\
5.498125	0.453020299457958\\
5.55136574074074	0.447806411219346\\
5.55638888888889	0.447236110801849\\
5.55946759259259	0.44688004294799\\
5.56048611111111	0.446761157674393\\
5.60539351851852	0.440992240145313\\
5.61043981481482	0.44028095455561\\
5.61315972222222	0.4398924220541\\
5.61460648148148	0.439684290802025\\
5.61685185185185	0.439359262497907\\
5.61778935185185	0.439222833444995\\
5.63293981481482	0.436959674048755\\
5.67181712962963	0.430662851105381\\
5.67417824074074	0.430258419587384\\
5.67565972222222	0.430003402268444\\
5.67583333333333	0.429973454157642\\
5.72508101851852	0.420958272934047\\
5.72584490740741	0.420810527617039\\
5.72984953703704	0.420032167446849\\
5.73196759259259	0.419617911610337\\
5.73237268518518	0.419538479920638\\
5.7333912037037	0.419338479479844\\
5.78729166666667	0.408191861519303\\
5.84063657407407	0.396158968579786\\
5.84469907407407	0.395205439567846\\
5.84494212962963	0.395148232655932\\
5.84501157407407	0.395131884557525\\
5.84572916666667	0.394962869282455\\
5.84731481481481	0.394588852110608\\
5.84744212962963	0.39455878889067\\
5.84780092592593	0.394474039215156\\
5.84868055555556	0.3942661032915\\
5.90346064814815	0.380886135598317\\
5.90456018518519	0.380609399181243\\
5.90581018518519	0.380294426759409\\
5.95017361111111	0.368876569870847\\
5.95128472222222	0.368584964131086\\
5.95733796296296	0.366991798201514\\
5.95859953703704	0.366658810422459\\
5.99944444444444	0.355712307277214\\
6.01927083333333	0.35029334587633\\
6.02068287037037	0.349905035661813\\
6.07572916666667	0.334553813478987\\
6.07767361111111	0.334004806048521\\
6.12369212962963	0.320907183230165\\
6.13309027777778	0.318211498399996\\
6.13498842592593	0.317666347793967\\
6.13619212962963	0.317320526103771\\
6.17320601851852	0.306649356017734\\
6.18494212962963	0.303254238822469\\
6.24876157407407	0.284757709623229\\
6.25163194444444	0.283926120294938\\
6.25172453703704	0.283899297282112\\
6.3034837962963	0.268944436813564\\
6.30511574074074	0.268474662351379\\
6.30893518518519	0.267375724950591\\
6.30917824074074	0.267305818471352\\
6.36299768518519	0.251918616098513\\
6.36516203703704	0.251304273247139\\
6.36681712962963	0.250834746204252\\
6.37883101851852	0.24743366441529\\
6.42065972222222	0.235699717935024\\
6.42096064814815	0.235615961467833\\
6.47592592592593	0.220497814059692\\
6.5343287037037	0.204878010294223\\
6.5375462962963	0.204032194637212\\
6.53884259259259	0.203691889961786\\
6.59601851851852	0.188952938998539\\
6.64996527777778	0.175563455136432\\
6.65070601851852	0.175383286802903\\
6.65076388888889	0.175369215445825\\
6.69883101851852	0.16390015878561\\
6.70283564814815	0.162964672917672\\
6.70502314814815	0.162454993026365\\
6.70605324074074	0.162215309269121\\
6.71027777777778	0.161234512381039\\
6.71064814814815	0.161148691760255\\
6.71068287037037	0.161140647459404\\
6.71171296296296	0.160902107703659\\
6.71193287037037	0.16085121051987\\
6.73209490740741	0.156225369730294\\
6.75421296296296	0.151244103734519\\
6.76596064814815	0.148638533211955\\
6.81811342592593	0.137412541070876\\
6.88480324074074	0.123880971624953\\
6.94032407407407	0.113327640370464\\
6.94290509259259	0.112852794049051\\
6.98989583333333	0.104451341897768\\
7.05606481481481	0.0933976934492163\\
7.15710648148148	0.0782266349880034\\
7.16491898148148	0.0771371772237238\\
7.28027777777778	0.062381501392703\\
7.28799768518518	0.0614801921294619\\
7.28805555555556	0.06147347515762\\
7.4034375	0.0492066942709017\\
7.45590277777778	0.04433347944635\\
7.69079861111111	0.0271676623442419\\
7.74900462962963	0.0239290029596777\\
8.03364583333333	0.0124775661227122\\
8.08883101851852	0.0109357506846589\\
8.84060185185185	0.00153406025285768\\
};
\addlegendentry{Gamma}

\addplot [color=mycolor3]
  table[row sep=crcr]{
3.65539351851852	0.0315930067177022\\
3.65539351851852	0.0315930067177022\\
3.88612268518519	0.0716129149621451\\
4.04607638888889	0.113274256104093\\
4.05780092592593	0.116773960469671\\
4.05827546296296	0.116916833565613\\
4.06336805555556	0.118456073307555\\
4.16209490740741	0.150349167678444\\
4.16583333333333	0.15162890504352\\
4.16824074074074	0.152455592737911\\
4.17811342592593	0.155866704882163\\
4.23090277777778	0.174643282117539\\
4.23425925925926	0.175865750052902\\
4.34474537037037	0.2176340871865\\
4.34844907407407	0.219075683358871\\
4.35103009259259	0.220081485095925\\
4.39923611111111	0.239016513768934\\
4.40034722222222	0.239455648494986\\
4.40402777777778	0.240910933410999\\
4.45054398148148	0.259361107514755\\
4.45975694444444	0.263020704675936\\
4.46435185185185	0.264845640080319\\
4.46532407407407	0.265231730253706\\
4.51805555555556	0.286109730931025\\
4.51966435185185	0.286743567257506\\
4.52009259259259	0.286912243141898\\
4.52246527777778	0.287846462802398\\
4.52336805555556	0.288201769803509\\
4.52395833333333	0.288434039714928\\
4.57143518518519	0.306968444443221\\
4.57194444444444	0.307165380895864\\
4.57393518518519	0.307934780612511\\
4.5762962962963	0.308846398005794\\
4.57699074074074	0.309114326813703\\
4.58032407407407	0.310399136803965\\
4.58097222222222	0.310648718072355\\
4.58162037037037	0.310898219303362\\
4.61822916666667	0.324848025518907\\
4.62917824074074	0.328959662349098\\
4.62978009259259	0.32918478345194\\
4.63076388888889	0.329552565824075\\
4.63206018518519	0.330036784547605\\
4.63226851851852	0.330114564011337\\
4.6349537037037	0.331116020924039\\
4.63815972222222	0.332309185157695\\
4.68565972222222	0.349632818056558\\
4.6862962962963	0.349860112178181\\
4.6946412037037	0.352826857433508\\
4.69556712962963	0.353154545087497\\
4.74951388888889	0.371690451850331\\
4.75083333333333	0.37212923615202\\
4.75155092592593	0.372367564025102\\
4.80350694444444	0.389014974638047\\
4.80724537037037	0.390164266877546\\
4.81015046296296	0.391052657984112\\
4.81168981481482	0.391521718574341\\
4.8565162037037	0.404652449900448\\
4.85902777777778	0.405356937720316\\
4.86289351851852	0.406434586561296\\
4.86568287037037	0.407207116370009\\
4.86581018518519	0.407242275553872\\
4.86608796296296	0.407318955683399\\
4.86652777777778	0.407440279412761\\
4.8666087962963	0.407462616953699\\
4.86809027777778	0.407870439593447\\
4.86835648148148	0.407943592418013\\
4.86905092592593	0.408134242360136\\
4.869375	0.408223121469713\\
4.91210648148148	0.419424118279232\\
4.9234837962963	0.422228242878986\\
4.92386574074074	0.42232104678629\\
4.92396990740741	0.422346341843599\\
4.9243287037037	0.422433419713792\\
4.9250462962963	0.422607344935392\\
4.92568287037037	0.422761375989528\\
4.92667824074074	0.423001738940077\\
4.97186342592593	0.433277751048753\\
4.98336805555556	0.435691399583365\\
4.98383101851852	0.43578677351607\\
5.02824074074074	0.444294373870171\\
5.03604166666667	0.445656041051024\\
5.03638888888889	0.445715716299448\\
5.0368287037037	0.445791190590365\\
5.03813657407407	0.446014871851283\\
5.03834490740741	0.446050398056992\\
5.03850694444444	0.446078009701621\\
5.03966435185185	0.446274730507957\\
5.03972222222222	0.446284543275121\\
5.03991898148148	0.446317890099663\\
5.04091435185185	0.446486192927966\\
5.04208333333333	0.446683012846598\\
5.04222222222222	0.44670633719696\\
5.08837962962963	0.45374403761591\\
5.09479166666667	0.454608247248305\\
5.09842592592593	0.455085698832781\\
5.0990162037037	0.455162400887773\\
5.09925925925926	0.455193915357302\\
5.14765046296296	0.460666862051421\\
5.15236111111111	0.461114212700323\\
5.15459490740741	0.461321041489841\\
5.1550462962963	0.461362421335323\\
5.15631944444444	0.461478382726298\\
5.20888888888889	0.465299213220806\\
5.21149305555556	0.465439486529844\\
5.21186342592593	0.465459061987131\\
5.21314814814815	0.465526241731325\\
5.21327546296296	0.46553283809714\\
5.21475694444444	0.465608786125849\\
5.26159722222222	0.467244781045351\\
5.27122685185185	0.467398520978826\\
5.27228009259259	0.467411588392468\\
5.27280092592593	0.46741777770565\\
5.31628472222222	0.467303374220536\\
5.32148148148148	0.467207060184445\\
5.32450231481482	0.467143053865539\\
5.32523148148148	0.467126722518213\\
5.3290625	0.467035295965608\\
5.32938657407407	0.467027129160482\\
5.32986111111111	0.467015048944359\\
5.33034722222222	0.46700252419693\\
5.37268518518519	0.465336166100842\\
5.38502314814815	0.464639682011586\\
5.38523148148148	0.464627117634754\\
5.38607638888889	0.464575889584477\\
5.38643518518519	0.464554003005702\\
5.38741898148148	0.464493587390402\\
5.38778935185185	0.464470689356899\\
5.42561342592593	0.461696330742013\\
5.43828703703704	0.460577080883142\\
5.45168981481481	0.459292341217369\\
5.49454861111111	0.454506229927172\\
5.49575231481481	0.454357275394334\\
5.498125	0.454061387450971\\
5.55136574074074	0.4466501086658\\
5.55638888888889	0.445876974971006\\
5.55946759259259	0.445397032113494\\
5.56048611111111	0.445237241048465\\
5.60539351851852	0.437705708169151\\
5.61043981481482	0.436801813973101\\
5.61315972222222	0.436309962310975\\
5.61460648148148	0.436047017160842\\
5.61685185185185	0.43563711620259\\
5.61778935185185	0.435465322525208\\
5.63293981481482	0.432636667177446\\
5.67181712962963	0.424944035254519\\
5.67417824074074	0.424457553413042\\
5.67565972222222	0.42415121917295\\
5.67583333333333	0.424115265750828\\
5.72508101851852	0.413470679615348\\
5.72584490740741	0.413298867704501\\
5.72984953703704	0.412394966030645\\
5.73196759259259	0.411914737841747\\
5.73237268518518	0.411822722257872\\
5.7333912037037	0.411591130317538\\
5.78729166666667	0.398873643663306\\
5.84063657407407	0.385490587900312\\
5.84469907407407	0.384442888532236\\
5.84494212962963	0.384380086871445\\
5.84501157407407	0.384362141090619\\
5.84572916666667	0.384176637703862\\
5.84731481481481	0.383766324753694\\
5.84744212962963	0.383733355496616\\
5.84780092592593	0.383640422658648\\
5.84868055555556	0.383412465887422\\
5.90346064814815	0.368901703745352\\
5.90456018518519	0.368604623717474\\
5.90581018518519	0.368266636820734\\
5.95017361111111	0.356109889528385\\
5.95128472222222	0.355801721899461\\
5.95733796296296	0.354119992939339\\
5.95859953703704	0.353768901492562\\
5.99944444444444	0.342301922290282\\
6.01927083333333	0.336675837630438\\
6.02068287037037	0.336273898610468\\
6.07572916666667	0.320505614598195\\
6.07767361111111	0.319945882378816\\
6.12369212962963	0.306671554788074\\
6.13309027777778	0.303957572999751\\
6.13498842592593	0.303409441699248\\
6.13619212962963	0.303061853564405\\
6.17320601851852	0.292382356206059\\
6.18494212962963	0.289002732414914\\
6.24876157407407	0.270733777353154\\
6.25163194444444	0.269917834873022\\
6.25172453703704	0.269891524001991\\
6.3034837962963	0.255292465639274\\
6.30511574074074	0.254836072215917\\
6.30893518518519	0.253768944610322\\
6.30917824074074	0.253701085629096\\
6.36299768518519	0.238832223555173\\
6.36516203703704	0.238241288256079\\
6.36681712962963	0.237789787109129\\
6.37883101851852	0.234522768827404\\
6.42065972222222	0.223297078608101\\
6.42096064814815	0.223217197671132\\
6.47592592592593	0.208853197457142\\
6.5343287037037	0.194119970184463\\
6.5375462962963	0.193325082699535\\
6.53884259259259	0.193005350048258\\
6.59601851851852	0.179200773704579\\
6.64996527777778	0.166728803843125\\
6.65070601851852	0.166561395659138\\
6.65076388888889	0.166548321330087\\
6.69883101851852	0.155912622211993\\
6.70283564814815	0.155046863718688\\
6.70502314814815	0.154575279810585\\
6.70605324074074	0.154353537004973\\
6.71027777777778	0.153446326231519\\
6.71064814814815	0.153366957470355\\
6.71068287037037	0.15335951803429\\
6.71171296296296	0.153138922807022\\
6.71193287037037	0.153091856524117\\
6.73209490740741	0.148817189067223\\
6.75421296296296	0.144220459238812\\
6.76596064814815	0.141818530142612\\
6.81811342592593	0.13148782673092\\
6.88480324074074	0.119068081265702\\
6.94032407407407	0.109399998797508\\
6.94290509259259	0.10896524888857\\
6.98989583333333	0.101275581279868\\
7.05606481481481	0.0911603774448656\\
7.15710648148148	0.0772619765531253\\
7.16491898148148	0.076262400138364\\
7.28027777777778	0.0626875131361991\\
7.28799768518518	0.0618554279662462\\
7.28805555555556	0.0618492253067717\\
7.4034375	0.0504740060039697\\
7.45590277777778	0.0459208161302344\\
7.69079861111111	0.0296173610549714\\
7.74900462962963	0.0264704284323471\\
8.03364583333333	0.0149926115586325\\
8.08883101851852	0.013381680942153\\
8.84060185185185	0.00258710649522333\\
};
\addlegendentry{Log-Normal}

\end{axis}
\end{tikzpicture}% 	\caption{The probability densities over the density of the observed lifetimes.}
\end{figure}
\subsection{Phase-type}
As the class of Phase-Type distributions is dense in the space of positive continuous distributions \cite{Ocinneide1999}, a Phase-Type distribution could also be used to model the lifetimes.
However, Phase-Type distributions have a few disadvantages:
the number of parameters grows quadratically with the amount of states and most of these parameters are redundant.
Furthermore, convergence of the EM-algorithm (to estimate the parameters) is slow and can get stuck in saddle points and local maxima \cite{Asmussen1996}.
Because of this, we will not use a Phase-type distribution to model the lifetime of the machine.

\section{Transition times}
In order to model the transitions between the events as a Markov chain, we need to find out whether the transition times (i.e. the length of the time intervals between the start and end of an event) are exponentially distributed.
When we visualized the distribution of the transition times for each of the states, we noticed two things:
\begin{enumerate}
	\item The distribution is not exponentially distributed.
	In figure \ref{figure:transitionFit}, it is visible that the exponential distribution fits the data poorly.
	\item For some events, the distribution of the time length seems to be multimodal.
	In figure \ref{figure:transitionBimodal}, an example of an event whose time length seems to have multimodal distribution.
\end{enumerate}
\begin{figure}[H]\label{figure:transitionFit}
\centering
\setlength\fwidth{0.5\textwidth}
\definecolor{mycolor1}{rgb}{0.00000,0.44700,0.74100}
\definecolor{mycolor2}{rgb}{0.85000,0.32500,0.09800}
\begin{tikzpicture}

\begin{axis}[
width=0.951\fwidth,
height=0.75\fwidth,
at={(0\fwidth,0\fwidth)},
scale only axis,
xmin=0,
xmax=300,
xlabel style={font=\color{white!15!black}},
xlabel={Transition time (s)},
ymin=0,
ymax=0.015,
ylabel style={font=\color{white!15!black}},
ylabel={Probability density},
axis background/.style={fill=white},
legend style={legend cell align=left, align=left, draw=white!15!black}
]
\addplot [color=mycolor1]
  table[row sep=crcr]{
0.00640453706108545	0.0046590164316289\\
2.80796273678352	0.00499701552866505\\
5.60952093650595	0.00289172760488058\\
8.41107913622838	0.00609267053684514\\
11.2126373359508	0.00713565061559552\\
14.0141955356732	0.00656398995561213\\
16.8157537353957	0.00651531195073745\\
19.6173119351181	0.00611245239683321\\
22.4188701348405	0.00616967234765618\\
25.220428334563	0.00663625222633286\\
28.0219865342854	0.00719511308207897\\
30.8235447340078	0.00778130365063828\\
33.6251029337303	0.00824048383672168\\
36.4266611334527	0.00847883758297363\\
39.2282193331751	0.00857320870857549\\
42.0297775328976	0.0086588980951206\\
44.83133573262	0.00881379686560755\\
47.6328939323424	0.00903552517386028\\
50.4344521320649	0.00927572802822487\\
53.2360103317873	0.00947596311956679\\
56.0375685315097	0.00959102706019905\\
58.8391267312321	0.00959973686578718\\
61.6406849309546	0.00950578084335286\\
64.442243130677	0.00933241801694909\\
67.2438013303995	0.00911150387677278\\
70.0453595301219	0.00887249443745627\\
72.8469177298443	0.00863538439322233\\
75.6484759295667	0.00840811837627717\\
78.4500341292892	0.00818860628364154\\
81.2515923290116	0.00796931708776199\\
84.053150528734	0.00774125067815781\\
86.8547087284565	0.00749763472827366\\
89.6562669281789	0.00723519649630906\\
92.4578251279013	0.00695428705724597\\
95.2593833276238	0.00665818833080211\\
98.0609415273462	0.00635170881658381\\
100.862499727069	0.00604007232542152\\
103.664057926791	0.0057282802292285\\
106.465616126513	0.00542029906622655\\
109.267174326236	0.0051192736700817\\
112.068732525958	0.00482730110129367\\
114.870290725681	0.00454561866405939\\
117.671848925403	0.00427472043796758\\
120.473407125126	0.00401484153673036\\
123.274965324848	0.00376564238569575\\
126.076523524571	0.00352681141212658\\
128.878081724293	0.00329777496000353\\
131.679639924015	0.00307799567784115\\
134.481198123738	0.00286698123027079\\
137.28275632346	0.00266423440205625\\
140.084314523183	0.00246939794862223\\
142.885872722905	0.00228224243011516\\
145.687430922628	0.00210271471616342\\
148.48898912235	0.00193072147763638\\
151.290547322072	0.00176641470983604\\
154.092105521795	0.00160992532732046\\
156.893663721517	0.00146141004502071\\
159.69522192124	0.00132107596247703\\
162.496780120962	0.00118912884086104\\
165.298338320685	0.00106570092458128\\
168.099896520407	0.000950880244797554\\
170.901454720129	0.000844675827189715\\
173.703012919852	0.00074696644731881\\
176.504571119574	0.000657638818124687\\
179.306129319297	0.000576435361709148\\
182.107687519019	0.000503029486431895\\
184.909245718742	0.000437066020676758\\
187.710803918464	0.000378130527083519\\
190.512362118186	0.000325754027575806\\
193.313920317909	0.000279461301337812\\
196.115478517631	0.000238804857991803\\
198.917036717354	0.000203258106683311\\
201.718594917076	0.000172327147521403\\
204.520153116799	0.000145543307991678\\
207.321711316521	0.000122463558543285\\
210.123269516243	0.000102668877275223\\
212.924827715966	8.57745374552172e-05\\
215.726385915688	7.14122826060666e-05\\
218.527944115411	5.925063425321e-05\\
221.329502315133	4.90042479348361e-05\\
224.131060514856	4.04001741714251e-05\\
226.932618714578	3.32008401009208e-05\\
229.7341769143	2.72172951819839e-05\\
232.535735114023	2.2241411881663e-05\\
235.337293313745	1.81274911965092e-05\\
238.138851513468	1.47253581504867e-05\\
240.94040971319	1.19281405852014e-05\\
243.741967912913	9.64506355576436e-06\\
246.543526112635	7.76058728791677e-06\\
249.345084312357	6.24122178532816e-06\\
252.14664251208	4.99590416878024e-06\\
254.948200711802	3.99137215484466e-06\\
257.749758911525	3.18916797569794e-06\\
260.551317111247	2.54275380281719e-06\\
263.35287531097	2.01065832989213e-06\\
266.154433510692	1.58584406212675e-06\\
268.955991710415	1.24869952106274e-06\\
271.757549910137	9.82456395021083e-07\\
274.559108109859	7.67297354432874e-07\\
277.360666309582	5.9884187869126e-07\\
};
\addlegendentry{Observed}

\addplot [color=mycolor2]
  table[row sep=crcr]{
0.00640453706108545	0.0144138284310982\\
2.80796273678352	0.0138433247093713\\
5.60952093650595	0.0132954016988039\\
8.41107913622838	0.012769165647967\\
11.2126373359508	0.0122637581803857\\
14.0141955356732	0.0117783548943876\\
16.8157537353957	0.0113121640183695\\
19.6173119351181	0.0108644251192897\\
22.4188701348405	0.0104344078622781\\
25.220428334563	0.010021410819341\\
28.0219865342854	0.00962476032521879\\
30.8235447340078	0.00924380937852794\\
33.6251029337303	0.00887793658639688\\
36.4266611334527	0.00852654515087327\\
39.2282193331751	0.00818906189544959\\
42.0297775328976	0.00786493633011915\\
44.83133573262	0.00755363975343748\\
47.6328939323424	0.00725466439012439\\
50.4344521320649	0.00696752256280002\\
53.2360103317873	0.00669174589650384\\
56.0375685315097	0.00642688455469897\\
58.8391267312321	0.00617250650551573\\
61.6406849309546	0.00592819681703751\\
64.442243130677	0.00569355698047942\\
67.2438013303995	0.00546820426015569\\
70.0453595301219	0.00525177106917564\\
72.8469177298443	0.00504390436984973\\
75.6484759295667	0.00484426509782779\\
78.4500341292892	0.0046525276090299\\
81.2515923290116	0.0044683791484681\\
84.053150528734	0.00429151934009216\\
86.8547087284565	0.00412165969682742\\
89.6562669281789	0.00395852315000559\\
92.4578251279013	0.00380184359742068\\
95.2593833276238	0.0036513654692731\\
98.0609415273462	0.00350684331129383\\
100.862499727069	0.0033680413843686\\
103.664057926791	0.00323473328000912\\
106.465616126513	0.00310670155104408\\
109.267174326236	0.00298373735692746\\
112.068732525958	0.00286564012308568\\
114.870290725681	0.00275221721374794\\
117.671848925403	0.00264328361772592\\
120.473407125126	0.00253866164663053\\
123.274965324848	0.00243818064503326\\
126.076523524571	0.00234167671209946\\
128.878081724293	0.00224899243423949\\
131.679639924015	0.00215997662834153\\
134.481198123738	0.00207448409516739\\
137.28275632346	0.00199237538250902\\
140.084314523183	0.0019135165577192\\
142.885872722905	0.00183777898924576\\
145.687430922628	0.00176503913681252\\
148.48898912235	0.00169517834990509\\
151.290547322072	0.00162808267423262\\
154.092105521795	0.00156364266584978\\
156.893663721517	0.00150175321263598\\
159.69522192124	0.00144231336284037\\
162.496780120962	0.00138522616041319\\
165.298338320685	0.00133039848685464\\
168.099896520407	0.00127774090932355\\
170.901454720129	0.00122716753475784\\
173.703012919852	0.00117859586976902\\
176.504571119574	0.00113194668608202\\
179.306129319297	0.00108714389130108\\
182.107687519019	0.00104411440479063\\
184.909245718742	0.00100278803846893\\
187.710803918464	0.000963097382319906\\
190.512362118186	0.000924977694436467\\
193.313920317909	0.000888366795415925\\
196.115478517631	0.000853204966935305\\
198.917036717354	0.000819434854341052\\
201.718594917076	0.000787001373094274\\
204.520153116799	0.00075585161891892\\
207.321711316521	0.000725934781506303\\
210.123269516243	0.000697202061635239\\
212.924827715966	0.000669606591572588\\
215.726385915688	0.000643103358624372\\
218.527944115411	0.000617649131712758\\
221.329502315133	0.000593202390859145\\
224.131060514856	0.000569723259458339\\
226.932618714578	0.000547173439233333\\
229.7341769143	0.000525516147764593\\
232.535735114023	0.000504716058491959\\
235.337293313745	0.000484739243091289\\
238.138851513468	0.000465553116131848\\
240.94040971319	0.000447126381924181\\
243.741967912913	0.000429428983471758\\
246.543526112635	0.00041243205344313\\
249.345084312357	0.000396107867084625\\
252.14664251208	0.00038042979699677\\
254.948200711802	0.000365372269700678\\
257.749758911525	0.000350910723923547\\
260.551317111247	0.000337021570535241\\
263.35287531097	0.00032368215407058\\
266.154433510692	0.000310870715774601\\
268.955991710415	0.000298566358110494\\
271.757549910137	0.000286749010672323\\
274.559108109859	0.000275399397446936\\
277.360666309582	0.000264499005371654\\
};
\addlegendentry{Exponential fit}

\end{axis}
\end{tikzpicture}% \caption{An exponential distribution fitted over the distribution of the time length of a certain event.}
\end{figure}
\begin{figure}[H]\label{figure:transitionBimodal}
\centering
\setlength\fwidth{0.5\textwidth}
\definecolor{mycolor1}{rgb}{0.00000,0.44700,0.74100}
\begin{tikzpicture}

\begin{axis}[
width=0.951\fwidth,
height=0.75\fwidth,
at={(0\fwidth,0\fwidth)},
scale only axis,
xmin=0,
xmax=300,
xlabel style={font=\color{white!15!black}},
xlabel={Transition time (s)},
ymin=0,
ymax=0.014,
ylabel style={font=\color{white!15!black}},
ylabel={Probability density},
axis background/.style={fill=white},
legend style={legend cell align=left, align=left, draw=white!15!black}
]
\addplot [color=mycolor1]
  table[row sep=crcr]{
0.00640453706108545	2.36570814763154e-22\\
2.80796273678352	0.0125270142252472\\
5.60952093650595	0.0111829729187901\\
8.41107913622838	0.0102459076587055\\
11.2126373359508	0.00916915920875157\\
14.0141955356732	0.00854187382170363\\
16.8157537353957	0.00853198246136874\\
19.6173119351181	0.00875412954066575\\
22.4188701348405	0.0089203800274997\\
25.220428334563	0.00881619417926449\\
28.0219865342854	0.00847750594178337\\
30.8235447340078	0.00807353051240437\\
33.6251029337303	0.00770414017471351\\
36.4266611334527	0.0073850523981109\\
39.2282193331751	0.00711171963788143\\
42.0297775328976	0.00689502653249833\\
44.83133573262	0.00675307682397332\\
47.6328939323424	0.00669633482067222\\
50.4344521320649	0.00672107624977652\\
53.2360103317873	0.00681225978364848\\
56.0375685315097	0.00694871833243325\\
58.8391267312321	0.00710832372894595\\
61.6406849309546	0.00727042738463208\\
64.442243130677	0.00741762058082715\\
67.2438013303995	0.0075367613823563\\
70.0453595301219	0.00761927303522195\\
72.8469177298443	0.00766040314321193\\
75.6484759295667	0.00765852477649616\\
78.4500341292892	0.00761409655149279\\
81.2515923290116	0.00752887985439346\\
84.053150528734	0.0074052587288388\\
86.8547087284565	0.00724605948914871\\
89.6562669281789	0.00705430502160476\\
92.4578251279013	0.00683331140761602\\
95.2593833276238	0.0065867151870682\\
98.0609415273462	0.00631835372870724\\
100.862499727069	0.00603229668149394\\
103.664057926791	0.00573274083404246\\
106.465616126513	0.00542381843925119\\
109.267174326236	0.00510955251881984\\
112.068732525958	0.00479367789881658\\
114.870290725681	0.00447963321414884\\
117.671848925403	0.00417046755298617\\
120.473407125126	0.00386874423932405\\
123.274965324848	0.00357666042260674\\
126.076523524571	0.00329592937782493\\
128.878081724293	0.00302786635336438\\
131.679639924015	0.00277343044063228\\
134.481198123738	0.0025333001780329\\
137.28275632346	0.00230775387102386\\
140.084314523183	0.00209689943000872\\
142.885872722905	0.00190061757937996\\
145.687430922628	0.0017186315179025\\
148.48898912235	0.0015505094711736\\
151.290547322072	0.00139572657189834\\
154.092105521795	0.0012537164498834\\
156.893663721517	0.00112380038037391\\
159.69522192124	0.00100528299528276\\
162.496780120962	0.000897462829627284\\
165.298338320685	0.000799626985799713\\
168.099896520407	0.00071109518028669\\
170.901454720129	0.000631133840940451\\
173.703012919852	0.000559134603021757\\
176.504571119574	0.000494434661180359\\
179.306129319297	0.000436429946633241\\
182.107687519019	0.000384551934464447\\
184.909245718742	0.000338240975237184\\
187.710803918464	0.000296989388839306\\
190.512362118186	0.000260327723646626\\
193.313920317909	0.000227814778057247\\
196.115478517631	0.000199028003703534\\
198.917036717354	0.000173606512974949\\
201.718594917076	0.000151192993838406\\
204.520153116799	0.000131465022980161\\
207.321711316521	0.000114138560909403\\
210.123269516243	9.89546396363473e-05\\
212.924827715966	8.56715794289254e-05\\
215.726385915688	7.40576195813476e-05\\
218.527944115411	6.39363119074382e-05\\
221.329502315133	5.51325100909633e-05\\
224.131060514856	4.74773712036014e-05\\
226.932618714578	4.08382550786416e-05\\
229.7341769143	3.50814828125811e-05\\
232.535735114023	3.00947776643792e-05\\
235.337293313745	2.57975758202048e-05\\
238.138851513468	2.20886594807411e-05\\
240.94040971319	1.88930258900354e-05\\
243.741967912913	1.61386275860817e-05\\
246.543526112635	1.37641275125242e-05\\
249.345084312357	1.17285313501636e-05\\
252.14664251208	9.98965692688269e-06\\
254.948200711802	8.498463851849e-06\\
257.749758911525	7.22112197784494e-06\\
260.551317111247	6.13243040751498e-06\\
263.35287531097	5.20609268728565e-06\\
266.154433510692	4.40988457428837e-06\\
268.955991710415	3.74270684074729e-06\\
271.757549910137	3.16626892151522e-06\\
274.559108109859	2.67934867619932e-06\\
277.360666309582	2.26625893458976e-06\\
};
\addlegendentry{Observed}

\end{axis}
\end{tikzpicture}% \caption{The estimated probability density function for the time length of a certain event.}
\end{figure}
From this, we can safely conclude that the transition times are not exponential and that a CTMC is not appropriate to accurately model the trace data.
But since using a semi-Markov model would complicate the analysis significantly, we will approximate the data by a CTMC anyway.  
\chapter{Parameter estimation}\label{chapter:ParameterEstimation}
In this chapter, we will discuss methods for estimating the parameters of the Markov modulated fluid model.
These parameters are the following:
\begin{itemize}
	\item First of all, we need the parameters of the CTMC.
	These are the transition rates $\lambda_{ij}$ between the states $s_i$ and $s_j$.
	\item For the fluid model, we also need a rate $r_i>0$ for each state $s_i$ and we need the size of the fluid increases $J_{ij}$ for transitions from $s_i$ to $s_j$. 
\end{itemize}
This results in $N^2+N+N^2=2N^2+N$ parameters.
Furthermore, we need a distribution for the initial fluid level.
\section{CTMC Estimation}
When we have the trace data, it is not difficult to estimate the transition rates.
We have continuous observations over the Markov chain as for each time, we know exactly in which CTMC-state the process was.
Let $T_i$ be the total time the process was observed to be in CTMC-state $s_i$ and let $N_{ij}$ be the total number of transitions that occurred from $s_i$ to $s_j$.
The maximum likelihood estimator of the rates $\lambda_{ij}$ is simply given by \cite{Inamura2006}
\[
\hat\lambda_{ij}=\frac{N_{ij}}{T_i}.
\]

\section{Estimating fluid rates and jump quantities}
Estimating the fluid rates and jump quantities is more difficult as we do not observe the fluid level at each time, but only the time at which the fluid level reaches zero (i.e. when the asset breaks).
In this section we will first compute the log likelihood of rate and jump parameters given trace data and discuss maximizing this likelihood.
Then we will propose an alternative method to estimate the parameters.

\subsection{Likelihood}
Suppose we have observed a run of the process and have seen that it started in state $s_{i_1}$, stayed there for a period time of length $\tau_1$.
Suppose also that after this time, a transition occurred to $s_{i_2}$ and the process stayed there for a time $\tau_2$ and so forth.
Hence we have observations in the following form
$$
\sigma=\left[(i_1,\tau_1),...,(i_L,\tau_L)\right].
$$
We assume that no preventive maintenance had been done so that after the last observation in the trace, the asset failed.
We also assume that the initial distribution is known and has probability density function $f$.

For a given MMFM model $M$ with rates $r_i$ and jump quantities $J_{ij}$, this would mean that initially the fluid level was
\begin{equation}\label{eq:initialLevelDefinition}
q_0(M,\sigma)=\tau_1r_{i_1}+\sum\limits_{l=2}^{L}\tau_lr_{i_l}-J_{i_{l-1}i_l}
\end{equation}
So that the likelihood of this trace would be
$$
L(M,\sigma)=f(q_0(M,\sigma))\left[\prod\limits_{l=1}^{L-1}\lambda_{i_li_{l+1}}e^{-\lambda_{i_l}\tau_l}\right]e^{-\lambda_{i_L}\tau_L}
$$
using $\lambda_i=\sum_j\lambda_{ij}$.
If we have a set of traces $\Sigma=[\sigma_1,...,\sigma_K]$ with \[
\sigma^{(k)}=\left[(i_1^{(k)},\tau_1^{(k)}),...,(i_{L^{(k)}}^{(k)},\tau_{L^{(k)}}^{(k)})\right],
\]
then the log-likelihood would be
\begin{equation}\label{eq:MmfmLikelihood}
\begin{split}
L(M,\Sigma)&=\sum\limits_{k=1}^K\log L(M,\sigma_k)\\
&=\sum\limits_{k=1}^K\log f(q_0(M,\sigma_k))+\log\left(\left[\prod\limits_{l=1}^{L-1}\lambda_{i_ki_{k+1}}e^{-\lambda_{i_k}\tau_k}\right]e^{-\lambda_{i_L}\tau_L}\right).
\end{split}
\end{equation}

\subsection{Maximizing likelihood}
To maximize the log-likelihood \eqref{eq:MmfmLikelihood}, we take partial derivatives to the fluid rates and jump quantities.
Let us first define some quantities:
Let $\tau(i,\sigma)$ be the total time the process was in state $s_i$ for trace $\sigma$, i.e.
$$
\tau(i,\sigma)=\sum\limits_{k|i_k=i}\tau_k.
$$
Furthermore, let $\#(i,j,\sigma)$ be the number of times a transition from $s_i$ to $s_j$ occurred in trace $\sigma$.
We will now introduce two lemmas:
\begin{lemma}
	The derivative of the initial level $q_0(M,\sigma)$ to the fluid rate $r_i$ is given by
	\[
	\frac{d}{dr_i}q_0(M,\sigma)=\tau(i,\sigma).
	\]
	\begin{proof}
		The proof is straightforward:
		\[
		\frac{d}{dr_i}q_0(M,\sigma)=\frac{d}{dr_i}\left[\tau_1r_{i_1}+\sum\limits_{l=2}^{L}\tau_lr_{i_l}-J_{i_{l-1}i_l}\right]=\sum\limits_{i_l=i}\tau_l=\tau(i,\sigma).
		\]
	\end{proof}
\end{lemma}
And similarly, for the jump quantity $J_{ij}$:
\begin{lemma}
	The derivative of the initial level  $q_0(M,\sigma)$ to the jump quantity $J_{ij}$ is given by
	\[
	\frac{d}{dJ_{ij}}q_0(M,\sigma)=\#(i,j,\sigma).
	\]
	\begin{proof}
		Again:
		\[
		\frac{d}{dJ_{ij}}q_0(M,\sigma)=\frac{d}{dJ_{ij}}\left[\tau_1r_{i_1}+\sum\limits_{l=2}^{L}\tau_lr_{i_l}-J_{i_{l-1}i_l}\right]=-\#(i,j,\sigma).
		\]
	\end{proof}
\end{lemma}

Before we take the derivative of \eqref{eq:MmfmLikelihood} to $r_i$, we note that only $\log f(q_0(M,\sigma))$ depends on $r_i$ so that the other term vanishes.
Hence:
\[
\frac{d}{dr_i}\log L(M,\Sigma)
=\frac{d}{dr_i}\sum_k\log f(q_0(M,\sigma^{(k)}))=\sum_k\frac{f'(q_0(M,\sigma^{(k)}))}{f(q_0(M,\sigma^{(k)}))}\tau(i,\sigma^{(k)}).
\]
Similarly, for the jump quantities $J_{ij}$, we get
$$
\frac{d}{dJ_{ij}}\log L(M,\Sigma)=\frac{d}{dJ_{ij}}\sum_k\log f(q_0(M,\sigma^{(k)}))=-\sum_k\frac{f'(q_0(M,\sigma^{(k)}))}{f(q_0(M,\sigma^{(k)}))}\#(i,j,\sigma^{(k)}).
$$
The maximum likelihood estimators $\hat r_i$ and $\hat J_{ij}$ are then a solution to the set of equations 
\[
\frac{d}{dr_i}\log L(M,\Sigma)=0,
\]
and
\[
\frac{d}{dJ_{ij}}\log L(M,\Sigma)=0,
\]
for all $i,j\in\{1,...,N\}$.

\begin{remark}
	Note that this maximum likelihood estimator for the fluid rates and jump quantities does not depend on the transition rates of the CTMC.
\end{remark}

\begin{remark}
	It may be difficult to find a solution to these equations.
	Alternatively, we could also find estimates by numerically maximizing the likelihood \eqref{eq:MmfmLikelihood}. 
\end{remark}

\subsection{Minimizing variance}
We will now propose an alternative method to estimate the fluid rates and jump quantities.
The asset is likely produced by a manufacturer that strives for a constant quality of the produced goods (i.e. wants to maintain continuity).
Hence, we could expect the initial fluid level, which corresponds to the initial fitness of the asset, to have a low variance.
Given trace data, we will therefore try to find MMFM parameters that minimize the variance of the initial fluid level.
From \eqref{eq:initialLevelDefinition} we can find the initial fluid levels for given parameters.
We then still need to fix an average initial fluid level $\bar q$.
Note that it does not matter which value we choose for $\bar q$ as \eqref{eq:initialLevelDefinition} is linear so that multiplying $\bar q$ by a constant will merely result in the parameters being multiplied by the same constant.
We then compute the variance for given parameters and trace data by squaring the difference between the initial level and the average $\bar q$.
Hence, we will minimize the following goal function:
\begin{equation}\label{eq:MinVarianceGoalFunction}
G(M,\Sigma)=\frac1K\sum_k \left(\bar q - q_0\left(M,\sigma^{(k)}\right)\right)^2.
\end{equation}

\subsection{Results}
Although we haven't been able to analyze the method of minimizing variance, we have implemented it in Matlab.
We have tested it with simulated trace data and compared the resulting parameters with the original parameters.
The performance of the method depends a lot on the variance of the initial distribution.
For distributions with large variance, it often occurs that the method manages to minimize the goal function \eqref{eq:MinVarianceGoalFunction} below the actual variance of the distribution.
This results in incorrect parameters.
However, the accuracy seems to improve for smaller variances. 
\chapter{Conclusion}\label{chapter:Conclusion}

In this thesis, discounted preventive maintenance problems were considered.
We used the following parameters:
a cost $c$ is paid for maintenance.
For corrective maintenance an additional cost $a$ must be paid.
Costs at time $t$ in the future are discounted by the discount factor $e^{-\beta t}$.
We assumed that the distribution of the initial fitness of the asset (its lifetime or initial fluid level) has an increasing hazard rate $h$.

We showed that for the age-based preventive maintenance problem, the optimal policy is a stationary control limit policy where maintenance is chosen whenever the age reaches the optimal control limit $\mu^*$.
If $\mu^*<\infty$, then this $\mu^*$ is the solution to the equation
\begin{equation}\label{eq:SummaryAgeControlLimit}
h(\mu^*)=\beta\frac{c+V(0^+,\mu^*)}{a},
\end{equation}
where $V(0^+,\mu^*)$ denotes the expected total discounted cost.
A policy iteration method was introduced and its convergence was proven.

For the simple fluid problem, we proved that the optimal policy is a stationary control limit policy where maintenance is chosen when the amount of used initial fluid exceeds a certain threshold $\mu^*$.
We showed that this problem can be reduced to the age-based maintenance problem by changing the discount factor.
For fluid jumps happening at rate $\lambda$ with size $J$, this adjusted discount is given by
\[
\beta^*=\beta+\lambda(1-D(J)),
\]
where $D(J)$ denotes the expected value of the discount factor over the period in which the fluid level decreases by $J$.
$D(J)$ can be computed using a method of successive approximation.
Because of the equivalence between this problem and the age-based maintenance problem, the same equation for the control limit holds and the same policy iteration method can be used.

We extended this simple fluid problem to a problem where the degradation of the asset is modeled by a MMFM with jumps.
Results from value iteration suggest that the solution is a stationary policy with control limits $\mu_i^*$ for CTMC-state $s_i$.
Ways to calculate the expected total discounted cost were presented and an equation was derived to which the optimal control limit adheres.
A policy iteration method similar to the one for age-based maintenance was presented.

Also, a method to estimate the fluid rates and the jump quantities was presented that assumes the distribution of the initial fluid level has a small variance.

\section{Further research}
We expect that the obtained results can be extended to models allowing states with zero fluid rates or fluid rates of opposite sign.
The results might also be extended to initial distributions without monotonously increasing hazard rates.

The model that was considered in this thesis was simplified in order to make the analysis feasible.
It could be made more realistic in one of the following ways:
the model could be extended to allow non-exponential transition times, i.e. by replacing the Markov chain by a semi-Markov process.
The jump sizes could also be modeled as random variables.
With the extra randomness in the jump sizes, the distribution of the current fluid level can no longer be described using the two state variables $L_0$ and $L_c$, as it would not be certain how much fluid is in the buffer at each time.
Also, similar to the second order fluid model as considered in \cite{Gribaudo2007}, the fluid decrease could be modeled as Brownian motion.
Again, with this extra randomness, we would lose certainty of the amount of fluid that is inside the buffer $L_c$ at each time.

Better methods for estimating the fluid parameters (fluid rates and jump sizes) from trace data could also be researched.

\chapter{Discussion}\label{chapter:discussion}
We briefly discuss the assumptions on which this thesis relies and what happens when these assumptions fail.
The effect of small changes in problem parameters is also discussed.
\section{Assumptions}
We assumed perfect repairs.
This means that after preventive or corrective maintenance, the fitness of the asset has the same distribution as a new asset.
If this assumption were to be violated, the optimal policy would no longer be stationary as it would depend on the number of repairs that have occurred.

We also assumed the cumulative distribution function of the initial fitness of the asset to be continuously differentiable.
If this were to fail, the hazard rate (and the derivative of the value function) might be undefined or infinite at points where the distribution would not be continuous or differentiable.

The hazard rate was also assumed to be increasing and continuous.
Discontinuities in the hazard rate could result in the equations for the control limits (\eqref{eq:AgeBasedHazardBound} and \eqref{eq:MmfmHazardBoundsShort}) not having solutions.
However, as long as the hazard rate is increasing, the optimal control limit would simply be the infimum of control limits that exceed the hazard bound.
If the hazard rate would not be monotonously increasing, then the equations for the control limit might have multiple solutions and the policy iteration might get stuck in a local optimum.

It was also assumed that the transitions in the Markovian environment occur independent of the condition (age or fluid level) of the asset.
In practice, this assumption might fail as the degradation of the asset might be visible in its behavior.
\cite{Scheinhardt1998} discusses models where the transitions in the Markovian environment do depend on the fluid level.

The assumption of constant known fluid jump sizes might also be unrealistic.
This assumption was mainly made to simplify the problem.
The same holds for the assumption of exponential transition times.

\section{Robustness}
Small errors in the problem parameters could be caused by changes in the environment.
For example, if the cost of maintenance would turn out to be larger than the cost $c$ that was used during the computation of the policy, this would result in the real total discounted cost being larger than calculated.
Furthermore, the chosen control limit would be too high. 

Most of the effects varying parameters are covered in sections \ref{section:AgeBasedStructuralProperties}, \ref{section:SimpleStructuralProperties} and \ref{section:MmfmStructuralProperties} for the age-based problem, the simple fluid problem and the MMFM problem respectively.


\bibliography{Sections/bibliography}

\begin{appendices}
	\chapter{List of symbols and notation}\label{AppendixSymbolsAndNotation}
The symbols and notation that are used in chapters \ref{chapter:AgeBased}, \ref{chapter:SimpleFluid} and \ref{chapter:Mmfm} are listed in the table below.
	\begin{tabularx}{\linewidth}{l|L}\label{table:Symbols}
		Symbol        & Meaning         \\
		\hline                       
		$X$			& State space of the MDP. \\
		$X(t)$ & State of the process at time $t$ \\
		$\omega_k$ & Random variable for the evolution of the stochastic process at time $t_k$.\\   
		$x_{BREAK}$ & State for when the asset is broken.           \\
		$x_{NEW}$ & State for when the asset is new.\\   
		$U(x)$& Set of available actions in state $x$.\\
		$a_W$& Action corresponding to doing nothing.\\
		$a_R$& Action corresponding to repairing (performing maintenance). \\
		$g(x,u)$    & Cost of performing action $u$ in state $x\in X$.\\
		$c$& Cost for maintenance.\\
		$a$& Additional cost for corrective maintenance.\\
		$\alpha_\delta$ & Discount over a period $\delta$. In this thesis, we use $\alpha_\delta=e^{-\beta \delta}$ for discount coefficient $\beta>0$.\\       
		$\mu$ & Control limit. $\mu^*$ denotes the optimal control limit.\\
		$\pi$& The policy for the MMFM-problem. $\pi=\{\mu_1,...,\mu_N\}$ where $\mu_i$ denotes the control limit in CTMC-state $s_i$. $\pi^*$ denotes the optimal policy.\\
	    $x\wedge y$   & The minimum of $x$ and $y$.          \\       
        $x\vee y$     & The maximum of $x$ and $y$.\\
        $Q_0$ & Distribution of the initial fitness (lifetime or fluid level) of the asset.\\
        $Q(t)$& Fluid level at time $t$.\\
        $L_0(t)$& Amount of used initial fluid at time $t$.\\
        $L_c(t)$& Amount of fluid inside the buffer at time $t$.\\
        $F$ & CDF of $Q_0$.\\
        $F_{X(t)}$ & CDF of $Q(t)$\\
        $\bar F(x)$& Reliability function corresponding to $F$. Furthermore $\bar F(x;y)=\frac{\bar F(x)}{\bar F(y)}$.\\
        $h$& Hazard rate of $Q_0$.\\                       
		$V_\delta(x,\mu)$ & Expected total discounted cost at state $x$ with time-step $\delta$, using control limit $\mu$. $\delta$ is omitted than for the continuous MDP. For the MMFM we write $V_\delta(x,\pi)$ with policy $\pi$.            \\
		$\lambda_{ij}$& Transition rate from state $s_i$ to $s_j$. Also $\lambda_i=-\sum_{j\neq i}\lambda_{ij}$. $\lambda$ is used for the simple fluid model.\\
		$J_{ij}$& Jump quantity when transitioning from $s_i$ to $s_j$. $J$ for the simple fluid model.\\
		$N$& Number of CTMC-states for the MMFM problem.\\
		$T_t(q)$&Random variable denoting the time until the fluid level has decreased by $q$, i.e. $\min\{\tau-t>0|Q(\tau)=Q(t)-q\}$.\\
		$N_t(q)$&The number of jumps that occur during the time that the fluid decreases by $q$.\\
		$D_{ij}^t(q,\pi,l)$&Expected value of the discount factor over the time period that the process reaches state $s_j$ while the fluid level decreases by $q$ without a control limit from $\pi$ being encountered, given that at time $t$ the process was in $X(t)= (i,l,0)$. For the simple fluid problem, $D(q)$ denotes the discount over the time that the fluid decreases by $q$.\\
		$\Lambda^D$&The generator matrix for $D_{ij}$.\\
	\end{tabularx}
%
 	\chapter{Proof of properties of optimal age-based control limits}\label{AppendixAgeBasedControlLimit}
Without the assumption of increasing hazard rates, it can also be proven that if an optimal control limit $\mu^*$ exists, $\mu^*$ must satisfy \eqref{eq:AgeBasedHazardBound} and the hazard rate must be increasing at $\mu^*$.
This can be proven using the Bellman equations.
For this, we will briefly return to discretized time:
If the control limit equals $\mu^*$, then one time interval earlier, $c+V_\delta(\delta,\mu^*)\geq V_\delta(\mu^*-\delta,\mu^*)$ holds since else the control limit would be smaller than $\mu^*$.
Using \eqref{eq:gatheredDelta}, we get

\[\begin{split}
&c+V_\delta(0^+,\mu^*)\\
\geq& V_\delta(\mu^*-\delta,\mu^*)\\
=&\delta h(\mu^*)(c+a+ V_\delta(0^+,\mu^*))+(1-\delta\beta-\delta h(\mu^*)) V_\delta(\mu^*,\mu^*)+o(\delta^2).
\end{split}
\]
Since we repair at age $\mu^*$, $V_\delta(\mu^*,\mu^*)=V_\delta(0^+,\mu^*)+c$ and we can write
$$
c+V_\delta(0^+,\mu^*)\geq \delta h(\mu^*)(c+a+ V_\delta(0^+))+(1-\delta\beta-\delta h(\mu^*)) (c+V_\delta(0^+))+o(\delta^2).
$$
Which simplifies to
$$
0\geq ah(\mu^*)-\beta (c+V_\delta(0^+,\mu^*))+o(\delta^2)
$$
and can be rewritten as
$$
h(\mu^*)\leq \beta\frac{c+V_\delta(0^+,\mu^*)}{a} +o(\delta^2)\rightarrow\beta\frac{c+V_\delta(0^+,\mu^*)}{a}.
$$
If instead of looking a decision stage before the control limit, we now look at the decision stage where the control limit $\mu^*$ is reached, the Bellman equations yield
$$
c+V_\delta(0^+,\mu^*)\leq V_\delta(\mu^*-\delta,\mu^*)=\delta h(\mu^*)(c+a+ V_\delta(0^+,\mu^*))+(1-\delta\beta-\delta h(\mu^*)) V_\delta(\mu^*+\delta)+o(\delta^2)
$$
And using the same steps, we get
$$
h(\mu^*)\geq \beta\frac{c+V_\delta(0^+,\mu^*)}{a} +o(\delta^2)\rightarrow\beta\frac{c+V_\delta(0^+,\mu^*)}{a}
$$
such that the result is proven when $\delta$ approaches zero.
From the above, it also follows that the hazard rate is increasing at the control limit.
This can be summarized in the following theorem:

\begin{theorem}
	Whenever the optimal policy is to repair when the age reaches control limit $\mu^*<\infty$, it holds that the hazard rate is increasing at $\mu^*$ and
	\[h(\mu^*)=\beta\frac{c+V(0^+,\mu^*)}{a}.\]
\end{theorem}

\begin{corollary}
	If the hazard rate of the lifetime $Q_0$ of the asset is monotonously decreasing, preventive repair will never be the optimal choice.
\end{corollary} \chapter{Total discounted costs for various problem parameters and policies?}\label{AppendixComputationsTable}
\section{Age-based problem}
Below optimal control limits and corresponding total discounted costs of the age-based maintenance problem are listed for a few parameters.
These control limits and total discounted costs were obtained using the iteration method presented in this thesis.
The scale $20/\pi$ for the Weibull distribution was chosen so that the mean lifetime is the same for both distributions.

	\begin{tabularx}{\linewidth}{llllll}\label{table:AgeComputations}
		$c$        & $a$ & $\beta$ & Lifetime & $\mu^*$ & $V(0^+,\mu^*)$        \\
		\hline                       
		$1.000$ & $100.000$ & $1.000$ & Weibull$(20/\pi,2)$ & $1.388$ & $1.181$ \\ 
		$1.000$ & $100.000$ & $1.000$ & Gamma$(2,5)$ & $2.349$ & $0.233$ \\ 
		$1.000$ & $5.000$ & $1.000$ & Weibull$(20/\pi,2)$ & $13.897$ & $0.091$ \\ 
		$1.000$ & $5.000$ & $1.000$ & Gamma$(2,5)$ & $10.298$ & $0.025$ \\ 
		$1.000$ & $100.000$ & $0.500$ & Weibull$(20/\pi,2)$ & $1.246$ & $2.916$ \\ 
		$1.000$ & $100.000$ & $0.500$ & Gamma$(2,5)$ & $2.123$ & $0.838$ \\ 
		$1.000$ & $100.000$ & $2.000$ & Weibull$(20/\pi,2)$ & $1.760$ & $0.383$ \\ 
		$1.000$ & $100.000$ & $2.000$ & Gamma$(2,5)$ & $2.831$ & $0.030$ \\ 
	\end{tabularx}

\section{Simple fluid problem}
Below optimal control limits and corresponding total discounted costs of the simple fluid model maintenance problem are listed for a few parameters.
These control limits and total discounted costs were obtained using the iteration method presented in this thesis.
\begin{tabularx}{\linewidth}{llllllll}\label{table:SimpleFluidComputations}
	$c$        & $a$ & $\beta$ & Initial fluid & $\lambda$ & $J$ & $\mu^*$ & $V(0^+,\mu^*)$        \\
	\hline    
	  $1$ & $100$ & $1$ & Weibull$(20/\pi,2)$ & $1.000$ & $0.500$ & $1.572$ & $0.608$ \\ 
	  $1$ & $100$ & $1$ & Gamma$(2,5)$ & $1.000$ & $0.500$ & $2.607$ & $0.075$ \\ 
	  $1$ & $5$ & $1$ & Weibull$(20/\pi,2)$ & $1.000$ & $0.500$ & $54.762$ & $0.039$ \\ 
	  $1$ & $5$ & $1$ & Gamma$(2,5)$ & $1.000$ & $0.500$ & $\infty$ & $0.005$ \\ 
	  $1$ & $100$ & $0.5$ & Weibull$(20/\pi,2)$ & $1.000$ & $0.500$ & $1.341$ & $1.495$ \\ 
	  $1$ & $100$ & $0.5$ & Gamma$(2,5)$ & $1.000$ & $0.500$ & $2.276$ & $0.335$ \\ 
	  $1$ & $100$ & $2.0$ & Weibull$(20/\pi,2)$ & $1.000$ & $0.500$ & $2.114$ & $0.209$ \\ 
	  $1$ & $100$ & $2.0$ & Gamma$(2,5)$ & $1.000$ & $0.500$ & $3.176$ & $0.009$ \\ 
	  $1$ & $100$ & $1.0$ & Weibull$(20/\pi,2)$ & $0.500$ & $1.000$ & $1.513$ & $0.730$ \\ 
	  $1$ & $100$ & $1.0$ & Gamma$(2,5)$ & $0.500$ & $1.000$ & $2.528$ & $0.104$ \\ 
	  $1$ & $5$ & $1.0$ & Weibull$(20/\pi,2)$ & $0.500$ & $1.000$ & $18.346$ & $0.049$ \\ 
	  $1$ & $5$ & $1.0$ & Gamma$(2,5)$ & $0.500$ & $1.000$ & $\infty$ & $0.008$ \\ 
	  $1$ & $100$ & $0.5$ & Weibull$(20/\pi,2)$ & $0.500$ & $1.000$ & $1.319$ & $1.698$ \\ 
	  $1$ & $100$ & $0.5$ & Gamma$(2,5)$ & $0.500$ & $1.000$ & $2.241$ & $0.403$ \\ 
	  $1$ & $100$ & $2.0$ & Weibull$(20/\pi,2)$ & $0.500$ & $1.000$ & $1.970$ & $0.259$ \\ 
	  $1$ & $100$ & $2.0$ & Gamma$(2,5)$ & $0.500$ & $1.000$ & $3.045$ & $0.014$ \\ 
\end{tabularx}
\section{Markov Modulated fluid model}
For the following two MMFMs we calculated the total discounted costs of the preventive maintenance problem.
In addition to calculating the exact solution via the iteration method presented in the thesis, we also computed the policies for the heuristics discussed in section \ref{section:MmfmHeuristics}.
We denote the uniform control limit by $\mu_u$ and the control limits that resulted from assuming no jumps will occur before the next failure by $\mu_i'$, with corresponding total discounted costs $V_u(\mu_u)$ and $V(0^+,\pi')$ respectively.

\begin{landscape}
	
	\begin{figure}
		\centering
		\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=2.7cm,
		thick,main node/.style={circle,draw,font=\sffamily\Large\bfseries, scale=0.65}, edge node/.style={scale=0.65},scale=0.65]
		
		\node[main node] (1) {$s_1:1$};
		\node[main node] (2) [right of=1] {$s_2:2$};
		\node[main node] (3) [below right of=1] {$s_3:3$};
		
		\path[every node/.style={font=\sffamily\small}]
		(1) edge node {$1:0$} (2)
		(2) edge node {$1:0$} (3)
		(3) edge node {$1:5$} (1);
		\end{tikzpicture}
		\caption{Depiction of the MMFM corresponding to table \ref{table:MmfmComputations1}.}
		\label{figure:AppendixMmfm1}
	\end{figure}

	\begin{table}[H]
		\centering
		\begin{tabularx}{\linewidth}{llllllllllllll}
			$c$& $a$ & $\beta$ & Initial fluid & $\mu_1^*$ & $\mu_2^*$ & $\mu_3^*$ & $V(0^+,\pi^*)$ & $\mu_u$ & $V_u(\mu_u)$ &$\mu_1'$ & $\mu_2'$ & $\mu_3'$ &$V(0^+,\pi')$  \\
			\hline    
			$1$ & $100$ & $1.0$ & Weibull$(20/\pi,2)$ & $1.839$ & $0.578$ & $1.144$ & $1.889$ & $1.749$ & $1.805$ & $1.657$ & $0.829$ & $0.552$ & $1.603$ \\ 
			$1$ & $100$ & $1.0$ & Gamma$(2,5)$ & $2.920$ & $1.964$ & $2.451$ & $1.235$ & $2.514$ & $0.494$ & $2.586$ & $2.032$ & $1.780$ & $0.614$ \\ 
			$1$ & $5$ & $1.0$ & Weibull$(20/\pi,2)$ & $19.966$ & $5.928$ & $12.424$ & $0.784$ & $15.226$ & $0.196$ & $18.585$ & $9.292$ & $6.195$ & $0.460$ \\ 
			$1$ & $5$ & $1.0$ & Gamma$(2,5)$ & $22.894$ & $6.948$ & $10.746$ & $0.719$ & $11.069$ & $0.096$ & $14.748$ & $7.246$ & $5.570$ & $0.365$ \\ 
			$1$ & $100$ & $0.5$ & Weibull$(20/\pi,2)$ & $1.559$ & $0.167$ & $1.207$ & $3.899$ & $1.332$ & $4.028$ & $1.485$ & $0.743$ & $0.495$ & $3.667$ \\ 
			$1$ & $100$ & $0.5$ & Gamma$(2,5)$ & $2.616$ & $1.365$ & $2.386$ & $2.334$ & $2.284$ & $1.316$ & $2.380$ & $1.883$ & $1.654$ & $1.560$ \\ 
			$1$ & $100$ & $2.0$ & Weibull$(20/\pi,2)$ & $2.091$ & $1.046$ & $1.036$ & $0.642$ & $2.142$ & $0.683$ & $2.061$ & $1.030$ & $0.687$ & $0.619$ \\ 
			$1$ & $100$ & $2.0$ & Gamma$(2,5)$ & $3.010$ & $2.333$ & $2.326$ & $0.210$ & $2.929$ & $0.126$ & $3.000$ & $2.326$ & $2.026$ & $0.199$ \\ 
			$1$ & $100$ & $1.0$ & Weibull$(20/\pi,2)$ & $2.167$ & $1.249$ & $0.467$ & $0.463$ & $2.477$ & $0.674$ & $0.962$ & $0.481$ & $0.321$ & $0.511$ \\ 
			$1$ & $100$ & $1.0$ & Gamma$(2,5)$ & $3.198$ & $2.590$ & $1.851$ & $0.211$ & $3.147$ & $0.164$ & $2.329$ & $1.846$ & $1.622$ & $0.204$ \\ 
			$1$ & $5$ & $1.0$ & Weibull$(20/\pi,2)$ & $0.000$ & $0.000$ & $0.000$ & $19.000$ & $31.477$ & $0.063$ & $15.266$ & $7.633$ & $5.089$ & $0.199$ \\ 
			$1$ & $5$ & $1.0$ & Gamma$(2,5)$ & $0.000$ & $0.000$ & $0.000$ & $19.000$ & $0.000$ & $19.000$ & $11.937$ & $6.503$ & $5.105$ & $0.169$ \\ 
			$1$ & $100$ & $0.5$ & Weibull$(20/\pi,2)$ & $1.881$ & $1.141$ & $0.362$ & $0.924$ & $2.514$ & $1.677$ & $0.688$ & $0.344$ & $0.229$ & $1.161$ \\ 
			$1$ & $100$ & $0.5$ & Gamma$(2,5)$ & $2.929$ & $2.433$ & $1.667$ & $0.469$ & $2.936$ & $0.478$ & $1.967$ & $1.576$ & $1.392$ & $0.462$ \\ 
			$1$ & $100$ & $2.0$ & Weibull$(20/\pi,2)$ & $2.760$ & $1.491$ & $0.665$ & $0.201$ & $2.821$ & $0.228$ & $1.527$ & $0.764$ & $0.509$ & $0.199$ \\ 
			$1$ & $100$ & $2.0$ & Gamma$(2,5)$ & $3.654$ & $2.850$ & $2.135$ & $0.076$ & $3.589$ & $0.032$ & $2.876$ & $2.239$ & $1.953$ & $0.074$ \\ 
		\end{tabularx}
		\caption{Computations corresponding to the MMFM of figure \ref{figure:AppendixMmfm1}.}
		\label{table:MmfmComputations1}
	\end{table}
	\subsection{MMFM 2}
	
	\begin{figure}
		\centering
		\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=2.7cm,
		thick,main node/.style={circle,draw,font=\sffamily\Large\bfseries, scale=0.65}, edge node/.style={scale=0.65},scale=0.65]
		
		\node[main node] (1) {$s_1:1$};
		\node[main node] (2) [right of=1] {$s_2:1$};
		\node[main node] (3) [below right of=1] {$s_3:3$};
		
		\path[every node/.style={font=\sffamily\small}]
		(2) edge node {$2:1$} (1)
		(1) edge node {$2:1$} (2)
		(2) edge node {$1:0$} (3)
		(3) edge node {$1:0$} (1);
		\end{tikzpicture}
		\caption{Depiction of the MMFM corresponding to table \ref{table:MmfmComputations2}.}
		\label{figure:AppendixMmfm2}
	\end{figure}
\end{landscape} \chapter{Matlab routines}
The relevant Matlab routines can be found in
\href{https://github.com/MartijnGosgens/preventive-maintenance.git}{this git repository}.
\end{appendices}
\end{document}