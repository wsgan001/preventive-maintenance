\section{Problem formulation and definition}
In this section, we extend the definition of age-based maintenance from section \ref{section:AgeBasedDefinition}.
First we define the underlying stochastic process of the state of the machine deteriorating over time and instantaneously increasing at the occurrence of jumps.
After that, we define a Markov decision process similarly to section \ref{section:AgeBasedDefinition}.

\subsection{Stochastic machine breakdown}
We define the random process $Q(t)$ as the fluid level at age $t$.
Initially, the fluid level is given by $Q(0)=Q_0\sim F$.
Then over time this level decreases at a constant rate of $1$.
The jumps occur according to a Poisson process with rate $\lambda$, i.e. the time interval between two consecutive jumps is exponentially distributed with rate $\lambda$.
Hence, let $P_\lambda(t)$ be a Poisson distributed random variable with rate $\lambda t$.
Then the fluid level at time $t$ is given by 
\[
Q(t)\stackrel d=Q_0+P_\lambda(t)J-t.
\]
Where $\stackrel d=$ denotes that the random variables on the left and right have the same distribution.
This process has the property that
\[
Q(t_1+t_2)\stackrel d= Q_0+P_\lambda(t_1)J+P_\lambda(t_2)J-t_1-t_2\stackrel d= Q(t_1)+P_\lambda(t_2)J-t_2.
\]
The machine breaks when the fluid level reaches $0$, i.e. at the time $t^*$ given by
\[
t^*=\inf\{t|Q(t)=0\}.
\]
When the machine is repaired, it starts with an age of zero again.

To derive the distribution of $Q(t)$ for a certain $t$ from the observed jumps, it seems we need to keep track of the exact times at which these jumps occurred.
This would be a very inconvenient format of the state of the machine.
Luckily, this information can be condensed into a simpler state description.
First, we will illustrate this with the following example:
\begin{example}
	If the first jump of the process would have occur at some time $t$, we know that:
	\begin{enumerate}
		\item At time $t$, $Q(t)\geq J$.
		Hence, we have a lower bound on the current fluid level.
		\item Initially, the fluid level was at least $t$, i.e. $Q_0\geq t$.
		Hence, we have a certain lower bound on the initial fluid level.
	\end{enumerate}
	If now, after some time $\tau<J$ another jump occurs, we know that:
	\begin{enumerate}
		\item At time $t+\tau$, $Q(t)\geq 2J-\tau$.
		The passage of time has hence decreased our lower bound of the current fluid level by $\tau$ and the jump has increased this bound by $J$.
		\item Our lower bound of the initial fluid level has remained unchanged.
		When our lower bound of the current fluid level is positive, our lower bound of the initial fluid level remains the same.
	\end{enumerate}
\end{example}
This suggests that the only two parameters we need to keep track of, are the lower bound of the current fluid level $L_c(t)$ and the lower bound of the initial fluid level $L_0(t)$.
We will refer to this $L_0$ as the used initial fluid.
The machine cannot break if 
\[L_c(t)>0,\]
since we know for certain that the there is still remaining fluid.
We will refer to this quantity $L_c(t)$ as the fluid buffer.
The machine breaks whenever
\[L_0(t)=Q_0,\]
i.e. when the initial fluid level is drained.
Hence, we maintain the two quantities $L_c(t)$ and $L_0(t)$ as the description of the state the machine is in.
\[
X(t)=(L_0(t),L_c(t))
\]
Initially
\[
X(0)=x_{NEW}:=(0,0).
\]
These two quantities evolve in the following way:
\begin{itemize}
	\item When $X(t)=(l_0,l_c)$ and a jump occurs $L_c$ increases by $J$.
	Hence, the state changes in the following way
	\begin{equation}\label{eq:SimpleJumpEvolution}
	(l_0,l_c)\stackrel{J}{\mapsto} (l_0,l_c+J).
	\end{equation}
	\item When $X(t)=(l_0,l_c)$ and a time period of length $\tau$ passes without a jump occurring, the fluid level decreases by $\tau$.
	If $l_c>0$, $L_c$ decreases but it cannot get lower than $0$ so it decreases by $\min\{l_c,\tau\}$.
	When $l_c=0$, $L_0$ increases by $\tau$.
	If $0<l_0<\tau$ then first a time of $l_0$ passes so that $L_c(t+l_0)=0$ and then the remaining time passes so that $l_0$ increases by $\tau-l_0$.
	This can be summarized in the following way
	\begin{equation}\label{eq:SimpleAgeEvolution}
	(l_0,l_c)\stackrel\tau\mapsto (l_0+\tau-\min\{l_c,\tau\},l_c-\min\{l_c,\tau\}).
	\end{equation}
\end{itemize}
\begin{theorem}\label{theorem:SimpleCurrentLevel}
	Using the $L_c(t)$ and the $L_0(t)$ as defined above.
	The current fluid level is given by
	\begin{equation}\label{eq:SimpleCurrentLevel}
	Q(t)=L_c(t)+Q_0-L_0(t).
	\end{equation}
	\begin{proof}
		At the start of the process, $X(0)=(0,0)$ so that
		\[
		Q(0)=0+Q_0-0=Q_0.
		\]
		When a jump occurs, we know that $Q(t)$ increases by $J$.
		By \eqref{eq:SimpleJumpEvolution}, $L_c$ also increases by $J$ such that jumps preserve \eqref{eq:SimpleCurrentLevel}.
		When a time $\tau$ passes without a jump occurring, $Q(t)$ decreases by $\tau$.
		From \eqref{eq:SimpleAgeEvolution}, we see that $L_c-L_0$ also decreases by $\tau$.
		This completes the proof.
		
	\end{proof}
\end{theorem}
\begin{corollary}
	Theorem \ref{theorem:SimpleCurrentLevel} implies that for $X(t)=x=(L_0(t),L_c(t))$, the distribution of $Q(t)$ is given by
	\begin{equation}\label{eq:SimpleCurrentDistribution}
	\begin{split}
	F_x(q)&:=\mathbb{P}(Q(t)<q)\\
	&=\mathbb{P}(L_c(t)+Q_0-L_0(t)<q|Q_0>L_0(t))\\
	&=\mathbb{P}(Q_0<q+L_0(t)-L_c(t)|Q_0>L_0(t))\\
	&=\frac{F(q+L_0(t)-L_c(t))-F(L_0(t))}{\bar{F}(L_0(t))}.\\
	\end{split}
	\end{equation}
\end{corollary}
\begin{remark}
	Note that we can write $L_0(t)$ in the following way:
	\[
	L_0(t)=\max\limits_{0\leq\tau\leq t} Q_0-Q(\tau).
	\]
	As by \eqref{eq:SimpleCurrentLevel}, 
	\[
	L_0(t)-L_c(t)=Q_0-Q(t),
	\]
	and $L_0$ cannot decrease and only increases whenever $L_c=0$.
\end{remark}
\begin{corollary}
	From the previous remark, it can also be seen easily that the machine will fail when the used initial fluid equals the initial fluid level as
	\[
	L_0(t)=Q_0\Rightarrow Q(t)=0.
	\]
\end{corollary}

Now, for $x_k=X(t_k)$, we describe the random disturbances $\omega_k=\omega_k(x_k)$ of the Markov decision process in the following way
\[
\omega_k(x_k):=\begin{cases}
\Omega_{SURVIVE}&\ \begin{split}&\text{if the machine does not break and no jump occurs}\\
&\text{in the $k$'th time interval.}\end{split}\\
\Omega_{BREAK}&\ \text{if the machine breaks in the $k$'th time interval.}\\
\Omega_{JUMP}&\ \begin{split}&\text{if the machine does not break and a jump occurs}\\
&\text{in the $k$'th time interval.}\end{split}\\
\end{cases}
\]
Assuming only one jump can occur in a time interval and letting $x_k=X(t_k)=(l_0,l_c)$, we get the following probabilities:
\[
\begin{split}
\mathbb{P}(\omega_k(x_k)=\Omega_{SURVIVE})&=\begin{cases}
e^{-\lambda \delta}=1-\delta\lambda+o(\delta^2)&\text{ if }l_c>0,\\
\begin{split}
e^{-\lambda \delta} & \bar{F}_{x_k}(l_0+\delta)\\
=1&-\delta h(l_c)-\delta\lambda+o(\delta^2)
\end{split}&\text{ if }l_c=0.\\
\end{cases}\\
\mathbb{P}(\omega_k(x_k)=\Omega_{BREAK})&=\begin{cases}
0&\text{ if }l_c>0,\\
\begin{split}
e^{-\lambda \delta}F_{x_k}&(l_0+\delta)\\
=&\delta h(l_c)+o(\delta^2)
\end{split}&\text{ if }l_c=0.\\
\end{cases}\\
\mathbb{P}(\omega_k(x_k)=\Omega_{JUMP})&=\begin{cases}
1-e^{-\lambda \delta} & \text{ if }l_c>0,\\
\begin{split}
1-&e^{-\lambda \delta}\\
=&\delta\lambda+o(\delta^2)
\end{split}&\text{ if }l_c=0.\\
\end{cases}
\end{split}
\]

\subsection{Control actions}
We introduce a state $x_{BREAK}$ for when the machine is broken.
and in this state the only available action is $a_R$.
In all other states, both actions $a_W$ and $a_R$ may be chosen.
The definitions of these actions remains the same as in the definition of the age-based maintenance problem.

\subsection{State evolution}
Initially $x_{NEW}=(0,0)$.
The state of the Markov decision process now evolves in the following way:
\[
x_{k+1}=f(x_k, u_k, \omega_k):=\begin{cases}
x_{NEW}&\ \text{if }u_k=a_R,\\
\begin{split}(l_0+\delta-\min\{l_c,\delta\}&,\\l_c-\min\{l_c,\delta\}&)\end{split}&\ \text{if }u_k=a_W\text{ and }\omega_k=\Omega_{SURVIVE},\\
(l_0,l_c+J-\delta)&\ \text{if }u_k=a_W\text{ and }\omega_k=\Omega_{JUMP},\\
x_{BREAK}&\ \text{if }u_k=a_W\text{ and }\omega_k=\Omega_{BREAK}.\\
\end{cases}
\]
Here we assumed that jumps occur at the start of time intervals.
Again, we use the definition of the random variable $S(x_k):=f(x_k,a_W,\omega_k(x_k))$ as the state after $x_k$.

\subsection{Costs and discounting}
The costs and discounting remain the same as in the age-based maintenance problem.

\subsection{Optimal policy and Bellman equations}
We want to find a stationary policy $\mu:X\rightarrow \{a_W,a_R\}$ that chooses the action $u_k=\mu(x_k)$ that minimizes the expected total discounted cost $V_\delta(x_k,\mu)$ for each state.
Similarly as in the definition of age-based maintenance, $V_\delta(x_k,\mu)$ is given by
\[V_\delta(x_k,\mu)=g(x_k,\mu(x_k))+\alpha_\delta \mathbb{E}[V_\delta(S(x_k),\mu)].\]
The Bellman equations for the optimal cost $V_\delta(x_k,\mu^*)$ read
\begin{equation}\label{eq:SimpleFluidBellman}
V_\delta(x_k,\mu^*)=\begin{cases}
c+a+\alpha_\delta V_\delta(x_{NEW},\mu^*),&\text{ if }x_k=x_{BREAK},\\
\min\left\{\begin{split}&c+\alpha_\delta V_\delta(x_{NEW},\mu^*),\\&\alpha_\delta \mathbb{E}[V_\delta(S(x_k),\mu^*)]\end{split}\right\},&\text{else.}\\
\end{cases}
\end{equation}
$\mu$ is optimal if $V_\delta(x,\mu)=V_\delta(x,\mu^*)$ for all $x$.
$\mathbb{E}[V_\delta(S(x_k),\mu^*)]$ when $x_k\neq x_{BREAK}$ is given by 
\begin{equation}\label{eq:SimpleFluidNextState}
\begin{split}
&\mathbb{E}[V_\delta(S(l_0,l_c),\mu^*)]\\
&=\begin{cases}
\begin{split}
&(1-e^{-\lambda \delta})V_\delta(l_0,l_c+J-\delta,\mu^*)\\
&+e^{-\lambda \delta}V_\delta(l_0,l_c-\delta,\mu^*),
\end{split}&\ \text{If $l_c=0$,}\\
\begin{split}
&e^{-\lambda \delta} \bar{F}_{t_k}(l_0+\delta)V_\delta(l_0+\delta,0,\mu^*)\\
&+ e^{-\lambda \delta}F_{t_k}(l_0+\delta)V_\delta(x_{BREAK},\mu^*)\\
&+(1-e^{-\lambda \delta})V_\delta(l_0,J-\delta,\mu^*),
\end{split}&\ \text{If $l_c>0$.}\\
\end{cases}\\
&=\begin{cases}
\begin{split}
&\lambda\delta V_\delta(l_0,l_c+J-\delta,\mu^*)\\
&+(1-\lambda \delta)V_\delta(l_0,l_c-\delta,\mu^*)+o(\delta^2),
\end{split}
&\ \text{If $l_c=0$,}\\
\begin{split}
&(1-\lambda \delta-\delta h(l_0))V_\delta(l_0+\delta,0,\mu^*)\\
&+ \delta h(l_0)V_\delta(x_{BREAK},\mu^*)\\
&+\lambda \delta V_\delta(l_0,J-\delta,\mu^*)+o(\delta^2),
\end{split}&\ \text{If $l_c>0$.}\\
\end{cases}
\end{split}
\end{equation}

\subsection{Alternative models}
The occurrence of fluid jumps can be modeled in many different ways.
We will briefly mention some alternatives to design choices that were made in the definition above.
\subsubsection{Decisions at jumps only}
We could also model the problem such that the choice to repair the machine can only be made the instant after a jump occurs.
This might be more realistic as the jump could be caused by some mechanic performing some partial maintenance and a mechanic might be needed to completely repair the machine.

\subsubsection{Jumps not according to a Poisson process}
The time in between the jumps could also have another distribution than the exponential distribution.
This would, however, make the problem significantly more complicated as the memorylessness simplifies the problem slightly.