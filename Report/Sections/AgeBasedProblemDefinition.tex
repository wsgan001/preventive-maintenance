\section{Problem formulation and definition}\label{section:AgeBasedDefinition}
In this section, the problem of choosing when to repair the asset is defined as a Markov decision process.
Calendar time is discretized in steps of size $\delta$, i.e. the $k$'th decision epoch is at time $t_k=k\delta$.
We refer to the interval $(k\delta,(k+1)\delta]$ as the $k$'th time interval.
At epoch $k\in\mathbb{N}\cup\{0\}$, we denote the state of the asset by $x_k\in X=\mathbb{N}_0$ and initially $x_0=1$.
When $x_k=x$, this means that after the $k$'th time interval, the asset has age $x\delta$.

The lifetime of the asset has a distribution function $F$.
We denote the reliability function by $\bar F(x):=1-F(x)$ and the conditional reliability function by $\bar F(x;y)=\frac{\bar F(x)}{\bar F(y)}$.
We assume that this distribution function is continuously differentiable so that the probability density function by $f$ and the hazard rate 
\[
h(x)=\frac{f(x)}{\bar F(x)}
\] 
are both continuous.

\subsection{Degradation model}
To model the degradation of the asset, we introduce random variables $\omega_k:=\omega_k(x_k)$ at decision epoch $k$ which only depend on $x_k$.
$$
\omega_k(x_k):=\begin{cases}
1,&\text{if the asset will reach age }\ \delta x_{k}\text{ given}\\
&\text{that it reached age}\ \delta(x_k-1)\ \text{ at time } t_k \\
0,&\text{otherwise}.
\end{cases}
$$
If the lifetimes of the asset are i.i.d. random variables with distribution $F$ then for $x>0$
$$
\mathbb{P}(\omega_k(x_k)=1)=\frac{1-F(\delta x_k)}{1-F(\delta (x_k-1))}.
$$
%and
%\[
%\mathbb{P}(\omega_k(x_k)=0)=\frac{F(\delta x_k)-F(\delta (x_k-1))}{1-F(\delta (x_k-1))}=\delta h(\delta x_k)+o(\delta^2)
%\]
%for small $\delta$.
%This hazard rate is assumed to be increasing.
%In the rest of the thesis we assume that the lifetime of the asset has an increasing hazard rate so that $\mathbb{P}(\omega_k(x)=1)$ is decreasing in $x$.

\subsection{Control actions}
At the $k$'th decision epoch, we shall choose an action $u_k$ from the action set $U(x_k)$.
Where
$$
U(x_k):=\begin{cases}
\{a_W,a_R\},&\text{if}\ x_k>0 \\
\{a_R\},&\text{if}\ x_k=0.
\end{cases}
$$
These actions are
\begin{itemize}
	\item $a_R$:
	Repair (or replace) the asset.
	\item $a_W$:
	Do nothing.
\end{itemize}

\subsection{State evolution}
During a time interval, a few things can happen:
\begin{itemize}
	\item If the asset is repaired, its age will be $\delta$ at the next stage.
	\item If the asset fails, its age will be $0$ at the next stage.
	\item If the asset does not fail and no repair is done, the age of the asset will increase by $\delta$.
\end{itemize}
Hence, the state evolves in the following way
$$
x_{k+1}=f(x_k,u_k,\omega_k):=\begin{cases}
1,&\text{if}\ u_k=a_R \\
0,&\text{if}\ u_k=a_W\ \text{and}\ \omega_k=0 \\
x_k+1,&\text{if}\ u_k=a_W\ \text{and}\ \omega_k=1.
\end{cases}
$$
For convenience, we define the random variable $S(x_k):=f(x_k,a_W,\omega_k(x_k))$ to denote the age of the asset one time interval after it was $x_k$.
Note that in the above definition, repairing the asset takes exactly one time interval.

\subsection{Costs and discounting}
Preventively repairing the asset has a cost $c>0$.
When the asset needs to be repaired correctively, an additional cost $a>0$ needs to be paid.
Hence, when the process is in state $x_k$ and the action $u_k$ is chosen, the following cost is incurred
$$
g(x_k,a_k):=\begin{cases}
c+a,&\text{if}\ x_k=0 \\
c,&\text{if}\ x_k>0\ \text{and}\ u_k=a_R \\
0,&\text{else}.
\end{cases}
$$
Furthermore, a discount $\alpha_\delta$ is introduced such that costs $n$ decision stages in the future are discounted by $\alpha_\delta^n$.
In the rest of the thesis, we will use a discount factor
$$
a_\delta=e^{-\beta\delta}
$$
for some discount rate $\beta>0$.
We consider the expected total discounted cost from decision epoch $k$ on
$$
V_\delta(x_k;k)=\sum\limits_{m=k}^\infty \alpha_\delta^{m-k}g(x_m,u_m).
$$


\subsection{Optimal stationary policy and the Bellman equations}
As the problem as defined above is a Markov decision process with $g$ independent of the decision epoch, there exists an optimal stationary policy \cite{Puterman2008}.
Hence, we want to find a stationary policy $\mu:X\rightarrow \{a_W,a_R\}$ that chooses the action $u_k=\mu(x_k)$ that minimizes the expected total discounted cost $V_\delta(x_0,\mu)$.
For a policy $\mu$, $V_\delta(x_k,\mu)$ is given by
$$
V_\delta(x_k,\mu)=g(x_k,\mu(x_k))+\alpha_\delta \mathbb{E}[V_\delta(f(x_k,\mu(x_k),\omega_k(x_k)),\mu)].
$$
The Bellman equations for the optimal cost $V^*_\delta$ read
\begin{equation}\label{eq:AgeBasedBellman}
V^*_\delta(x_k)=\begin{cases}
\min\{c+\alpha_\delta V^*_\delta(1),\alpha_\delta \mathbb{E}[V^*_\delta(S(x_k))]\},&\text{if}\ x_k>0 \\
c+a+\alpha_\delta V^*_\delta(1),&\text{else.}
\end{cases}
\end{equation}
Under the optimal policy, the total discounted cost $V_\delta(x_k,\mu;k)=V^*_\delta(x_k)$ for all $x_k,k$.
Since we only consider stationary policies, the $k$ will also be suppressed in the notation of $V_\delta(x_k,\mu)$.

\subsection{Continuous-time MDP}
In the remainder of the chapter, we will consider a continuous-time MDP that is obtained by letting $\delta\rightarrow0$.
We will occasionally return to the discrete MDP to prove certain properties.
For small $\delta$ the discount $\alpha_\delta$ is given by
\[
\alpha_\delta=1-\delta\beta+o(\delta^2).
\]
When action $a_W$ is chosen, at age $x_k$, the transition probabilities become
$$
\mathbb{P}(\omega_k(x_k)=1)=\frac{1-F(\delta x_k)}{1-F(\delta (x_k-1))}=1-\delta h(\delta x_k)+o(\delta^2),
$$
and
\[
\mathbb{P}(\omega_k(x_k)=0)=\frac{F(\delta x_k)-F(\delta (x_k-1))}{1-F(\delta (x_k-1))}=\delta h(\delta x_k)+o(\delta^2).
\]
This hazard rate $h$ is assumed to be increasing.
For the value functions, we will write $V^*(x):=\lim\limits_{\delta\rightarrow0}V_\delta^*(\lfloor x/\delta\rfloor)$ and similarly $V(x,\mu):=\lim\limits_{\delta\rightarrow0}V_\delta(\lfloor x/\delta\rfloor,\mu)$.
Moreover $V^*(0^+):=\lim\limits_{\delta\rightarrow0}V_\delta^*(1)$.
Note that we have to write $V^*(0^+)$ instead of $V^*(0)$ for a new asset as the latter corresponds to the asset being broken.

\subsection{Alternative models}
The problem can be formalized in many different ways.
We will briefly show some alternatives to the modeling choices that were made in the above problem definition.
\subsubsection{Instantaneous repairs}
If we would want to make repairs take zero time, we would have to change the definition of $x_{k+1}$ to 
$$
x_{k+1}=f_2(x_k,u_k,\omega_k):=\begin{cases}
0,&\text{if}\ \omega_k=0 \\
2,&\text{if}\ u_k=a_R\ \text{and}\ \omega_k=1\\
x_k+1,&\text{if}\ u_k=a_W\ \text{and}\ \omega_k=1.
\end{cases}
$$
This would however, introduce the possibility of having to correctively repair the asset twice in a row.
However, when we let $\delta\rightarrow 0$, this would not make any difference.

\subsubsection{Stochastic inter-decision times}
Another possibility would be to have positive random i.i.d. inter-decision times $\Delta_k$ and to use a continuous discount such that costs at time $t$ are discounted by $e^{-\beta t}$ for $\beta>0$.
The state space could then be modeled as $X=\mathbb{R}_0^+\cup\{x_{BREAK}\}$ where $x_{BREAK}$ is the state where the asset is broken.
The state evolution would be as follows:

$$
x_{k+1}=f(x_k,u_k,\omega_k,\Delta_k):=\begin{cases}
\Delta_k,&\text{if}\ u_k=a_R \\
x_f,&\text{if}\ u_k=a_W\ \text{and}\ \omega_k=0 \\
x_k+\Delta_k,&\text{if}\ u_k=a_W\ \text{and}\ \omega_k=1.
\end{cases}
$$
The Bellman equations should then be changed to
$$
V^*(x_k)=\begin{cases}
\min\{c+\mathbb{E}[e^{-\beta \Delta} V^*(\Delta)],\mathbb{E}[e^{-\beta \Delta} V^*(f(x_k,a_W,\omega_k,\Delta))],&\text{if}\ x_k\neq x_f \\
c+a+\mathbb{E}[e^{-\beta \Delta} V^*(\Delta)],&\text{else.}
\end{cases}
$$
Where repair would again take one inter-decision time. Where $\Delta$ is of the same family of i.i.d. random variables as the $\Delta_i$'s.

%\subsubsection{Remaining lifetime in state information}
%The remaining lifetime could also be included in the state information.
%We would then denote the cost when the machine still has a time $q$ to live by $V(q)$ and in each time step, this remaining lifetime would decrease by $\delta$ until the remaining lifetime is negative, when the machine must be repaired.
%If the initial remaining lifetime would be given by the random variable $Q\sim F$, the total discounted cost would then be $\mathbb{E}[V(Q)]$ and the Bellman equations would be:
%$$
%V(q)=\min\{
%c+\alpha_{\delta} \mathbb{E}[V(Q)],
%\alpha_{\delta} V(q-\delta)
%\}
%$$
%for $q>0$ and
%$$
%V(q)=c + a + \alpha_{\delta} \mathbb{E}[V(Q)],
%$$
%else.
%These equations are easy to solve although the resulting policy is not very useful in a realistic setting:
%If $0<q\leq\delta$, then 
%\[
%\begin{split}
%V(q)&=\min\{
%c+\alpha_{\delta} \mathbb{E}[V(Q)],\alpha_{\delta} V(q-\delta)\}\\
%&=\min\{
%c+\alpha_{\delta} \mathbb{E}[V(Q)],\alpha_{\delta}(c+a+\alpha_{\delta} \mathbb{E}[V(Q)])\}\\
%&=c+\alpha_{\delta} \mathbb{E}[V(Q)]
%\end{split}
%\]
%(Assuming $a>\frac{1-\alpha_\delta}{\alpha_\delta}(c+\alpha_\delta\mathbb{E}[V(Q)])$, note that for sufficiently small discount factor $\alpha_\delta$, this does not hold.).
%And by induction, we can prove that for $(k-1)\delta<q\leq k\delta$ ($k>0$)
%\[\begin{split}
%V(q)&=\min\{
%c+\alpha_{\delta} \mathbb{E}[V(Q)],\alpha_{\delta} V(q-\delta)\}\\
%&=\min\{
%c+\alpha_{\delta} \mathbb{E}[V(Q)],\alpha_{\delta} \alpha_{\delta}^{k-2}(c+\alpha_\delta\mathbb{E}[V(Q)])\}\\
%&=\alpha_{\delta}^{k-1}(c+\alpha_\delta\mathbb{E}[V(Q)]).
%\end{split}\]
%
%As can be seen, the cost does not depend on $a$ as correctively repairing never occurs. This is because in this formulation, the time-to-live is known when making the decision (when choosing the minimum). Such that we will repair at the last opportunity before the machine breaks down.
%If, for instance, we choose $\alpha_\delta=e^{-\beta \delta}$ for $\beta>0$, we have for $(k-1)\delta<q\leq k\delta$
%$$
%V(q)=e^{-\beta(k-1)\delta}(c+\alpha_\delta\mathbb{E}[V(Q)]).
%$$
%If we let $\delta$ approach zero, the cost approaches 
%$$
%V(q)=e^{-\beta q}(c+\alpha_\delta\mathbb{E}[V(Q)]).
%$$
%As can be seen, this is the cost of repairing the machine preventively at exactly the instant that it will break, which is indeed optimal but can unfortunately not be realized as the time-to-live cannot be directly observed.