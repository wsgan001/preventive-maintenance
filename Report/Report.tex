\input{Sections/imports.tex}
\begin{document}
\title{Dynamically adaptive age-based maintenance policies}
\author{Martijn G\"{o}sgens\\
\and
S\'{a}ndor Kolumb\'{a}n\\
\and
Stella Kapodistria
}
\input{Sections/TitlePage.tex}


\begin{abstract}
	In this thesis, we model the lifetime of an asset as a Markov modulated fluid model (MMFM) and find a replacement policy minimizing the total discounted cost.
	We assume the cost of correctively repairing the machine is larger than the cost of preventively repairing it.
	At each transition of the Markovian environment, the fluid level instantaneously increases by a constant amount, where the amount depends on the origin and destination state of the Markovian environment.
	Numeric methods to compute the total discounted cost for a given stationary replacement policy and iteration methods to find the optimal replacement policy are presented.
\end{abstract}

\chapter*{Executive summary}
[Describe characteristics of a machine whose deterioration that can be modeled by a MMFM with jumps: different activities that in different degrees wear out the machine, the machine has no schedule (actions as CTMC), partial repairs between activities and an initial fitness of the machine.]

[List assumptions]

[The type of observations for which the policy is useful: trace data where at each time the current activity is known and failures are observed.]

[Mention the kind of historical data needed for the parameter estimation.]

[The type of (online) policy that is presented and how it would be implemented.]

[Explain possibilities of forecasting time until preventive repair.]

\tableofcontents

% Introduction
\input{Sections/introduction}

\chapter{Literature overview}\label{chapter:literatureOverview}
In this chapter, some preliminaries will be summarized.
We will first explain some useful results and concepts from Markov decision theory.
After that, we will do the same for survival analysis.

\section{Markov decision theory}
Markov Decision Theory provides the mathematical framework to make decisions based on a Markov model.
There are various types of Markov Decision Problems (MDPs).
A distinction can be made based on the time horizon of the problem; whether it is finite or infinite.
For infinite horizon problems, the total cost might be infinite.
Two approaches are common to resolve this issue of infinity: The first is to discount costs further in the future; The second is to consider the average cost per time unit in the long run.
We will first compare these two approaches.
After that we will explain the structure of solutions to MDPs and discuss methods to find them.
\subsubsection{Discounted vs. long run average cost}
[Explain relation and pros and cons of both]
\subsubsection{Stationary policies}
\section{Survival analysis}
\subsection{Classification of lifetime distributions}
[increasing and decreasing hazard rate. No preventive maintenance for decreasing hazard rates.]


%\chapter{Analysis of problems}
\chapter{Age-based maintenance}\label{chapter:AgeBased}
A machine is considered that is subject to deterioration over time.
If no further observations are made while the machine is active, any choice to repair the machine can only be based on its age.
In this chapter we will investigate methods to find an optimal preventive maintenance policy in terms of total discounted cost.
% Problem formulation and definitions
\input{Sections/AgeBasedProblemDefinition.tex}
% Structure of optimal policy
\input{Sections/AgeBasedPolicyStructure.tex}
% Computation of total discounted cost
\input{Sections/AgeBasedTDC.tex}
% Analysis of the optimal policy
\input{Sections/AgeBasedOptimalPolicy}
% Computing the optimal policy
\input{Sections/AgeBasedPolicyComputation}
% Structural properties
\input{Sections/AgeBasedStructuralProperties.tex}

\chapter{Simple fluid model with jumps}\label{chapter:SimpleFluid}
The problem of the previous chapter can be seen as a very simple Markov modulated fluid model:
Initially, the bucket has a random amount of fluid $Q\sim F$.
The fluid decreases constantantly with rate $1$ and no fluid jumps occur.
In this chapter, we extend this model by allowing jumps to occur according to a Poisson process with rate $\lambda$.
The jumps all have the same constant (and known size) $J$.
In the real world, these fluid jumps could correspond to a partial repair of the machine.
The presence of jumps introduces the following complications:
\begin{itemize}
	\item The hazard of the machine failing at some time $t$ cannot be derived directly from the age only but also depends on the number of jumps that occurred before $t$.
	\item Furthermore, the times at which these jumps occurred also matter.
	When a jump occurs at time $t$, it is certain that the fluid quantity is at least $J$ so that you know for certain that in the interval $[t,t+J)$ the machine cannot fail.
\end{itemize}
In this chapter, the expected total discounted cost is calculated and methods are introduced to find the optimal replacement policy.
% Problem formulation and definition
\input{Sections/SimpleFluidProblemDefinition.tex}
% Structure of optimal policy
\input{Sections/SimpleFluidPolicyStructure}
% Computation of total discounted cost
\input{Sections/SimpleFluidTDC}
% Heuristic policies
\input{Sections/SimpleFluidHeuristics}
% The optimal policy
\input{Sections/SimpleFluidOptimalPolicy}
% Structural properties
\input{Sections/SimpleFluidStructuralProperties}

\chapter{Markov Modulated Fluid Model with jumps}\label{chapter:Mmfm}
In this chapter, we extend the model of the simple fluid model with jumps from the previous chapter to a Markov modulated fluid model (MMFM) with various states, fluid rates, various fluid jump sizes and rates.
The fluid jumps occur when a transition occurs in the underlying Markov chain.
The MMFM that is used is similar to the first-order fluid model considered in \cite{Gribaudo2007}, with the addition of constant jumps.
The size of the jumps are constant.
The various fluid rates, transition rates and jump sizes introduce the following complications with regard to computing the total discounted cost and the optimal policy:
\begin{enumerate}
	\item The computation of the expected discount factors $D(q)$ is more difficult as we need to take multiple
	paths with different probabilities and jump sizes into account.
	Moreover, it is also relevant from which state you start and where you end.
	\item There are different control limits $\mu_i$ for different states $s_i$, all depending on each other.
	\item A jump can cause the machine to be repaired when the amount of used fluid has exceeded the control limit.
\end{enumerate}
These complications will be explained and tackled in the following sections.
% Problem formulation and definition
\input{Sections/MmfmProblemDefinition.tex}
% Structure of optimal policy
\input{Sections/MmfmPolicyStructure}
% Computation of total discounted cost
\input{Sections/MmfmTDC}
% Computation of discounted probabilities
\input{Sections/MmfmDiscounts}
% The optimal policy
\input{Sections/MmfmOptimalPolicy}
% Structural properties
\input{Sections/MmfmStructuralProperties}
% Heuristic policies
\input{Sections/MmfmHeuristicPolicies}
% Computing the optimal control limits
\input{Sections/MmfmPolicyComputation}

% Chapter Data analysis
\input{Sections/DataAnalysis}

\chapter{Parameter estimation}\label{chapter:ParameterEstimation}
In this chapter, we will discuss methods for estimating the parameters of the Markov modulated fluid model.
These parameters are the following:
\begin{itemize}
	\item First of all, we need the parameters of the CTMC.
	These are the transition rates $\lambda_{ij}$ between the states $s_i$ and $s_j$.
	\item For the fluid model, we also need a rate $r_i>0$ for each state $s_i$ and we need the size of the fluid increases $J_{ij}$ for transitions from $s_i$ to $s_j$. 
\end{itemize}
This results in $N^2+N+N^2=2N^2+N$ parameters.
Furthermore, we need a distribution for the initial fluid level.
\section{CTMC Estimation}
When we have the trace data, it is not difficult to estimate the transition rates.
We have continuous observations over the Markov chain as for each time, we know exactly in which CTMC-state the process was.
Let $T_i$ be the total time the process was observed to be in CTMC-state $s_i$ and let $N_{ij}$ be the total number of transitions that occurred from $s_i$ to $s_j$.
The maximum likelihood estimator of the rates $\lambda_{ij}$ is simply given by \cite{Inamura2006}
\[
\hat\lambda_{ij}=\frac{N_{ij}}{T_i}.
\]

% Estimating fluid rates and jump quantities
\input{Sections/ParametersMmfmEstimation}

\chapter{Conclusion}\label{chapter:Conclusion}
[Summarize results]
\section{Further research}
[Random jump sizes, better parameter estimation methods, zero or negative fluid rates, nonincreasing hazard rates, ordering the CTMC states depending only on the MMFM]

\chapter{Discussion}\label{chapter:discussion}
\section{Assumptions}
[List assumptions, their consequences and alternatives]
\section{Robustness}
[Explain what happens to the resulting policy and total discounted cost when one of the problem parameters or MMFM parameters changes a little.]


\bibliography{Sections/bibliography}

\begin{appendices}
	\input{Sections/ListOfSymbols.tex}
	\input{Sections/AgeBasedHazardBoundProof.tex}
\chapter{CTMC analysis}
\section{Value iteration}
[Derive Bellman equations, mention implementation]
\section{State clustering}
[Explain the state clustering that was employed, mention that repair states tend to be clustered and explain]
\chapter{Total discounted costs for various problem parameters and policies?}\label{AppendixComputationsTable}
[Tables containing the total discounted cost and control limit that resulted from various heuristic policies and parameters.]
\chapter{Matlab scripts and ProM plugins}
[references to the code]
\end{appendices}
\end{document}